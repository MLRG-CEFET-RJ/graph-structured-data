(1044, 29)
Shape of X [Batches, Digits in each Batch]:  torch.Size([64, 22])
Grad =  False
Shape of y [Batches, Optimal labels in each Batch]:  torch.Size([64, 8])
Using cuda device
NeuralNetwork(
  (fc1): Linear(in_features=22, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=7, bias=True)
)
Epoch 1, train_loss: 2596.6748004300252, val_loss: 1864.3535097440083
Validation loss decreased (inf --> 1864.353510).  Saving model ...
Epoch 2, train_loss: 1924.309638842701, val_loss: 1358.8336695035298
Validation loss decreased (1864.353510 --> 1611.593590).  Saving model ...
Epoch 3, train_loss: 1566.0441952962644, val_loss: 1164.469714208887
Validation loss decreased (1611.593590 --> 1462.552298).  Saving model ...
Epoch 4, train_loss: 1426.475458722258, val_loss: 1124.487314965991
Validation loss decreased (1462.552298 --> 1378.036052).  Saving model ...
Epoch 5, train_loss: 1368.2467459629381, val_loss: 1150.981298340692
Validation loss decreased (1378.036052 --> 1332.625101).  Saving model ...
Epoch 6, train_loss: 1414.1844005982034, val_loss: 1141.747589402729
Validation loss decreased (1332.625101 --> 1300.812183).  Saving model ...
Epoch 7, train_loss: 1389.1747462077697, val_loss: 1144.943302189863
Validation loss decreased (1300.812183 --> 1278.545200).  Saving model ...
Epoch 8, train_loss: 1390.5115722928665, val_loss: 1138.5956837468686
Validation loss decreased (1278.545200 --> 1261.051510).  Saving model ...
Epoch 9, train_loss: 1389.0478281198937, val_loss: 1131.1341801749345
Validation loss decreased (1261.051510 --> 1246.616251).  Saving model ...
Epoch 10, train_loss: 1401.2343698058764, val_loss: 1136.0918640648883
Validation loss decreased (1246.616251 --> 1235.563813).  Saving model ...
Epoch 11, train_loss: 1390.6892301317191, val_loss: 1150.5300600043056
Validation loss decreased (1235.563813 --> 1227.833471).  Saving model ...
Epoch 12, train_loss: 1401.4707005288822, val_loss: 1130.899367548802
Validation loss decreased (1227.833471 --> 1219.755629).  Saving model ...
Epoch 13, train_loss: 1380.1756300027357, val_loss: 1141.7860120623207
Validation loss decreased (1219.755629 --> 1213.757967).  Saving model ...
Epoch 14, train_loss: 1399.9920485880587, val_loss: 1139.014301569374
Validation loss decreased (1213.757967 --> 1208.419133).  Saving model ...
Epoch 15, train_loss: 1411.7487657571546, val_loss: 1128.7283727460447
Validation loss decreased (1208.419133 --> 1203.106416).  Saving model ...
Epoch 16, train_loss: 1389.222853334173, val_loss: 1136.4304891736426
Validation loss decreased (1203.106416 --> 1198.939171).  Saving model ...
Epoch 17, train_loss: 1394.4121786535704, val_loss: 1132.8514207822311
Validation loss decreased (1198.939171 --> 1195.051656).  Saving model ...
Epoch 18, train_loss: 1371.740753668639, val_loss: 1139.855561260824
Validation loss decreased (1195.051656 --> 1191.985206).  Saving model ...
Epoch 19, train_loss: 1395.5170824915601, val_loss: 1123.9018459761592
Validation loss decreased (1191.985206 --> 1188.401871).  Saving model ...
Epoch 20, train_loss: 1383.02079021741, val_loss: 1120.764281392098
Validation loss decreased (1188.401871 --> 1185.019992).  Saving model ...
Epoch 21, train_loss: 1403.491267130485, val_loss: 1121.6991530303608
Validation loss decreased (1185.019992 --> 1182.004714).  Saving model ...
Epoch 22, train_loss: 1383.042567555861, val_loss: 1107.872150001703
Validation loss decreased (1182.004714 --> 1178.635052).  Saving model ...
Epoch 23, train_loss: 1394.626161241337, val_loss: 1103.2895861422578
Validation loss decreased (1178.635052 --> 1175.359162).  Saving model ...
Epoch 24, train_loss: 1384.2022427916497, val_loss: 1118.55589499297
Validation loss decreased (1175.359162 --> 1172.992359).  Saving model ...
Epoch 25, train_loss: 1403.8539772752697, val_loss: 1104.5227823698967
Validation loss decreased (1172.992359 --> 1170.253576).  Saving model ...
Epoch 26, train_loss: 1370.7605230827155, val_loss: 1113.8967578322802
Validation loss decreased (1170.253576 --> 1168.086006).  Saving model ...
Epoch 27, train_loss: 1380.310313507675, val_loss: 1117.2214519536058
Validation loss decreased (1168.086006 --> 1166.202134).  Saving model ...
Epoch 28, train_loss: 1387.396509589655, val_loss: 1108.3766160364505
Validation loss decreased (1166.202134 --> 1164.136937).  Saving model ...
Epoch 29, train_loss: 1388.5792734944623, val_loss: 1110.4981317608447
Validation loss decreased (1164.136937 --> 1162.287323).  Saving model ...
Epoch 30, train_loss: 1388.7059792336934, val_loss: 1112.6438438583305
Validation loss decreased (1162.287323 --> 1160.632540).  Saving model ...
Epoch 31, train_loss: 1384.5611327271604, val_loss: 1116.481111318977
Validation loss decreased (1160.632540 --> 1159.208301).  Saving model ...
Epoch 32, train_loss: 1388.2927076901694, val_loss: 1117.958032418181
Validation loss decreased (1159.208301 --> 1157.919230).  Saving model ...
Epoch 33, train_loss: 1383.8322258941691, val_loss: 1116.4943273464842
Validation loss decreased (1157.919230 --> 1156.663930).  Saving model ...
Epoch 34, train_loss: 1362.534035698762, val_loss: 1127.07856575648
Validation loss decreased (1156.663930 --> 1155.793772).  Saving model ...
Epoch 35, train_loss: 1384.5245351611597, val_loss: 1123.9928698716344
Validation loss decreased (1155.793772 --> 1154.885175).  Saving model ...
Epoch 36, train_loss: 1381.6238450975618, val_loss: 1123.3122944346183
Validation loss decreased (1154.885175 --> 1154.008150).  Saving model ...
Epoch 37, train_loss: 1382.6868259102562, val_loss: 1127.1879834245753
Validation loss decreased (1154.008150 --> 1153.283281).  Saving model ...
Epoch 38, train_loss: 1381.122688297239, val_loss: 1124.3551937827358
Validation loss decreased (1153.283281 --> 1152.522015).  Saving model ...
Epoch 39, train_loss: 1385.9947073147398, val_loss: 1116.1759121506302
Validation loss decreased (1152.522015 --> 1151.590064).  Saving model ...
Epoch 40, train_loss: 1375.8282915098316, val_loss: 1121.4922829071681
Validation loss decreased (1151.590064 --> 1150.837620).  Saving model ...
Epoch 41, train_loss: 1388.9092355011, val_loss: 1116.1078015786632
Validation loss decreased (1150.837620 --> 1149.990551).  Saving model ...
Epoch 42, train_loss: 1378.9034527142824, val_loss: 1109.172747823927
Validation loss decreased (1149.990551 --> 1149.018698).  Saving model ...
Epoch 43, train_loss: 1380.9131802348845, val_loss: 1109.421359658241
Validation loss decreased (1149.018698 --> 1148.097830).  Saving model ...
Epoch 44, train_loss: 1359.0002761010126, val_loss: 1128.6977854084084
Validation loss decreased (1148.097830 --> 1147.656920).  Saving model ...
Epoch 45, train_loss: 1387.8841589991994, val_loss: 1115.1237468057209
Validation loss decreased (1147.656920 --> 1146.933960).  Saving model ...
Epoch 46, train_loss: 1394.3599641654214, val_loss: 1099.202421590134
Validation loss decreased (1146.933960 --> 1145.896318).  Saving model ...
Epoch 47, train_loss: 1372.3749300184684, val_loss: 1098.781045798902
Validation loss decreased (1145.896318 --> 1144.893866).  Saving model ...
Epoch 48, train_loss: 1369.5014498583846, val_loss: 1111.357658068339
Validation loss decreased (1144.893866 --> 1144.195195).  Saving model ...
Epoch 49, train_loss: 1369.1720642721816, val_loss: 1110.8534067118608
Validation loss decreased (1144.195195 --> 1143.514750).  Saving model ...
Epoch 50, train_loss: 1381.4090923941326, val_loss: 1105.850212463626
Validation loss decreased (1143.514750 --> 1142.761459).  Saving model ...
Epoch 51, train_loss: 1377.4120970869803, val_loss: 1103.687563618024
Validation loss decreased (1142.761459 --> 1141.995305).  Saving model ...
Epoch 52, train_loss: 1375.7011858849287, val_loss: 1101.605634362609
Validation loss decreased (1141.995305 --> 1141.218580).  Saving model ...
Epoch 53, train_loss: 1388.901058670074, val_loss: 1087.319404142874
Validation loss decreased (1141.218580 --> 1140.201614).  Saving model ...
Epoch 54, train_loss: 1360.6284474304723, val_loss: 1109.0169079833558
Validation loss decreased (1140.201614 --> 1139.624120).  Saving model ...
Epoch 55, train_loss: 1363.9891482932214, val_loss: 1113.6833879771054
Validation loss decreased (1139.624120 --> 1139.152470).  Saving model ...
Epoch 56, train_loss: 1369.1307203798065, val_loss: 1120.9403643210726
Validation loss decreased (1139.152470 --> 1138.827254).  Saving model ...
Epoch 57, train_loss: 1369.4411749735707, val_loss: 1133.9493614876708
Validation loss decreased (1138.827254 --> 1138.741677).  Saving model ...
Epoch 58, train_loss: 1378.5593625080007, val_loss: 1119.6795273886785
Validation loss decreased (1138.741677 --> 1138.413019).  Saving model ...
Epoch 59, train_loss: 1367.953772152226, val_loss: 1121.296783138204
Validation loss decreased (1138.413019 --> 1138.122914).  Saving model ...
Epoch 60, train_loss: 1378.0734099272688, val_loss: 1115.3386295989706
Validation loss decreased (1138.122914 --> 1137.743176).  Saving model ...
Epoch 61, train_loss: 1369.0968421357773, val_loss: 1120.9699637801557
Validation loss decreased (1137.743176 --> 1137.468205).  Saving model ...
Epoch 62, train_loss: 1373.7357290728503, val_loss: 1119.6665888627367
Validation loss decreased (1137.468205 --> 1137.181082).  Saving model ...
Epoch 63, train_loss: 1366.7451475708062, val_loss: 1120.1007184055113
Validation loss decreased (1137.181082 --> 1136.909965).  Saving model ...
Epoch 64, train_loss: 1367.9677630020321, val_loss: 1126.2322069892173
Validation loss decreased (1136.909965 --> 1136.743125).  Saving model ...
Epoch 65, train_loss: 1362.869097411971, val_loss: 1130.7527451206133
Validation loss decreased (1136.743125 --> 1136.650965).  Saving model ...
Epoch 66, train_loss: 1369.8519801611758, val_loss: 1128.8852692003602
Validation loss decreased (1136.650965 --> 1136.533303).  Saving model ...
Epoch 67, train_loss: 1371.0549515924365, val_loss: 1125.511632910481
Validation loss decreased (1136.533303 --> 1136.368801).  Saving model ...
Epoch 68, train_loss: 1367.3625214299313, val_loss: 1128.23242119065
Validation loss decreased (1136.368801 --> 1136.249148).  Saving model ...
Epoch 69, train_loss: 1369.8947149109067, val_loss: 1124.1198361273161
Validation loss decreased (1136.249148 --> 1136.073361).  Saving model ...
Epoch 70, train_loss: 1374.5398390088371, val_loss: 1116.7192444757177
Validation loss decreased (1136.073361 --> 1135.796874).  Saving model ...
Epoch 71, train_loss: 1359.1996177359974, val_loss: 1124.583604123857
Validation loss decreased (1135.796874 --> 1135.638940).  Saving model ...
Epoch 72, train_loss: 1371.7063610554494, val_loss: 1122.3709934817416
Validation loss decreased (1135.638940 --> 1135.454663).  Saving model ...
Epoch 73, train_loss: 1364.993883819882, val_loss: 1128.4736321678865
Validation loss decreased (1135.454663 --> 1135.359033).  Saving model ...
Epoch 74, train_loss: 1366.7450537930952, val_loss: 1125.1976481411189
Validation loss decreased (1135.359033 --> 1135.221717).  Saving model ...
Epoch 75, train_loss: 1364.7811741945836, val_loss: 1112.6809788412515
Validation loss decreased (1135.221717 --> 1134.921174).  Saving model ...
Epoch 76, train_loss: 1352.4402337373053, val_loss: 1131.0828638783203
Validation loss decreased (1134.921174 --> 1134.870669).  Saving model ...
Epoch 77, train_loss: 1378.038464396113, val_loss: 1119.4004137604322
Validation loss decreased (1134.870669 --> 1134.669757).  Saving model ...
Epoch 78, train_loss: 1354.6060084826981, val_loss: 1140.6386208666688
EarlyStopping counter: 1 out of 500
Epoch 79, train_loss: 1379.3700107826678, val_loss: 1124.5263434780966
Validation loss decreased (1134.669757 --> 1134.616915).  Saving model ...
Epoch 80, train_loss: 1351.0498580711603, val_loss: 1140.884812138698
EarlyStopping counter: 1 out of 500
Epoch 81, train_loss: 1385.619808065589, val_loss: 1128.4725085364441
EarlyStopping counter: 2 out of 500
Epoch 82, train_loss: 1372.649565942571, val_loss: 1124.0926864456244
Validation loss decreased (1134.616915 --> 1134.490076).  Saving model ...
Epoch 83, train_loss: 1353.4963549868826, val_loss: 1117.7418731406876
Validation loss decreased (1134.490076 --> 1134.288291).  Saving model ...
Epoch 84, train_loss: 1375.1802589234474, val_loss: 1124.5372609496112
Validation loss decreased (1134.288291 --> 1134.172207).  Saving model ...
Epoch 85, train_loss: 1358.293393283002, val_loss: 1126.8719176385132
Validation loss decreased (1134.172207 --> 1134.086321).  Saving model ...
Epoch 86, train_loss: 1346.8151829986712, val_loss: 1145.2335081630279
EarlyStopping counter: 1 out of 500
Epoch 87, train_loss: 1355.0720877527804, val_loss: 1154.2663127956562
EarlyStopping counter: 2 out of 500
Epoch 88, train_loss: 1380.6047028528872, val_loss: 1135.1627937665687
EarlyStopping counter: 3 out of 500
Epoch 89, train_loss: 1354.0904121132694, val_loss: 1140.193806153756
EarlyStopping counter: 4 out of 500
Epoch 90, train_loss: 1360.133085924347, val_loss: 1144.136882514865
EarlyStopping counter: 5 out of 500
Epoch 91, train_loss: 1356.3741765637992, val_loss: 1149.6161872126434
EarlyStopping counter: 6 out of 500
Epoch 92, train_loss: 1369.3992196686486, val_loss: 1142.5461669299334
EarlyStopping counter: 7 out of 500
Epoch 93, train_loss: 1357.1514911932209, val_loss: 1147.886399383898
EarlyStopping counter: 8 out of 500
Epoch 94, train_loss: 1359.0490122890276, val_loss: 1148.0651852400213
EarlyStopping counter: 9 out of 500
Epoch 95, train_loss: 1361.5121290672946, val_loss: 1142.9939176783737
EarlyStopping counter: 10 out of 500
Epoch 96, train_loss: 1329.5758076738734, val_loss: 1159.3290962157423
EarlyStopping counter: 11 out of 500
Epoch 97, train_loss: 1355.0659863006863, val_loss: 1163.9417886248339
EarlyStopping counter: 12 out of 500
Epoch 98, train_loss: 1359.2434013544, val_loss: 1164.168973004376
EarlyStopping counter: 13 out of 500
Epoch 99, train_loss: 1343.0516026902003, val_loss: 1163.5000438283107
EarlyStopping counter: 14 out of 500
Epoch 100, train_loss: 1358.7685114354938, val_loss: 1159.7282380694812
EarlyStopping counter: 15 out of 500
Epoch 101, train_loss: 1359.165645098346, val_loss: 1152.11723176444
EarlyStopping counter: 16 out of 500
Epoch 102, train_loss: 1345.4277656655638, val_loss: 1154.145772067617
EarlyStopping counter: 17 out of 500
Epoch 103, train_loss: 1362.9061116572216, val_loss: 1136.6363397391635
EarlyStopping counter: 18 out of 500
Epoch 104, train_loss: 1339.8912235533608, val_loss: 1153.8747746064041
EarlyStopping counter: 19 out of 500
Epoch 105, train_loss: 1345.853544403844, val_loss: 1146.828895770355
EarlyStopping counter: 20 out of 500
Epoch 106, train_loss: 1343.6896546404882, val_loss: 1154.4298459363863
EarlyStopping counter: 21 out of 500
Epoch 107, train_loss: 1341.4826074448267, val_loss: 1156.8459968380573
EarlyStopping counter: 22 out of 500
Epoch 108, train_loss: 1341.7781622331481, val_loss: 1157.4761391360669
EarlyStopping counter: 23 out of 500
Epoch 109, train_loss: 1355.916536582972, val_loss: 1140.475914545147
EarlyStopping counter: 24 out of 500
Epoch 110, train_loss: 1330.530693958086, val_loss: 1151.604853940716
EarlyStopping counter: 25 out of 500
Epoch 111, train_loss: 1345.710128748436, val_loss: 1147.936853210749
EarlyStopping counter: 26 out of 500
Epoch 112, train_loss: 1338.556762579716, val_loss: 1150.7437056561748
EarlyStopping counter: 27 out of 500
Epoch 113, train_loss: 1349.1677644919205, val_loss: 1146.1567318843024
EarlyStopping counter: 28 out of 500
Epoch 114, train_loss: 1351.0870360797162, val_loss: 1141.462670446413
EarlyStopping counter: 29 out of 500
Epoch 115, train_loss: 1323.8625819393358, val_loss: 1151.9090187168117
EarlyStopping counter: 30 out of 500
Epoch 116, train_loss: 1353.8459485419958, val_loss: 1147.6831961456928
EarlyStopping counter: 31 out of 500
Epoch 117, train_loss: 1348.3974412612295, val_loss: 1144.5249450481376
EarlyStopping counter: 32 out of 500
Epoch 118, train_loss: 1341.5563770107037, val_loss: 1146.8803062249992
EarlyStopping counter: 33 out of 500
Epoch 119, train_loss: 1340.1006382341227, val_loss: 1149.926230223355
EarlyStopping counter: 34 out of 500
Epoch 120, train_loss: 1336.3965071497435, val_loss: 1142.0006570402777
EarlyStopping counter: 35 out of 500
Epoch 121, train_loss: 1345.422811155091, val_loss: 1144.7196564371495
EarlyStopping counter: 36 out of 500
Epoch 122, train_loss: 1329.9987651803172, val_loss: 1155.0403811275512
EarlyStopping counter: 37 out of 500
Epoch 123, train_loss: 1326.0402876376904, val_loss: 1168.9345309967462
EarlyStopping counter: 38 out of 500
Epoch 124, train_loss: 1358.0722616986045, val_loss: 1145.8881911420817
EarlyStopping counter: 39 out of 500
Epoch 125, train_loss: 1328.2717170816745, val_loss: 1148.5099794605921
EarlyStopping counter: 40 out of 500
Epoch 126, train_loss: 1348.5978336639637, val_loss: 1148.219563277297
EarlyStopping counter: 41 out of 500
Epoch 127, train_loss: 1326.9829832456778, val_loss: 1154.852463148876
EarlyStopping counter: 42 out of 500
Epoch 128, train_loss: 1320.2903940753513, val_loss: 1159.800464787483
EarlyStopping counter: 43 out of 500
Epoch 129, train_loss: 1336.547010655365, val_loss: 1161.3484058430456
EarlyStopping counter: 44 out of 500
Epoch 130, train_loss: 1328.6491179284003, val_loss: 1158.003078251591
EarlyStopping counter: 45 out of 500
Epoch 131, train_loss: 1337.1629346515242, val_loss: 1160.28061958154
EarlyStopping counter: 46 out of 500
Epoch 132, train_loss: 1336.1462852243951, val_loss: 1160.7360191253376
EarlyStopping counter: 47 out of 500
Epoch 133, train_loss: 1337.0505530064995, val_loss: 1149.3029828178437
EarlyStopping counter: 48 out of 500
Epoch 134, train_loss: 1322.162037240189, val_loss: 1156.4337250233577
EarlyStopping counter: 49 out of 500
Epoch 135, train_loss: 1335.3526856083513, val_loss: 1145.4367398354739
EarlyStopping counter: 50 out of 500
Epoch 136, train_loss: 1312.991086942125, val_loss: 1153.7284178213717
EarlyStopping counter: 51 out of 500
Epoch 137, train_loss: 1323.7262681661139, val_loss: 1158.62566485193
EarlyStopping counter: 52 out of 500
Epoch 138, train_loss: 1327.7923951136859, val_loss: 1150.2122340132569
EarlyStopping counter: 53 out of 500
Epoch 139, train_loss: 1324.7533443683649, val_loss: 1149.8902253861775
EarlyStopping counter: 54 out of 500
Epoch 140, train_loss: 1323.9007608204404, val_loss: 1140.7427589275217
EarlyStopping counter: 55 out of 500
Epoch 141, train_loss: 1321.945165877019, val_loss: 1154.1403462436463
EarlyStopping counter: 56 out of 500
Epoch 142, train_loss: 1323.3437279549096, val_loss: 1148.9584816928261
EarlyStopping counter: 57 out of 500
Epoch 143, train_loss: 1324.1982990021918, val_loss: 1140.3853226680224
EarlyStopping counter: 58 out of 500
Epoch 144, train_loss: 1290.4434022876362, val_loss: 1155.2738514533746
EarlyStopping counter: 59 out of 500
Epoch 145, train_loss: 1329.6034346541512, val_loss: 1146.759413340798
EarlyStopping counter: 60 out of 500
Epoch 146, train_loss: 1314.5188229471719, val_loss: 1145.6284377786847
EarlyStopping counter: 61 out of 500
Epoch 147, train_loss: 1309.0099652004608, val_loss: 1145.9986125906307
EarlyStopping counter: 62 out of 500
Epoch 148, train_loss: 1306.0482252186223, val_loss: 1147.88083062481
EarlyStopping counter: 63 out of 500
Epoch 149, train_loss: 1307.8550158980893, val_loss: 1146.0475124840382
EarlyStopping counter: 64 out of 500
Epoch 150, train_loss: 1311.9160211847686, val_loss: 1138.654339811537
EarlyStopping counter: 65 out of 500
Epoch 151, train_loss: 1305.0654084441178, val_loss: 1138.0890383825479
EarlyStopping counter: 66 out of 500
Epoch 152, train_loss: 1308.7107128655891, val_loss: 1124.3544983792306
EarlyStopping counter: 67 out of 500
Epoch 153, train_loss: 1290.9533386951384, val_loss: 1140.7813448238373
EarlyStopping counter: 68 out of 500
Epoch 154, train_loss: 1300.2247803249045, val_loss: 1137.8310937743715
EarlyStopping counter: 69 out of 500
Epoch 155, train_loss: 1304.6334742312374, val_loss: 1138.4047847782242
EarlyStopping counter: 70 out of 500
Epoch 156, train_loss: 1304.926046596897, val_loss: 1126.698749935892
EarlyStopping counter: 71 out of 500
Epoch 157, train_loss: 1295.3822092780022, val_loss: 1133.8903230501987
EarlyStopping counter: 72 out of 500
Epoch 158, train_loss: 1287.8444238816335, val_loss: 1146.9004330377222
EarlyStopping counter: 73 out of 500
Epoch 159, train_loss: 1303.5051485074873, val_loss: 1131.8971054803883
EarlyStopping counter: 74 out of 500
Epoch 160, train_loss: 1297.3884984142983, val_loss: 1116.1999567952864
EarlyStopping counter: 75 out of 500
Epoch 161, train_loss: 1291.7271692258564, val_loss: 1124.3812262842391
EarlyStopping counter: 76 out of 500
Epoch 162, train_loss: 1285.013192824331, val_loss: 1128.8764736836047
EarlyStopping counter: 77 out of 500
Epoch 163, train_loss: 1281.321286780397, val_loss: 1145.9798617149281
EarlyStopping counter: 78 out of 500
Epoch 164, train_loss: 1291.9085170379878, val_loss: 1139.5453587998284
EarlyStopping counter: 79 out of 500
Epoch 165, train_loss: 1291.288584864847, val_loss: 1133.4279417579264
EarlyStopping counter: 80 out of 500
Epoch 166, train_loss: 1286.0248697757136, val_loss: 1132.563592249199
EarlyStopping counter: 81 out of 500
Epoch 167, train_loss: 1291.8257221751721, val_loss: 1123.3361552695874
EarlyStopping counter: 82 out of 500
Epoch 168, train_loss: 1286.9119478270336, val_loss: 1122.3385897837745
EarlyStopping counter: 83 out of 500
Epoch 169, train_loss: 1280.940917436866, val_loss: 1117.2294545644302
EarlyStopping counter: 84 out of 500
Epoch 170, train_loss: 1287.8497505642567, val_loss: 1114.4038924118324
EarlyStopping counter: 85 out of 500
Epoch 171, train_loss: 1266.8008332014065, val_loss: 1117.7036300087861
EarlyStopping counter: 86 out of 500
Epoch 172, train_loss: 1271.249246674697, val_loss: 1122.3067654819843
EarlyStopping counter: 87 out of 500
Epoch 173, train_loss: 1283.515128503108, val_loss: 1126.318838994415
EarlyStopping counter: 88 out of 500
Epoch 174, train_loss: 1272.4977149854935, val_loss: 1115.6323692739454
EarlyStopping counter: 89 out of 500
Epoch 175, train_loss: 1265.539858126022, val_loss: 1124.1887694295249
EarlyStopping counter: 90 out of 500
Epoch 176, train_loss: 1269.49640161902, val_loss: 1119.9927525858527
EarlyStopping counter: 91 out of 500
Epoch 177, train_loss: 1271.2015088181063, val_loss: 1122.4132358990778
EarlyStopping counter: 92 out of 500
Epoch 178, train_loss: 1259.2557024651453, val_loss: 1120.326261928523
EarlyStopping counter: 93 out of 500
Epoch 179, train_loss: 1271.2010181230187, val_loss: 1112.9020279444592
EarlyStopping counter: 94 out of 500
Epoch 180, train_loss: 1251.3955125878986, val_loss: 1126.848187358026
EarlyStopping counter: 95 out of 500
Epoch 181, train_loss: 1272.9260320976118, val_loss: 1115.2669886313547
EarlyStopping counter: 96 out of 500
Epoch 182, train_loss: 1253.4343125994326, val_loss: 1122.136628249663
EarlyStopping counter: 97 out of 500
Epoch 183, train_loss: 1260.373324282413, val_loss: 1112.108034014437
EarlyStopping counter: 98 out of 500
Epoch 184, train_loss: 1260.22454737576, val_loss: 1119.6928899988425
EarlyStopping counter: 99 out of 500
Epoch 185, train_loss: 1255.7441887583586, val_loss: 1120.337719801267
EarlyStopping counter: 100 out of 500
Epoch 186, train_loss: 1266.0321620202317, val_loss: 1115.309361689356
EarlyStopping counter: 101 out of 500
Epoch 187, train_loss: 1262.2360460442094, val_loss: 1112.1000648557701
EarlyStopping counter: 102 out of 500
Epoch 188, train_loss: 1255.823590486956, val_loss: 1119.4810007763792
EarlyStopping counter: 103 out of 500
Epoch 189, train_loss: 1250.2318777987953, val_loss: 1119.2833036799786
EarlyStopping counter: 104 out of 500
Epoch 190, train_loss: 1252.524915831748, val_loss: 1111.6988683523075
EarlyStopping counter: 105 out of 500
Epoch 191, train_loss: 1254.4933878784682, val_loss: 1110.5766645994897
EarlyStopping counter: 106 out of 500
Epoch 192, train_loss: 1257.3896368032567, val_loss: 1099.7756064692255
EarlyStopping counter: 107 out of 500
Epoch 193, train_loss: 1241.532780397134, val_loss: 1112.368458716693
EarlyStopping counter: 108 out of 500
Epoch 194, train_loss: 1251.780046873941, val_loss: 1108.5877394559652
EarlyStopping counter: 109 out of 500
Epoch 195, train_loss: 1238.6515219593584, val_loss: 1108.7044370653898
EarlyStopping counter: 110 out of 500
Epoch 196, train_loss: 1245.6662201549493, val_loss: 1122.9000065200419
EarlyStopping counter: 111 out of 500
Epoch 197, train_loss: 1240.3968567236902, val_loss: 1122.6129483590305
EarlyStopping counter: 112 out of 500
Epoch 198, train_loss: 1247.0242776294522, val_loss: 1130.8530318235469
EarlyStopping counter: 113 out of 500
Epoch 199, train_loss: 1248.890263927511, val_loss: 1120.134027056606
EarlyStopping counter: 114 out of 500
Epoch 200, train_loss: 1235.677146491936, val_loss: 1119.8433501859067
EarlyStopping counter: 115 out of 500
Epoch 201, train_loss: 1244.4425949871058, val_loss: 1105.417073981144
EarlyStopping counter: 116 out of 500
Epoch 202, train_loss: 1237.0508132637276, val_loss: 1119.873056843811
EarlyStopping counter: 117 out of 500
Epoch 203, train_loss: 1238.330704107272, val_loss: 1118.1637381740854
EarlyStopping counter: 118 out of 500
Epoch 204, train_loss: 1238.422156001705, val_loss: 1114.6659098803557
EarlyStopping counter: 119 out of 500
Epoch 205, train_loss: 1231.908298894401, val_loss: 1103.3089391671288
EarlyStopping counter: 120 out of 500
Epoch 206, train_loss: 1237.4796836684504, val_loss: 1118.2684028341155
EarlyStopping counter: 121 out of 500
Epoch 207, train_loss: 1237.5186360817552, val_loss: 1101.1058914721457
EarlyStopping counter: 122 out of 500
Epoch 208, train_loss: 1228.0280079113838, val_loss: 1123.8703056369006
EarlyStopping counter: 123 out of 500
Epoch 209, train_loss: 1238.184387665757, val_loss: 1134.5604019745192
EarlyStopping counter: 124 out of 500
Epoch 210, train_loss: 1241.8493073967402, val_loss: 1100.500019280381
EarlyStopping counter: 125 out of 500
Epoch 211, train_loss: 1231.580270771655, val_loss: 1105.1017254297824
EarlyStopping counter: 126 out of 500
Epoch 212, train_loss: 1235.391290004327, val_loss: 1100.8824800070129
EarlyStopping counter: 127 out of 500
Epoch 213, train_loss: 1230.249264063861, val_loss: 1114.0247276728244
EarlyStopping counter: 128 out of 500
Epoch 214, train_loss: 1235.944341018849, val_loss: 1095.5852153052226
EarlyStopping counter: 129 out of 500
Epoch 215, train_loss: 1234.4244573711278, val_loss: 1100.3484792261654
EarlyStopping counter: 130 out of 500
Epoch 216, train_loss: 1224.84815455304, val_loss: 1107.5377556763756
EarlyStopping counter: 131 out of 500
Epoch 217, train_loss: 1234.4291916471682, val_loss: 1096.8080850303618
EarlyStopping counter: 132 out of 500
Epoch 218, train_loss: 1224.4728994669672, val_loss: 1085.8758462775197
EarlyStopping counter: 133 out of 500
Epoch 219, train_loss: 1231.1131960383361, val_loss: 1090.5743157362058
Validation loss decreased (1134.086321 --> 1134.055736).  Saving model ...
Epoch 220, train_loss: 1229.5893493390329, val_loss: 1085.9730614310724
Validation loss decreased (1134.055736 --> 1133.837178).  Saving model ...
Epoch 221, train_loss: 1208.9356400162058, val_loss: 1124.0684651836643
Validation loss decreased (1133.837178 --> 1133.792976).  Saving model ...
Epoch 222, train_loss: 1237.416106020332, val_loss: 1106.2000708684216
Validation loss decreased (1133.792976 --> 1133.668684).  Saving model ...
Epoch 223, train_loss: 1218.4796901391485, val_loss: 1096.9637873576307
Validation loss decreased (1133.668684 --> 1133.504088).  Saving model ...
Epoch 224, train_loss: 1215.7439576909424, val_loss: 1100.595739135389
Validation loss decreased (1133.504088 --> 1133.357175).  Saving model ...
Epoch 225, train_loss: 1226.760961690902, val_loss: 1100.1589853126916
Validation loss decreased (1133.357175 --> 1133.209628).  Saving model ...
Epoch 226, train_loss: 1220.029367944415, val_loss: 1082.1697632108796
Validation loss decreased (1133.209628 --> 1132.983788).  Saving model ...
Epoch 227, train_loss: 1214.857458243858, val_loss: 1095.610346902918
Validation loss decreased (1132.983788 --> 1132.819147).  Saving model ...
Epoch 228, train_loss: 1215.4062561570715, val_loss: 1096.7656846172724
Validation loss decreased (1132.819147 --> 1132.661018).  Saving model ...
Epoch 229, train_loss: 1221.1958789335804, val_loss: 1097.3753841446949
Validation loss decreased (1132.661018 --> 1132.506932).  Saving model ...
Epoch 230, train_loss: 1215.6987206151514, val_loss: 1091.8918466829373
Validation loss decreased (1132.506932 --> 1132.330345).  Saving model ...
Epoch 231, train_loss: 1213.19460457161, val_loss: 1094.0719145044577
Validation loss decreased (1132.330345 --> 1132.164724).  Saving model ...
Epoch 232, train_loss: 1209.0673664060723, val_loss: 1101.5229458370918
Validation loss decreased (1132.164724 --> 1132.032647).  Saving model ...
Epoch 233, train_loss: 1219.8603022184216, val_loss: 1079.6999977148905
Validation loss decreased (1132.032647 --> 1131.808044).  Saving model ...
Epoch 234, train_loss: 1196.2855108170056, val_loss: 1108.7625073349036
Validation loss decreased (1131.808044 --> 1131.709558).  Saving model ...
Epoch 235, train_loss: 1207.971558206106, val_loss: 1110.5824857574923
Validation loss decreased (1131.709558 --> 1131.619656).  Saving model ...
Epoch 236, train_loss: 1221.5568160975606, val_loss: 1087.2001391047022
Validation loss decreased (1131.619656 --> 1131.431438).  Saving model ...
Epoch 237, train_loss: 1215.003966949238, val_loss: 1081.7677647710732
Validation loss decreased (1131.431438 --> 1131.221886).  Saving model ...
Epoch 238, train_loss: 1209.8821539552976, val_loss: 1082.5953558081171
Validation loss decreased (1131.221886 --> 1131.017573).  Saving model ...
Epoch 239, train_loss: 1211.6422506748363, val_loss: 1090.273596440819
Validation loss decreased (1131.017573 --> 1130.847096).  Saving model ...
Epoch 240, train_loss: 1216.184568891162, val_loss: 1065.7480751067621
Validation loss decreased (1130.847096 --> 1130.575850).  Saving model ...
Epoch 241, train_loss: 1203.1003586618258, val_loss: 1075.461171334055
Validation loss decreased (1130.575850 --> 1130.347159).  Saving model ...
Epoch 242, train_loss: 1208.8474630016524, val_loss: 1075.5198631679132
Validation loss decreased (1130.347159 --> 1130.120600).  Saving model ...
Epoch 243, train_loss: 1196.8348610694607, val_loss: 1096.3343797680627
Validation loss decreased (1130.120600 --> 1129.981562).  Saving model ...
Epoch 244, train_loss: 1208.6859699274587, val_loss: 1097.2778873008272
Validation loss decreased (1129.981562 --> 1129.847530).  Saving model ...
Epoch 245, train_loss: 1195.2458723386658, val_loss: 1090.8484549900338
Validation loss decreased (1129.847530 --> 1129.688350).  Saving model ...
Epoch 246, train_loss: 1215.91922048784, val_loss: 1078.8075799439132
Validation loss decreased (1129.688350 --> 1129.481518).  Saving model ...
Epoch 247, train_loss: 1200.2713602446431, val_loss: 1078.785731301264
Validation loss decreased (1129.481518 --> 1129.276272).  Saving model ...
Epoch 248, train_loss: 1197.8461599445116, val_loss: 1092.6406963360753
Validation loss decreased (1129.276272 --> 1129.128548).  Saving model ...
Epoch 249, train_loss: 1204.3140091783812, val_loss: 1079.9591556115506
Validation loss decreased (1129.128548 --> 1128.931080).  Saving model ...
Epoch 250, train_loss: 1204.3150325239883, val_loss: 1083.9298066383824
Validation loss decreased (1128.931080 --> 1128.751075).  Saving model ...
Epoch 251, train_loss: 1196.5762413886102, val_loss: 1094.135234571784
Validation loss decreased (1128.751075 --> 1128.613163).  Saving model ...
Epoch 252, train_loss: 1199.3849117841753, val_loss: 1091.2391594544165
Validation loss decreased (1128.613163 --> 1128.464854).  Saving model ...
Epoch 253, train_loss: 1213.5467286340458, val_loss: 1077.6260124153125
Validation loss decreased (1128.464854 --> 1128.263910).  Saving model ...
Epoch 254, train_loss: 1192.712199441067, val_loss: 1083.5615230154995
Validation loss decreased (1128.263910 --> 1128.087916).  Saving model ...
Epoch 255, train_loss: 1203.9215135747615, val_loss: 1081.173838838869
Validation loss decreased (1128.087916 --> 1127.903939).  Saving model ...
Epoch 256, train_loss: 1201.030939085442, val_loss: 1074.7741594564916
Validation loss decreased (1127.903939 --> 1127.696401).  Saving model ...
Epoch 257, train_loss: 1184.4253771260576, val_loss: 1083.418038604569
Validation loss decreased (1127.696401 --> 1127.524112).  Saving model ...
Epoch 258, train_loss: 1199.454972073887, val_loss: 1089.7781800876726
Validation loss decreased (1127.524112 --> 1127.377810).  Saving model ...
Epoch 259, train_loss: 1192.0139530037654, val_loss: 1077.8836663571553
Validation loss decreased (1127.377810 --> 1127.186713).  Saving model ...
Epoch 260, train_loss: 1200.700911454706, val_loss: 1076.5311081790928
Validation loss decreased (1127.186713 --> 1126.991884).  Saving model ...
Epoch 261, train_loss: 1196.382326785237, val_loss: 1076.8061416817598
Validation loss decreased (1126.991884 --> 1126.799601).  Saving model ...
Epoch 262, train_loss: 1199.259659075231, val_loss: 1069.6036754986537
Validation loss decreased (1126.799601 --> 1126.581296).  Saving model ...
Epoch 263, train_loss: 1197.0278903542014, val_loss: 1068.4947396563603
Validation loss decreased (1126.581296 --> 1126.360435).  Saving model ...
Epoch 264, train_loss: 1193.0053151117195, val_loss: 1073.6644742623967
Validation loss decreased (1126.360435 --> 1126.160829).  Saving model ...
Epoch 265, train_loss: 1191.7587561384992, val_loss: 1069.2218126606945
Validation loss decreased (1126.160829 --> 1125.945964).  Saving model ...
Epoch 266, train_loss: 1188.7091008043722, val_loss: 1069.8718200363057
Validation loss decreased (1125.945964 --> 1125.735159).  Saving model ...
Epoch 267, train_loss: 1190.614048045359, val_loss: 1073.9870709625
Validation loss decreased (1125.735159 --> 1125.541346).  Saving model ...
Epoch 268, train_loss: 1195.7124522739323, val_loss: 1069.9824982885523
Validation loss decreased (1125.541346 --> 1125.334037).  Saving model ...
Epoch 269, train_loss: 1198.431590790906, val_loss: 1065.3887427401544
Validation loss decreased (1125.334037 --> 1125.111192).  Saving model ...
Epoch 270, train_loss: 1198.731533825006, val_loss: 1056.2879106543685
Validation loss decreased (1125.111192 --> 1124.856291).  Saving model ...
Epoch 271, train_loss: 1178.3083375854678, val_loss: 1057.4060175048867
Validation loss decreased (1124.856291 --> 1124.607397).  Saving model ...
Epoch 272, train_loss: 1188.8421639592646, val_loss: 1064.5229634205064
Validation loss decreased (1124.607397 --> 1124.386498).  Saving model ...
Epoch 273, train_loss: 1189.6873766420524, val_loss: 1055.7908388766539
Validation loss decreased (1124.386498 --> 1124.135232).  Saving model ...
Epoch 274, train_loss: 1190.0899875333057, val_loss: 1053.8470586344936
Validation loss decreased (1124.135232 --> 1123.878706).  Saving model ...
Epoch 275, train_loss: 1193.567810655971, val_loss: 1037.794867451456
Validation loss decreased (1123.878706 --> 1123.565674).  Saving model ...
Epoch 276, train_loss: 1184.6410314802183, val_loss: 1061.8023954522612
Validation loss decreased (1123.565674 --> 1123.341894).  Saving model ...
Epoch 277, train_loss: 1186.1690077304427, val_loss: 1066.093494510386
Validation loss decreased (1123.341894 --> 1123.135221).  Saving model ...
Epoch 278, train_loss: 1183.6727431002544, val_loss: 1056.38493131174
Validation loss decreased (1123.135221 --> 1122.895112).  Saving model ...
Epoch 279, train_loss: 1180.877927455916, val_loss: 1059.53441241622
Validation loss decreased (1122.895112 --> 1122.668013).  Saving model ...
Epoch 280, train_loss: 1197.8703357675672, val_loss: 1030.2771738885951
Validation loss decreased (1122.668013 --> 1122.338046).  Saving model ...
Epoch 281, train_loss: 1175.8751327367104, val_loss: 1057.9829865702877
Validation loss decreased (1122.338046 --> 1122.109024).  Saving model ...
Epoch 282, train_loss: 1180.3273690872768, val_loss: 1052.9077327267773
Validation loss decreased (1122.109024 --> 1121.863629).  Saving model ...
Epoch 283, train_loss: 1185.1004586022107, val_loss: 1054.9768770813503
Validation loss decreased (1121.863629 --> 1121.627280).  Saving model ...
Epoch 284, train_loss: 1180.648077474819, val_loss: 1061.9272316688523
Validation loss decreased (1121.627280 --> 1121.417069).  Saving model ...
Epoch 285, train_loss: 1180.3970910735686, val_loss: 1052.0868334016538
Validation loss decreased (1121.417069 --> 1121.173805).  Saving model ...
Epoch 286, train_loss: 1174.5021284825891, val_loss: 1050.9080895811542
Validation loss decreased (1121.173805 --> 1120.928121).  Saving model ...
Epoch 287, train_loss: 1181.0834426286242, val_loss: 1054.4181152347285
Validation loss decreased (1120.928121 --> 1120.696378).  Saving model ...
Epoch 288, train_loss: 1178.2207605329527, val_loss: 1051.3426270581176
Validation loss decreased (1120.696378 --> 1120.455567).  Saving model ...
Epoch 289, train_loss: 1171.0090780491998, val_loss: 1052.0909849511256
Validation loss decreased (1120.455567 --> 1120.219011).  Saving model ...
Epoch 290, train_loss: 1177.332009212285, val_loss: 1044.645175644336
Validation loss decreased (1120.219011 --> 1119.958412).  Saving model ...
Epoch 291, train_loss: 1176.3194530520977, val_loss: 1041.9139937365496
Validation loss decreased (1119.958412 --> 1119.690218).  Saving model ...
Epoch 292, train_loss: 1170.493012881577, val_loss: 1045.6159519141695
Validation loss decreased (1119.690218 --> 1119.436539).  Saving model ...
Epoch 293, train_loss: 1168.7859284923609, val_loss: 1051.659894322113
Validation loss decreased (1119.436539 --> 1119.205219).  Saving model ...
Epoch 294, train_loss: 1180.0407584550223, val_loss: 1036.7604192948343
Validation loss decreased (1119.205219 --> 1118.924795).  Saving model ...
Epoch 295, train_loss: 1170.4373364160692, val_loss: 1047.4229622234682
Validation loss decreased (1118.924795 --> 1118.682416).  Saving model ...
Epoch 296, train_loss: 1182.0006601398848, val_loss: 1048.8446136550551
Validation loss decreased (1118.682416 --> 1118.446477).  Saving model ...
Epoch 297, train_loss: 1179.1346243357334, val_loss: 1037.2234497276943
Validation loss decreased (1118.446477 --> 1118.172999).  Saving model ...
Epoch 298, train_loss: 1175.7416410457283, val_loss: 1030.1068875154742
Validation loss decreased (1118.172999 --> 1117.877475).  Saving model ...
Epoch 299, train_loss: 1163.6060061419007, val_loss: 1035.8100892296104
Validation loss decreased (1117.877475 --> 1117.603002).  Saving model ...
Epoch 300, train_loss: 1169.7575737437041, val_loss: 1035.5265186514237
Validation loss decreased (1117.603002 --> 1117.329414).  Saving model ...
Epoch 301, train_loss: 1161.1339168951383, val_loss: 1049.103423686381
Validation loss decreased (1117.329414 --> 1117.102750).  Saving model ...
Epoch 302, train_loss: 1170.0478450267797, val_loss: 1042.439827437092
Validation loss decreased (1117.102750 --> 1116.855521).  Saving model ...
Epoch 303, train_loss: 1169.0306111097752, val_loss: 1031.848095637604
Validation loss decreased (1116.855521 --> 1116.574969).  Saving model ...
Epoch 304, train_loss: 1175.5915978751618, val_loss: 1025.9951195559238
Validation loss decreased (1116.574969 --> 1116.277009).  Saving model ...
Epoch 305, train_loss: 1168.40180993565, val_loss: 1039.407669365097
Validation loss decreased (1116.277009 --> 1116.024978).  Saving model ...
Epoch 306, train_loss: 1172.398577841553, val_loss: 1022.8739216708254
Validation loss decreased (1116.024978 --> 1115.720563).  Saving model ...
Epoch 307, train_loss: 1162.208027969708, val_loss: 1037.4934980459127
Validation loss decreased (1115.720563 --> 1115.465752).  Saving model ...
Epoch 308, train_loss: 1174.0855908425597, val_loss: 1025.4234336318352
Validation loss decreased (1115.465752 --> 1115.173406).  Saving model ...
Epoch 309, train_loss: 1165.2290838297072, val_loss: 1038.552095407645
Validation loss decreased (1115.173406 --> 1114.925441).  Saving model ...
Epoch 310, train_loss: 1174.8885385379192, val_loss: 1028.1670137057042
Validation loss decreased (1114.925441 --> 1114.645575).  Saving model ...
Epoch 311, train_loss: 1169.2835796171373, val_loss: 1036.937184154811
Validation loss decreased (1114.645575 --> 1114.395709).  Saving model ...
Epoch 312, train_loss: 1167.095639396438, val_loss: 1028.586000784989
Validation loss decreased (1114.395709 --> 1114.120678).  Saving model ...
Epoch 313, train_loss: 1163.446288121328, val_loss: 1042.1528808935043
Validation loss decreased (1114.120678 --> 1113.890749).  Saving model ...
Epoch 314, train_loss: 1168.262509471599, val_loss: 1028.4062817700703
Validation loss decreased (1113.890749 --> 1113.618505).  Saving model ...
Epoch 315, train_loss: 1171.5857673789158, val_loss: 1029.849081371846
Validation loss decreased (1113.618505 --> 1113.352571).  Saving model ...
Epoch 316, train_loss: 1160.2417744652007, val_loss: 1028.3184855138375
Validation loss decreased (1113.352571 --> 1113.083475).  Saving model ...
Epoch 317, train_loss: 1165.3710564939324, val_loss: 1027.917008609507
Validation loss decreased (1113.083475 --> 1112.814811).  Saving model ...
Epoch 318, train_loss: 1174.072859720847, val_loss: 1029.7443857821715
Validation loss decreased (1112.814811 --> 1112.553584).  Saving model ...
Epoch 319, train_loss: 1160.1223943456814, val_loss: 1031.0967207550564
Validation loss decreased (1112.553584 --> 1112.298233).  Saving model ...
Epoch 320, train_loss: 1166.4702695926458, val_loss: 1029.6225393546515
Validation loss decreased (1112.298233 --> 1112.039871).  Saving model ...
Epoch 321, train_loss: 1165.5260844082582, val_loss: 1027.6132196652006
Validation loss decreased (1112.039871 --> 1111.776860).  Saving model ...
Epoch 322, train_loss: 1160.571963748591, val_loss: 1024.785996836954
Validation loss decreased (1111.776860 --> 1111.506702).  Saving model ...
Epoch 323, train_loss: 1164.3414115046655, val_loss: 1018.8724769107945
Validation loss decreased (1111.506702 --> 1111.219909).  Saving model ...
Epoch 324, train_loss: 1153.2193305878886, val_loss: 1034.9757558249105
Validation loss decreased (1111.219909 --> 1110.984587).  Saving model ...
Epoch 325, train_loss: 1169.5535513358031, val_loss: 1019.5527151290138
Validation loss decreased (1110.984587 --> 1110.703259).  Saving model ...
Epoch 326, train_loss: 1164.294311220404, val_loss: 1016.3163611721556
Validation loss decreased (1110.703259 --> 1110.413728).  Saving model ...
Epoch 327, train_loss: 1161.9681598622226, val_loss: 1004.1805231625948
Validation loss decreased (1110.413728 --> 1110.088856).  Saving model ...
Epoch 328, train_loss: 1156.1905247956606, val_loss: 1011.5777614918023
Validation loss decreased (1110.088856 --> 1109.788517).  Saving model ...
Epoch 329, train_loss: 1160.6100442921356, val_loss: 1012.6439433537593
Validation loss decreased (1109.788517 --> 1109.493245).  Saving model ...
Epoch 330, train_loss: 1167.6447338838286, val_loss: 1014.4615549216451
Validation loss decreased (1109.493245 --> 1109.205270).  Saving model ...
Epoch 331, train_loss: 1160.0694680669235, val_loss: 1020.630578515883
Validation loss decreased (1109.205270 --> 1108.937673).  Saving model ...
Epoch 332, train_loss: 1161.7139651025618, val_loss: 1006.8863685375674
Validation loss decreased (1108.937673 --> 1108.630290).  Saving model ...
Epoch 333, train_loss: 1156.8884519136188, val_loss: 1002.720319283053
Validation loss decreased (1108.630290 --> 1108.312242).  Saving model ...
Epoch 334, train_loss: 1159.2925900695438, val_loss: 1016.5794730861544
Validation loss decreased (1108.312242 --> 1108.037593).  Saving model ...
Epoch 335, train_loss: 1155.2981582697935, val_loss: 1014.8117240729158
Validation loss decreased (1108.037593 --> 1107.759306).  Saving model ...
Epoch 336, train_loss: 1164.2357704213393, val_loss: 1004.8346433426718
Validation loss decreased (1107.759306 --> 1107.452983).  Saving model ...
Epoch 337, train_loss: 1158.5958120370615, val_loss: 1002.0755140327086
Validation loss decreased (1107.452983 --> 1107.140290).  Saving model ...
Epoch 338, train_loss: 1152.7444742410426, val_loss: 1010.6507263191546
Validation loss decreased (1107.140290 --> 1106.854818).  Saving model ...
Epoch 339, train_loss: 1164.0812967269562, val_loss: 1010.4184817867372
Validation loss decreased (1106.854818 --> 1106.570345).  Saving model ...
Epoch 340, train_loss: 1160.3180661865213, val_loss: 1008.4854145763101
Validation loss decreased (1106.570345 --> 1106.281860).  Saving model ...
Epoch 341, train_loss: 1150.9960302748136, val_loss: 1013.2802465665345
Validation loss decreased (1106.281860 --> 1106.009128).  Saving model ...
Epoch 342, train_loss: 1157.8121872372853, val_loss: 1011.0940700052405
Validation loss decreased (1106.009128 --> 1105.731599).  Saving model ...
Epoch 343, train_loss: 1156.9672713032267, val_loss: 1006.8773072285124
Validation loss decreased (1105.731599 --> 1105.443394).  Saving model ...
Epoch 344, train_loss: 1167.3098649874905, val_loss: 993.9260937113232
Validation loss decreased (1105.443394 --> 1105.119216).  Saving model ...
Epoch 345, train_loss: 1154.23198932089, val_loss: 993.602021524509
Validation loss decreased (1105.119216 --> 1104.795977).  Saving model ...
Epoch 346, train_loss: 1143.4754508704707, val_loss: 1005.887470839995
Validation loss decreased (1104.795977 --> 1104.510115).  Saving model ...
Epoch 347, train_loss: 1157.8956480259408, val_loss: 1000.3051542212348
Validation loss decreased (1104.510115 --> 1104.209812).  Saving model ...
Epoch 348, train_loss: 1152.0365448513905, val_loss: 1003.3530456343407
Validation loss decreased (1104.209812 --> 1103.919994).  Saving model ...
Epoch 349, train_loss: 1151.3752152120546, val_loss: 1011.0073207635793
Validation loss decreased (1103.919994 --> 1103.653768).  Saving model ...
Epoch 350, train_loss: 1152.4870865176733, val_loss: 1006.8090233230595
Validation loss decreased (1103.653768 --> 1103.377069).  Saving model ...
Epoch 351, train_loss: 1141.392114468813, val_loss: 1007.569061536392
Validation loss decreased (1103.377069 --> 1103.104112).  Saving model ...
Epoch 352, train_loss: 1155.2191293185526, val_loss: 1011.5755325316062
Validation loss decreased (1103.104112 --> 1102.844087).  Saving model ...
Epoch 353, train_loss: 1150.2753135880728, val_loss: 996.8547363489207
Validation loss decreased (1102.844087 --> 1102.543834).  Saving model ...
Epoch 354, train_loss: 1164.452898403046, val_loss: 1001.8581188086231
Validation loss decreased (1102.543834 --> 1102.259411).  Saving model ...
Epoch 355, train_loss: 1147.5025860681137, val_loss: 1010.1290785381533
Validation loss decreased (1102.259411 --> 1101.999889).  Saving model ...
Epoch 356, train_loss: 1153.8669980701275, val_loss: 1005.0175737628675
Validation loss decreased (1101.999889 --> 1101.727467).  Saving model ...
Epoch 357, train_loss: 1150.581951930219, val_loss: 1000.131972782833
Validation loss decreased (1101.727467 --> 1101.442886).  Saving model ...
Epoch 358, train_loss: 1151.9398064483337, val_loss: 991.3637071646145
Validation loss decreased (1101.442886 --> 1101.135402).  Saving model ...
Epoch 359, train_loss: 1145.6649451893277, val_loss: 995.9420201068898
Validation loss decreased (1101.135402 --> 1100.842384).  Saving model ...
Epoch 360, train_loss: 1150.4207461004826, val_loss: 995.2471281056496
Validation loss decreased (1100.842384 --> 1100.549064).  Saving model ...
Epoch 361, train_loss: 1151.778979248106, val_loss: 988.5063707761855
Validation loss decreased (1100.549064 --> 1100.238697).  Saving model ...
Epoch 362, train_loss: 1148.637122934952, val_loss: 990.2803519354046
Validation loss decreased (1100.238697 --> 1099.934944).  Saving model ...
Epoch 363, train_loss: 1140.805144882637, val_loss: 1010.7110012948075
Validation loss decreased (1099.934944 --> 1099.689148).  Saving model ...
Epoch 364, train_loss: 1150.0736057325444, val_loss: 997.8245748677081
Validation loss decreased (1099.689148 --> 1099.409301).  Saving model ...
Epoch 365, train_loss: 1150.5163274190677, val_loss: 998.5725303612818
Validation loss decreased (1099.409301 --> 1099.133035).  Saving model ...
Epoch 366, train_loss: 1141.1447612596498, val_loss: 998.4421451797754
Validation loss decreased (1099.133035 --> 1098.857924).  Saving model ...
Epoch 367, train_loss: 1158.3299335516435, val_loss: 991.5014887868479
Validation loss decreased (1098.857924 --> 1098.565399).  Saving model ...
Epoch 368, train_loss: 1146.1334564828064, val_loss: 991.6214260201987
Validation loss decreased (1098.565399 --> 1098.274791).  Saving model ...
Epoch 369, train_loss: 1131.1852549505654, val_loss: 994.5535188779126
Validation loss decreased (1098.274791 --> 1097.993703).  Saving model ...
Epoch 370, train_loss: 1150.4041364269826, val_loss: 995.1030284959302
Validation loss decreased (1097.993703 --> 1097.715620).  Saving model ...
Epoch 371, train_loss: 1153.19133747457, val_loss: 1000.3676078196369
Validation loss decreased (1097.715620 --> 1097.453227).  Saving model ...
Epoch 372, train_loss: 1143.7836051105792, val_loss: 991.3501321230113
Validation loss decreased (1097.453227 --> 1097.168003).  Saving model ...
Epoch 373, train_loss: 1147.5702986124916, val_loss: 991.55137437454
Validation loss decreased (1097.168003 --> 1096.884849).  Saving model ...
Epoch 374, train_loss: 1146.4092311779605, val_loss: 993.7052362184173
Validation loss decreased (1096.884849 --> 1096.608968).  Saving model ...
Epoch 375, train_loss: 1151.116258155486, val_loss: 993.1499470855574
Validation loss decreased (1096.608968 --> 1096.333077).  Saving model ...
Epoch 376, train_loss: 1146.731320703322, val_loss: 992.6530004958757
Validation loss decreased (1096.333077 --> 1096.057332).  Saving model ...
Epoch 377, train_loss: 1139.7616896686284, val_loss: 1001.3341125429562
Validation loss decreased (1096.057332 --> 1095.806077).  Saving model ...
Epoch 378, train_loss: 1138.4092895858907, val_loss: 994.2234292937211
Validation loss decreased (1095.806077 --> 1095.537340).  Saving model ...
Epoch 379, train_loss: 1147.8243725323723, val_loss: 991.0316783091317
Validation loss decreased (1095.537340 --> 1095.261599).  Saving model ...
Epoch 380, train_loss: 1146.6174941275747, val_loss: 992.3971824147526
Validation loss decreased (1095.261599 --> 1094.990903).  Saving model ...
Epoch 381, train_loss: 1136.6793701699328, val_loss: 994.6576232752537
Validation loss decreased (1094.990903 --> 1094.727561).  Saving model ...
Epoch 382, train_loss: 1142.8604982867505, val_loss: 988.6735683261909
Validation loss decreased (1094.727561 --> 1094.449933).  Saving model ...
Epoch 383, train_loss: 1144.7196607842093, val_loss: 989.5143228252291
Validation loss decreased (1094.449933 --> 1094.175950).  Saving model ...
Epoch 384, train_loss: 1149.8916597374123, val_loss: 989.6916328589564
Validation loss decreased (1094.175950 --> 1093.903855).  Saving model ...
Epoch 385, train_loss: 1146.8672058614702, val_loss: 979.6907482929145
Validation loss decreased (1093.903855 --> 1093.607198).  Saving model ...
Epoch 386, train_loss: 1138.7206082684606, val_loss: 977.616096988696
Validation loss decreased (1093.607198 --> 1093.306703).  Saving model ...
Epoch 387, train_loss: 1139.1124865121637, val_loss: 990.2149589006107
Validation loss decreased (1093.306703 --> 1093.040316).  Saving model ...
Epoch 388, train_loss: 1136.7745072101632, val_loss: 980.9595835449963
Validation loss decreased (1093.040316 --> 1092.751448).  Saving model ...
Epoch 389, train_loss: 1139.694253691316, val_loss: 979.546036895602
Validation loss decreased (1092.751448 --> 1092.460431).  Saving model ...
Epoch 390, train_loss: 1135.1503014647851, val_loss: 994.0291004720002
Validation loss decreased (1092.460431 --> 1092.208043).  Saving model ...
Epoch 391, train_loss: 1150.5575078918066, val_loss: 986.2730178389729
Validation loss decreased (1092.208043 --> 1091.937110).  Saving model ...
Epoch 392, train_loss: 1148.1837953557329, val_loss: 982.4312416500962
Validation loss decreased (1091.937110 --> 1091.657758).  Saving model ...
Epoch 393, train_loss: 1132.876644398101, val_loss: 984.2794326256385
Validation loss decreased (1091.657758 --> 1091.384531).  Saving model ...
Epoch 394, train_loss: 1138.300333670022, val_loss: 992.3139638943145
Validation loss decreased (1091.384531 --> 1091.133083).  Saving model ...
Epoch 395, train_loss: 1145.7340325929197, val_loss: 981.8621225101423
Validation loss decreased (1091.133083 --> 1090.856447).  Saving model ...
Epoch 396, train_loss: 1137.0454176579947, val_loss: 987.5045924400846
Validation loss decreased (1090.856447 --> 1090.595458).  Saving model ...
Epoch 397, train_loss: 1133.7908097766406, val_loss: 998.3537920790251
Validation loss decreased (1090.595458 --> 1090.363111).  Saving model ...
Epoch 398, train_loss: 1142.5601410003403, val_loss: 989.1853277274417
Validation loss decreased (1090.363111 --> 1090.108895).  Saving model ...
Epoch 399, train_loss: 1137.140318723907, val_loss: 988.0945936925326
Validation loss decreased (1090.108895 --> 1089.853221).  Saving model ...
Epoch 400, train_loss: 1134.360017263662, val_loss: 991.171181448036
Validation loss decreased (1089.853221 --> 1089.606515).  Saving model ...
Epoch 401, train_loss: 1147.6497907897347, val_loss: 981.6370436791582
Validation loss decreased (1089.606515 --> 1089.337265).  Saving model ...
Epoch 402, train_loss: 1133.886660186194, val_loss: 980.5847847417111
Validation loss decreased (1089.337265 --> 1089.066736).  Saving model ...
Epoch 403, train_loss: 1130.917788972145, val_loss: 984.2352908177292
Validation loss decreased (1089.066736 --> 1088.806609).  Saving model ...
Epoch 404, train_loss: 1136.9041543286223, val_loss: 988.9999092848658
Validation loss decreased (1088.806609 --> 1088.559562).  Saving model ...
Epoch 405, train_loss: 1133.2516742021076, val_loss: 986.078610714895
Validation loss decreased (1088.559562 --> 1088.306523).  Saving model ...
Epoch 406, train_loss: 1132.6828330259611, val_loss: 983.4328662881148
Validation loss decreased (1088.306523 --> 1088.048213).  Saving model ...
Epoch 407, train_loss: 1131.6867697841774, val_loss: 985.0143679719505
Validation loss decreased (1088.048213 --> 1087.795059).  Saving model ...
Epoch 408, train_loss: 1130.2918093138608, val_loss: 987.5350151732237
Validation loss decreased (1087.795059 --> 1087.549324).  Saving model ...
Epoch 409, train_loss: 1140.3499904478292, val_loss: 985.9712076639248
Validation loss decreased (1087.549324 --> 1087.300966).  Saving model ...
Epoch 410, train_loss: 1145.3765885158753, val_loss: 983.1828101685315
Validation loss decreased (1087.300966 --> 1087.047020).  Saving model ...
Epoch 411, train_loss: 1136.807811749776, val_loss: 976.714773391088
Validation loss decreased (1087.047020 --> 1086.778571).  Saving model ...
Epoch 412, train_loss: 1134.7173209000478, val_loss: 978.4683025832092
Validation loss decreased (1086.778571 --> 1086.515682).  Saving model ...
Epoch 413, train_loss: 1123.922844360891, val_loss: 982.1651881059455
Validation loss decreased (1086.515682 --> 1086.263018).  Saving model ...
Epoch 414, train_loss: 1127.768577340548, val_loss: 987.1539075074817
Validation loss decreased (1086.263018 --> 1086.023624).  Saving model ...
Epoch 415, train_loss: 1135.8897536615152, val_loss: 984.4885900867431
Validation loss decreased (1086.023624 --> 1085.778961).  Saving model ...
Epoch 416, train_loss: 1136.520748455449, val_loss: 978.0984502973826
Validation loss decreased (1085.778961 --> 1085.520114).  Saving model ...
Epoch 417, train_loss: 1128.895809099475, val_loss: 980.765620017317
Validation loss decreased (1085.520114 --> 1085.268904).  Saving model ...
Epoch 418, train_loss: 1136.5180642756068, val_loss: 982.5393602749597
Validation loss decreased (1085.268904 --> 1085.023139).  Saving model ...
Epoch 419, train_loss: 1128.4757333277335, val_loss: 983.8709878955068
Validation loss decreased (1085.023139 --> 1084.781726).  Saving model ...
Epoch 420, train_loss: 1135.3187080144496, val_loss: 972.7875800606943
Validation loss decreased (1084.781726 --> 1084.515073).  Saving model ...
Epoch 421, train_loss: 1132.439474420827, val_loss: 985.7199526030049
Validation loss decreased (1084.515073 --> 1084.280406).  Saving model ...
Epoch 422, train_loss: 1136.8648712277698, val_loss: 979.1963977777519
Validation loss decreased (1084.280406 --> 1084.031391).  Saving model ...
Epoch 423, train_loss: 1137.986820511785, val_loss: 979.198231087482
Validation loss decreased (1084.031391 --> 1083.783559).  Saving model ...
Epoch 424, train_loss: 1127.2729745206138, val_loss: 987.1763525327492
Validation loss decreased (1083.783559 --> 1083.555712).  Saving model ...
Epoch 425, train_loss: 1141.6657625369605, val_loss: 970.0012296637784
Validation loss decreased (1083.555712 --> 1083.288525).  Saving model ...
Epoch 426, train_loss: 1122.47184644438, val_loss: 989.5275503243344
Validation loss decreased (1083.288525 --> 1083.068429).  Saving model ...
Epoch 427, train_loss: 1128.4210252042328, val_loss: 984.9740938315571
Validation loss decreased (1083.068429 --> 1082.838699).  Saving model ...
Epoch 428, train_loss: 1140.607192862952, val_loss: 985.7214464975291
Validation loss decreased (1082.838699 --> 1082.611790).  Saving model ...
Epoch 429, train_loss: 1121.805130162905, val_loss: 993.3583717773582
Validation loss decreased (1082.611790 --> 1082.403740).  Saving model ...
Epoch 430, train_loss: 1131.9466167297628, val_loss: 984.7375571484478
Validation loss decreased (1082.403740 --> 1082.176609).  Saving model ...
Epoch 431, train_loss: 1123.191740974164, val_loss: 997.1218255853215
Validation loss decreased (1082.176609 --> 1081.979266).  Saving model ...
Epoch 432, train_loss: 1131.729335074477, val_loss: 992.6456109812087
Validation loss decreased (1081.979266 --> 1081.772476).  Saving model ...
Epoch 433, train_loss: 1135.6046128078108, val_loss: 983.6310554829353
Validation loss decreased (1081.772476 --> 1081.545821).  Saving model ...
Epoch 434, train_loss: 1129.349898061899, val_loss: 990.2632010730554
Validation loss decreased (1081.545821 --> 1081.335492).  Saving model ...
Epoch 435, train_loss: 1122.5769097243706, val_loss: 991.4417088370857
Validation loss decreased (1081.335492 --> 1081.128840).  Saving model ...
Epoch 436, train_loss: 1131.1550947790151, val_loss: 982.294451444061
Validation loss decreased (1081.128840 --> 1080.902156).  Saving model ...
Epoch 437, train_loss: 1115.5955306949356, val_loss: 992.1057745160001
Validation loss decreased (1080.902156 --> 1080.698960).  Saving model ...
Epoch 438, train_loss: 1139.0311411766304, val_loss: 987.2294631973905
Validation loss decreased (1080.698960 --> 1080.485560).  Saving model ...
Epoch 439, train_loss: 1119.6436613948572, val_loss: 979.7523625053301
Validation loss decreased (1080.485560 --> 1080.256099).  Saving model ...
Epoch 440, train_loss: 1136.9119408680376, val_loss: 978.074679734486
Validation loss decreased (1080.256099 --> 1080.023869).  Saving model ...
Epoch 441, train_loss: 1118.29081372788, val_loss: 988.7431325113336
Validation loss decreased (1080.023869 --> 1079.816883).  Saving model ...
Epoch 442, train_loss: 1123.5287647990954, val_loss: 988.5351050348198
Validation loss decreased (1079.816883 --> 1079.610363).  Saving model ...
Epoch 443, train_loss: 1133.0091818458116, val_loss: 984.4881492739697
Validation loss decreased (1079.610363 --> 1079.395640).  Saving model ...
Epoch 444, train_loss: 1126.947598318278, val_loss: 983.3187640349073
Validation loss decreased (1079.395640 --> 1079.179251).  Saving model ...
Epoch 445, train_loss: 1126.874164706965, val_loss: 978.7292519175567
Validation loss decreased (1079.179251 --> 1078.953520).  Saving model ...
Epoch 446, train_loss: 1128.608412702154, val_loss: 982.8932276653363
Validation loss decreased (1078.953520 --> 1078.738139).  Saving model ...
Epoch 447, train_loss: 1124.2869250832148, val_loss: 988.011719146923
Validation loss decreased (1078.738139 --> 1078.535171).  Saving model ...
Epoch 448, train_loss: 1130.159937368863, val_loss: 987.6232717674311
Validation loss decreased (1078.535171 --> 1078.332243).  Saving model ...
Epoch 449, train_loss: 1122.8233929338064, val_loss: 986.6570057195207
Validation loss decreased (1078.332243 --> 1078.128066).  Saving model ...
Epoch 450, train_loss: 1108.4546956011893, val_loss: 990.00985875792
Validation loss decreased (1078.128066 --> 1077.932248).  Saving model ...
Epoch 451, train_loss: 1129.055966589035, val_loss: 991.3406218739793
Validation loss decreased (1077.932248 --> 1077.740249).  Saving model ...
Epoch 452, train_loss: 1118.026005428292, val_loss: 982.7081388861166
Validation loss decreased (1077.740249 --> 1077.530001).  Saving model ...
Epoch 453, train_loss: 1120.0128822765462, val_loss: 989.6843021707626
Validation loss decreased (1077.530001 --> 1077.336081).  Saving model ...
Epoch 454, train_loss: 1122.1398551262755, val_loss: 984.5740047944037
Validation loss decreased (1077.336081 --> 1077.131759).  Saving model ...
Epoch 455, train_loss: 1127.2268507678968, val_loss: 987.3815306068796
Validation loss decreased (1077.131759 --> 1076.934506).  Saving model ...
Epoch 456, train_loss: 1127.175514019581, val_loss: 984.9970170444032
Validation loss decreased (1076.934506 --> 1076.732889).  Saving model ...
Epoch 457, train_loss: 1121.3383968701387, val_loss: 987.1395813333992
Validation loss decreased (1076.732889 --> 1076.536842).  Saving model ...
Epoch 458, train_loss: 1122.3070940564592, val_loss: 985.0702967495835
Validation loss decreased (1076.536842 --> 1076.337133).  Saving model ...
Epoch 459, train_loss: 1118.5718419674185, val_loss: 989.2116189540761
Validation loss decreased (1076.337133 --> 1076.147318).  Saving model ...
Epoch 460, train_loss: 1128.5521830313207, val_loss: 983.5739883006064
Validation loss decreased (1076.147318 --> 1075.946071).  Saving model ...
Epoch 461, train_loss: 1117.4028879971827, val_loss: 989.8596712677571
Validation loss decreased (1075.946071 --> 1075.759333).  Saving model ...
Epoch 462, train_loss: 1129.6978957933902, val_loss: 991.7315162032182
Validation loss decreased (1075.759333 --> 1075.577454).  Saving model ...
Epoch 463, train_loss: 1118.151310868561, val_loss: 992.4034273906996
Validation loss decreased (1075.577454 --> 1075.397813).  Saving model ...
Epoch 464, train_loss: 1127.582199132244, val_loss: 990.9747977184811
Validation loss decreased (1075.397813 --> 1075.215867).  Saving model ...
Epoch 465, train_loss: 1122.2818541180002, val_loss: 988.0266277687641
Validation loss decreased (1075.215867 --> 1075.028363).  Saving model ...
Epoch 466, train_loss: 1113.5157384845709, val_loss: 989.8896496745397
Validation loss decreased (1075.028363 --> 1074.845662).  Saving model ...
Epoch 467, train_loss: 1132.8092896839125, val_loss: 984.244288214622
Validation loss decreased (1074.845662 --> 1074.651655).  Saving model ...
Epoch 468, train_loss: 1111.5187105039563, val_loss: 992.0606644789382
Validation loss decreased (1074.651655 --> 1074.475178).  Saving model ...
Epoch 469, train_loss: 1121.172207777084, val_loss: 993.9880531802445
Validation loss decreased (1074.475178 --> 1074.303564).  Saving model ...
Epoch 470, train_loss: 1116.9074012352419, val_loss: 984.3444819767391
Validation loss decreased (1074.303564 --> 1074.112162).  Saving model ...
Epoch 471, train_loss: 1136.1515861107102, val_loss: 989.2716474894245
Validation loss decreased (1074.112162 --> 1073.932033).  Saving model ...
Epoch 472, train_loss: 1114.1678755444295, val_loss: 988.8647848263937
Validation loss decreased (1073.932033 --> 1073.751806).  Saving model ...
Epoch 473, train_loss: 1123.3033513905118, val_loss: 989.1474436994396
Validation loss decreased (1073.751806 --> 1073.572938).  Saving model ...
Epoch 474, train_loss: 1118.1413975201326, val_loss: 985.4044321947631
Validation loss decreased (1073.572938 --> 1073.386929).  Saving model ...
Epoch 475, train_loss: 1130.692960029362, val_loss: 984.3237853600361
Validation loss decreased (1073.386929 --> 1073.199427).  Saving model ...
Epoch 476, train_loss: 1112.4035017167155, val_loss: 979.147474604183
Validation loss decreased (1073.199427 --> 1073.001839).  Saving model ...
Epoch 477, train_loss: 1116.7884688380507, val_loss: 978.5477137564732
Validation loss decreased (1073.001839 --> 1072.803822).  Saving model ...
Epoch 478, train_loss: 1124.285696621992, val_loss: 974.995305819335
Validation loss decreased (1072.803822 --> 1072.599202).  Saving model ...
Epoch 479, train_loss: 1114.0010396305113, val_loss: 970.6003861716059
Validation loss decreased (1072.599202 --> 1072.386261).  Saving model ...
Epoch 480, train_loss: 1121.2373076302376, val_loss: 984.6192585789721
Validation loss decreased (1072.386261 --> 1072.203413).  Saving model ...
Epoch 481, train_loss: 1114.4007543792889, val_loss: 983.1807597840719
Validation loss decreased (1072.203413 --> 1072.018335).  Saving model ...
Epoch 482, train_loss: 1118.6945719599303, val_loss: 981.6973337416299
Validation loss decreased (1072.018335 --> 1071.830947).  Saving model ...
Epoch 483, train_loss: 1128.9209150333352, val_loss: 984.9711914855465
Validation loss decreased (1071.830947 --> 1071.651113).  Saving model ...
Epoch 484, train_loss: 1121.697106688642, val_loss: 985.1678523085737
Validation loss decreased (1071.651113 --> 1071.472428).  Saving model ...
Epoch 485, train_loss: 1118.9784544260776, val_loss: 983.9421331273626
Validation loss decreased (1071.472428 --> 1071.291953).  Saving model ...
Epoch 486, train_loss: 1112.4138846237745, val_loss: 985.8496783935584
Validation loss decreased (1071.291953 --> 1071.116146).  Saving model ...
Epoch 487, train_loss: 1114.1546773462828, val_loss: 988.8875198580604
Validation loss decreased (1071.116146 --> 1070.947299).  Saving model ...
Epoch 488, train_loss: 1123.1445332005992, val_loss: 991.7638792436655
Validation loss decreased (1070.947299 --> 1070.785038).  Saving model ...
Epoch 489, train_loss: 1124.3470304940383, val_loss: 993.5993866297936
Validation loss decreased (1070.785038 --> 1070.627194).  Saving model ...
Epoch 490, train_loss: 1113.9753932346334, val_loss: 990.8540347909488
Validation loss decreased (1070.627194 --> 1070.464392).  Saving model ...
Epoch 491, train_loss: 1111.650501040154, val_loss: 989.1220108288309
Validation loss decreased (1070.464392 --> 1070.298725).  Saving model ...
Epoch 492, train_loss: 1110.8797198389489, val_loss: 993.6011539340021
Validation loss decreased (1070.298725 --> 1070.142836).  Saving model ...
Epoch 493, train_loss: 1123.3969977591346, val_loss: 978.9347694725461
Validation loss decreased (1070.142836 --> 1069.957829).  Saving model ...
Epoch 494, train_loss: 1106.3157803126612, val_loss: 986.4501298253186
Validation loss decreased (1069.957829 --> 1069.788785).  Saving model ...
Epoch 495, train_loss: 1128.7559818489867, val_loss: 988.5867400210437
Validation loss decreased (1069.788785 --> 1069.624741).  Saving model ...
Epoch 496, train_loss: 1127.9180590410551, val_loss: 988.7052410441861
Validation loss decreased (1069.624741 --> 1069.461597).  Saving model ...
Epoch 497, train_loss: 1117.59695909369, val_loss: 983.3373058170305
Validation loss decreased (1069.461597 --> 1069.288308).  Saving model ...
Epoch 498, train_loss: 1117.5269048914734, val_loss: 984.8137208109879
Validation loss decreased (1069.288308 --> 1069.118681).  Saving model ...
Epoch 499, train_loss: 1112.7476016991673, val_loss: 985.7797066533127
Validation loss decreased (1069.118681 --> 1068.951669).  Saving model ...
Epoch 500, train_loss: 1114.873258172179, val_loss: 985.3075525757564
Validation loss decreased (1068.951669 --> 1068.784381).  Saving model ...
Epoch 501, train_loss: 1132.5975920828557, val_loss: 985.087664922741
Validation loss decreased (1068.784381 --> 1068.617321).  Saving model ...
Epoch 502, train_loss: 1110.236309024134, val_loss: 984.4004879105092
Validation loss decreased (1068.617321 --> 1068.449559).  Saving model ...
Epoch 503, train_loss: 1117.2428085595604, val_loss: 990.8757198779675
Validation loss decreased (1068.449559 --> 1068.295336).  Saving model ...
Epoch 504, train_loss: 1119.285855343645, val_loss: 985.1049081435914
Validation loss decreased (1068.295336 --> 1068.130276).  Saving model ...
Epoch 505, train_loss: 1113.198768323348, val_loss: 983.7237840080707
Validation loss decreased (1068.130276 --> 1067.963134).  Saving model ...
Epoch 506, train_loss: 1109.4142383474116, val_loss: 990.8225083059739
Validation loss decreased (1067.963134 --> 1067.810682).  Saving model ...
Epoch 507, train_loss: 1117.9587541236622, val_loss: 986.1538853839596
Validation loss decreased (1067.810682 --> 1067.649624).  Saving model ...
Epoch 508, train_loss: 1115.5426273373248, val_loss: 987.550365169402
Validation loss decreased (1067.649624 --> 1067.491948).  Saving model ...
Epoch 509, train_loss: 1126.5351430764656, val_loss: 987.7125686823441
Validation loss decreased (1067.491948 --> 1067.335211).  Saving model ...
Epoch 510, train_loss: 1120.0278975104764, val_loss: 984.7413238791625
Validation loss decreased (1067.335211 --> 1067.173262).  Saving model ...
Epoch 511, train_loss: 1099.7335080267, val_loss: 986.6403780718648
Validation loss decreased (1067.173262 --> 1067.015663).  Saving model ...
Epoch 512, train_loss: 1126.6359417392514, val_loss: 982.8859833685561
Validation loss decreased (1067.015663 --> 1066.851347).  Saving model ...
Epoch 513, train_loss: 1096.779070406717, val_loss: 989.2459457260597
Validation loss decreased (1066.851347 --> 1066.700070).  Saving model ...
Epoch 514, train_loss: 1119.0845790953338, val_loss: 990.4032751108984
Validation loss decreased (1066.700070 --> 1066.551632).  Saving model ...
Epoch 515, train_loss: 1112.9265878859117, val_loss: 985.4931012884339
Validation loss decreased (1066.551632 --> 1066.394237).  Saving model ...
Epoch 516, train_loss: 1106.3765509099806, val_loss: 989.4437566803567
Validation loss decreased (1066.394237 --> 1066.245108).  Saving model ...
Epoch 517, train_loss: 1114.5191443570404, val_loss: 983.3341372354388
Validation loss decreased (1066.245108 --> 1066.084739).  Saving model ...
Epoch 518, train_loss: 1111.64274191689, val_loss: 985.9349086765895
Validation loss decreased (1066.084739 --> 1065.930010).  Saving model ...
Epoch 519, train_loss: 1116.513997480983, val_loss: 983.1567263764367
Validation loss decreased (1065.930010 --> 1065.770523).  Saving model ...
Epoch 520, train_loss: 1102.4904725080874, val_loss: 986.1457549947285
Validation loss decreased (1065.770523 --> 1065.617399).  Saving model ...
Epoch 521, train_loss: 1112.7909013661365, val_loss: 973.8408691664099
Validation loss decreased (1065.617399 --> 1065.441244).  Saving model ...
Epoch 522, train_loss: 1111.8113019676487, val_loss: 985.6692436487591
Validation loss decreased (1065.441244 --> 1065.288424).  Saving model ...
Epoch 523, train_loss: 1105.9631166178413, val_loss: 985.7073459874705
Validation loss decreased (1065.288424 --> 1065.136262).  Saving model ...
Epoch 524, train_loss: 1107.4595290096836, val_loss: 982.4303885687726
Validation loss decreased (1065.136262 --> 1064.978426).  Saving model ...
Epoch 525, train_loss: 1110.7302070500607, val_loss: 971.5821546590329
Validation loss decreased (1064.978426 --> 1064.800528).  Saving model ...
Epoch 526, train_loss: 1106.4215561787905, val_loss: 981.9934547893649
Validation loss decreased (1064.800528 --> 1064.643101).  Saving model ...
Epoch 527, train_loss: 1120.6212102552158, val_loss: 979.5246465601746
Validation loss decreased (1064.643101 --> 1064.481585).  Saving model ...
Epoch 528, train_loss: 1100.7843419942453, val_loss: 976.3234907362199
Validation loss decreased (1064.481585 --> 1064.314619).  Saving model ...
Epoch 529, train_loss: 1105.789387950986, val_loss: 989.6132160663607
Validation loss decreased (1064.314619 --> 1064.173407).  Saving model ...
Epoch 530, train_loss: 1116.3723426483505, val_loss: 979.8928290214807
Validation loss decreased (1064.173407 --> 1064.014387).  Saving model ...
Epoch 531, train_loss: 1115.4905484893825, val_loss: 973.5104836806105
Validation loss decreased (1064.014387 --> 1063.843946).  Saving model ...
Epoch 532, train_loss: 1113.0100891560603, val_loss: 974.4687592220749
Validation loss decreased (1063.843946 --> 1063.675948).  Saving model ...
Epoch 533, train_loss: 1104.4507498908708, val_loss: 968.418494469281
Validation loss decreased (1063.675948 --> 1063.497229).  Saving model ...
Epoch 534, train_loss: 1108.658792239721, val_loss: 980.7110285302007
Validation loss decreased (1063.497229 --> 1063.342198).  Saving model ...
Epoch 535, train_loss: 1108.8558907176248, val_loss: 966.7302861728052
Validation loss decreased (1063.342198 --> 1063.161615).  Saving model ...
Epoch 536, train_loss: 1114.0518305487246, val_loss: 967.8431866223286
Validation loss decreased (1063.161615 --> 1062.983782).  Saving model ...
Epoch 537, train_loss: 1121.051676638425, val_loss: 983.5932164827987
Validation loss decreased (1062.983782 --> 1062.835941).  Saving model ...
Epoch 538, train_loss: 1104.2014965818566, val_loss: 982.1079094605537
Validation loss decreased (1062.835941 --> 1062.685889).  Saving model ...
Epoch 539, train_loss: 1117.1847141956052, val_loss: 974.5044544093257
Validation loss decreased (1062.685889 --> 1062.522287).  Saving model ...
Epoch 540, train_loss: 1105.3829106658316, val_loss: 975.147845780099
Validation loss decreased (1062.522287 --> 1062.360483).  Saving model ...
Epoch 541, train_loss: 1108.452846281751, val_loss: 979.601425780853
Validation loss decreased (1062.360483 --> 1062.207509).  Saving model ...
Epoch 542, train_loss: 1104.844860805864, val_loss: 978.5174496147373
Validation loss decreased (1062.207509 --> 1062.053099).  Saving model ...
Epoch 543, train_loss: 1117.679677769967, val_loss: 972.9283489890895
Validation loss decreased (1062.053099 --> 1061.888965).  Saving model ...
Epoch 544, train_loss: 1106.6819904720503, val_loss: 977.6667950202805
Validation loss decreased (1061.888965 --> 1061.734145).  Saving model ...
Epoch 545, train_loss: 1107.3627394789974, val_loss: 976.0151512509366
Validation loss decreased (1061.734145 --> 1061.576862).  Saving model ...
Epoch 546, train_loss: 1105.3862863090778, val_loss: 971.5536872718072
Validation loss decreased (1061.576862 --> 1061.411985).  Saving model ...
Epoch 547, train_loss: 1105.3747236994482, val_loss: 971.8728549133853
Validation loss decreased (1061.411985 --> 1061.248293).  Saving model ...
Epoch 548, train_loss: 1107.31853420161, val_loss: 979.5968908090505
Validation loss decreased (1061.248293 --> 1061.099294).  Saving model ...
Epoch 549, train_loss: 1101.8885681959287, val_loss: 977.2127790380413
Validation loss decreased (1061.099294 --> 1060.946496).  Saving model ...
Epoch 550, train_loss: 1115.7915570080706, val_loss: 971.1914734506167
Validation loss decreased (1060.946496 --> 1060.783305).  Saving model ...
Epoch 551, train_loss: 1104.411761639776, val_loss: 974.1087475690579
Validation loss decreased (1060.783305 --> 1060.626001).  Saving model ...
Epoch 552, train_loss: 1105.6750194226372, val_loss: 971.8216186558761
Validation loss decreased (1060.626001 --> 1060.465123).  Saving model ...
Epoch 553, train_loss: 1110.592307736486, val_loss: 975.6441493759776
Validation loss decreased (1060.465123 --> 1060.311740).  Saving model ...
Epoch 554, train_loss: 1107.749033102342, val_loss: 970.1968491471698
Validation loss decreased (1060.311740 --> 1060.149078).  Saving model ...
Epoch 555, train_loss: 1100.1019959999405, val_loss: 966.7285619837268
Validation loss decreased (1060.149078 --> 1059.980752).  Saving model ...
Epoch 556, train_loss: 1107.9004677599064, val_loss: 966.7224904956644
Validation loss decreased (1059.980752 --> 1059.813022).  Saving model ...
Epoch 557, train_loss: 1103.9488818536486, val_loss: 968.3439766618059
Validation loss decreased (1059.813022 --> 1059.648804).  Saving model ...
Epoch 558, train_loss: 1102.0761056681904, val_loss: 966.6348655815481
Validation loss decreased (1059.648804 --> 1059.482113).  Saving model ...
Epoch 559, train_loss: 1108.0243759208258, val_loss: 985.2043753600566
Validation loss decreased (1059.482113 --> 1059.349237).  Saving model ...
Epoch 560, train_loss: 1108.9175353566905, val_loss: 965.9132857318281
Validation loss decreased (1059.349237 --> 1059.182387).  Saving model ...
Epoch 561, train_loss: 1104.1085243470138, val_loss: 974.9645417980796
Validation loss decreased (1059.182387 --> 1059.032266).  Saving model ...
Epoch 562, train_loss: 1104.2118873691934, val_loss: 967.7995845608801
Validation loss decreased (1059.032266 --> 1058.869930).  Saving model ...
Epoch 563, train_loss: 1096.562441104617, val_loss: 968.5695343116039
Validation loss decreased (1058.869930 --> 1058.709539).  Saving model ...
Epoch 564, train_loss: 1106.0808838598125, val_loss: 967.3004165078978
Validation loss decreased (1058.709539 --> 1058.547466).  Saving model ...
Epoch 565, train_loss: 1100.5373612719727, val_loss: 962.5648978470877
Validation loss decreased (1058.547466 --> 1058.377585).  Saving model ...
Epoch 566, train_loss: 1104.2685573244714, val_loss: 970.6190553105762
Validation loss decreased (1058.377585 --> 1058.222535).  Saving model ...
Epoch 567, train_loss: 1102.6750240148626, val_loss: 970.4394077059518
Validation loss decreased (1058.222535 --> 1058.067714).  Saving model ...
Epoch 568, train_loss: 1096.8792285164577, val_loss: 972.5421899519588
Validation loss decreased (1058.067714 --> 1057.917141).  Saving model ...
Epoch 569, train_loss: 1109.5717144162543, val_loss: 970.3873899166234
Validation loss decreased (1057.917141 --> 1057.763310).  Saving model ...
Epoch 570, train_loss: 1093.8047612407556, val_loss: 978.634059218257
Validation loss decreased (1057.763310 --> 1057.624487).  Saving model ...
Epoch 571, train_loss: 1107.7287857381175, val_loss: 974.9776964517879
Validation loss decreased (1057.624487 --> 1057.479747).  Saving model ...
Epoch 572, train_loss: 1109.1296663162068, val_loss: 966.0541337359837
Validation loss decreased (1057.479747 --> 1057.319912).  Saving model ...
Epoch 573, train_loss: 1108.4069214372032, val_loss: 970.637553888383
Validation loss decreased (1057.319912 --> 1057.168633).  Saving model ...
Epoch 574, train_loss: 1092.824045275019, val_loss: 979.0369710822021
Validation loss decreased (1057.168633 --> 1057.032516).  Saving model ...
Epoch 575, train_loss: 1106.8215280358797, val_loss: 975.0199041157302
Validation loss decreased (1057.032516 --> 1056.889885).  Saving model ...
Epoch 576, train_loss: 1104.809682995488, val_loss: 964.8092310173867
Validation loss decreased (1056.889885 --> 1056.730023).  Saving model ...
Epoch 577, train_loss: 1099.8022144998542, val_loss: 970.4578151974416
Validation loss decreased (1056.730023 --> 1056.580504).  Saving model ...
Epoch 578, train_loss: 1103.8790728958688, val_loss: 965.432029331084
Validation loss decreased (1056.580504 --> 1056.422808).  Saving model ...
Epoch 579, train_loss: 1098.6246388689065, val_loss: 970.5622183436822
Validation loss decreased (1056.422808 --> 1056.274517).  Saving model ...
Epoch 580, train_loss: 1106.6678655801213, val_loss: 974.2991629758591
Validation loss decreased (1056.274517 --> 1056.133180).  Saving model ...
Epoch 581, train_loss: 1095.222782534512, val_loss: 966.9229275404524
Validation loss decreased (1056.133180 --> 1055.979634).  Saving model ...
Epoch 582, train_loss: 1099.8167845761197, val_loss: 969.7525011300162
Validation loss decreased (1055.979634 --> 1055.831477).  Saving model ...
Epoch 583, train_loss: 1107.1150111167779, val_loss: 962.9216513148504
Validation loss decreased (1055.831477 --> 1055.672112).  Saving model ...
Epoch 584, train_loss: 1101.886483159761, val_loss: 962.9134316157856
Validation loss decreased (1055.672112 --> 1055.513279).  Saving model ...
Epoch 585, train_loss: 1098.3347572954058, val_loss: 975.1926271690267
Validation loss decreased (1055.513279 --> 1055.375979).  Saving model ...
Epoch 586, train_loss: 1106.2783197469378, val_loss: 971.1260112024239
Validation loss decreased (1055.375979 --> 1055.232207).  Saving model ...
Epoch 587, train_loss: 1102.0489818111785, val_loss: 970.6048552192142
Validation loss decreased (1055.232207 --> 1055.088038).  Saving model ...
Epoch 588, train_loss: 1091.064902291979, val_loss: 965.8646818310245
Validation loss decreased (1055.088038 --> 1054.936298).  Saving model ...
Epoch 589, train_loss: 1107.2595917810988, val_loss: 968.6180652662562
Validation loss decreased (1054.936298 --> 1054.789747).  Saving model ...
Epoch 590, train_loss: 1095.4789636914927, val_loss: 977.9444604706769
Validation loss decreased (1054.789747 --> 1054.659501).  Saving model ...
Epoch 591, train_loss: 1097.7362412393193, val_loss: 973.6112834997975
Validation loss decreased (1054.659501 --> 1054.522363).  Saving model ...
Epoch 592, train_loss: 1108.7252220720386, val_loss: 960.9118382309543
Validation loss decreased (1054.522363 --> 1054.364238).  Saving model ...
Epoch 593, train_loss: 1101.6058031443802, val_loss: 974.5544374842119
Validation loss decreased (1054.364238 --> 1054.229651).  Saving model ...
Epoch 594, train_loss: 1105.9159149269879, val_loss: 959.7694078890485
Validation loss decreased (1054.229651 --> 1054.070627).  Saving model ...
Epoch 595, train_loss: 1097.5078844282646, val_loss: 966.0689797065879
Validation loss decreased (1054.070627 --> 1053.922725).  Saving model ...
Epoch 596, train_loss: 1104.7052559320844, val_loss: 966.1685830582073
Validation loss decreased (1053.922725 --> 1053.775487).  Saving model ...
Epoch 597, train_loss: 1101.7727137659228, val_loss: 962.0240524815191
Validation loss decreased (1053.775487 --> 1053.621799).  Saving model ...
Epoch 598, train_loss: 1097.215257879364, val_loss: 961.3900448587209
Validation loss decreased (1053.621799 --> 1053.467565).  Saving model ...
Epoch 599, train_loss: 1100.2261518365092, val_loss: 959.6355657506875
Validation loss decreased (1053.467565 --> 1053.310918).  Saving model ...
Epoch 600, train_loss: 1096.404236668799, val_loss: 972.9662090292687
Validation loss decreased (1053.310918 --> 1053.177010).  Saving model ...
Epoch 601, train_loss: 1108.1363255679269, val_loss: 966.6237892615796
Validation loss decreased (1053.177010 --> 1053.032995).  Saving model ...
Epoch 602, train_loss: 1091.6966645217556, val_loss: 960.7082243715396
Validation loss decreased (1053.032995 --> 1052.879631).  Saving model ...
Epoch 603, train_loss: 1097.6461358302129, val_loss: 973.3812896016353
Validation loss decreased (1052.879631 --> 1052.747793).  Saving model ...
Epoch 604, train_loss: 1100.0140628665592, val_loss: 975.3797333423742
Validation loss decreased (1052.747793 --> 1052.619700).  Saving model ...
Epoch 605, train_loss: 1105.1990602944347, val_loss: 957.5891052645669
Validation loss decreased (1052.619700 --> 1052.462625).  Saving model ...
Epoch 606, train_loss: 1100.8445531472755, val_loss: 956.7536331798415
Validation loss decreased (1052.462625 --> 1052.304689).  Saving model ...
Epoch 607, train_loss: 1087.1820123378009, val_loss: 972.2081428515472
Validation loss decreased (1052.304689 --> 1052.172735).  Saving model ...
Epoch 608, train_loss: 1096.0483514547725, val_loss: 971.3586385896916
Validation loss decreased (1052.172735 --> 1052.039817).  Saving model ...
Epoch 609, train_loss: 1101.8480542192196, val_loss: 963.7713605981406
Validation loss decreased (1052.039817 --> 1051.894877).  Saving model ...
Epoch 610, train_loss: 1103.0673056216797, val_loss: 964.5134194238543
Validation loss decreased (1051.894877 --> 1051.751628).  Saving model ...
Epoch 611, train_loss: 1100.4258114153715, val_loss: 962.6623005225928
Validation loss decreased (1051.751628 --> 1051.605819).  Saving model ...
Epoch 612, train_loss: 1098.3111374939347, val_loss: 969.6365989199394
Validation loss decreased (1051.605819 --> 1051.471883).  Saving model ...
Epoch 613, train_loss: 1102.8589136230091, val_loss: 968.9141450177743
Validation loss decreased (1051.471883 --> 1051.337204).  Saving model ...
Epoch 614, train_loss: 1097.4739847730973, val_loss: 976.3259413613217
Validation loss decreased (1051.337204 --> 1051.215036).  Saving model ...
Epoch 615, train_loss: 1102.1802371319939, val_loss: 960.0469006221828
Validation loss decreased (1051.215036 --> 1051.066795).  Saving model ...
Epoch 616, train_loss: 1103.0537540013495, val_loss: 963.3159689418035
Validation loss decreased (1051.066795 --> 1050.924343).  Saving model ...
Epoch 617, train_loss: 1095.6214458807262, val_loss: 961.2087244535378
Validation loss decreased (1050.924343 --> 1050.778937).  Saving model ...
Epoch 618, train_loss: 1093.3452718504882, val_loss: 959.3704893212852
Validation loss decreased (1050.778937 --> 1050.631026).  Saving model ...
Epoch 619, train_loss: 1096.5529347797753, val_loss: 969.0044968603278
Validation loss decreased (1050.631026 --> 1050.499158).  Saving model ...
Epoch 620, train_loss: 1095.8515441080326, val_loss: 963.9260596941139
Validation loss decreased (1050.499158 --> 1050.359524).  Saving model ...
Epoch 621, train_loss: 1101.2191366441434, val_loss: 958.8365086272032
Validation loss decreased (1050.359524 --> 1050.212144).  Saving model ...
Epoch 622, train_loss: 1091.2974350180898, val_loss: 959.3442259054717
Validation loss decreased (1050.212144 --> 1050.066054).  Saving model ...
Epoch 623, train_loss: 1095.8970803030666, val_loss: 968.1979304702196
Validation loss decreased (1050.066054 --> 1049.934645).  Saving model ...
Epoch 624, train_loss: 1089.8384977479075, val_loss: 974.7473365748373
Validation loss decreased (1049.934645 --> 1049.814152).  Saving model ...
Epoch 625, train_loss: 1102.003681205115, val_loss: 966.1773841282176
Validation loss decreased (1049.814152 --> 1049.680333).  Saving model ...
Epoch 626, train_loss: 1096.6518874479427, val_loss: 966.4906003868142
Validation loss decreased (1049.680333 --> 1049.547442).  Saving model ...
Epoch 627, train_loss: 1095.2238378364277, val_loss: 955.0486599779132
Validation loss decreased (1049.547442 --> 1049.396727).  Saving model ...
Epoch 628, train_loss: 1091.6367642664436, val_loss: 957.8969159147479
Validation loss decreased (1049.396727 --> 1049.251026).  Saving model ...
Epoch 629, train_loss: 1096.8779543645192, val_loss: 964.0058004303336
Validation loss decreased (1049.251026 --> 1049.115501).  Saving model ...
Epoch 630, train_loss: 1101.4407953966233, val_loss: 952.0913013163764
Validation loss decreased (1049.115501 --> 1048.961495).  Saving model ...
Epoch 631, train_loss: 1097.9491473544408, val_loss: 953.0322554684572
Validation loss decreased (1048.961495 --> 1048.809467).  Saving model ...
Epoch 632, train_loss: 1096.6145185658202, val_loss: 956.3404890879441
Validation loss decreased (1048.809467 --> 1048.663156).  Saving model ...
Epoch 633, train_loss: 1091.2809837485834, val_loss: 963.0325672769108
Validation loss decreased (1048.663156 --> 1048.527878).  Saving model ...
Epoch 634, train_loss: 1090.7639513280285, val_loss: 958.4026366258113
Validation loss decreased (1048.527878 --> 1048.385725).  Saving model ...
Epoch 635, train_loss: 1094.259890752894, val_loss: 954.2016706730705
Validation loss decreased (1048.385725 --> 1048.237403).  Saving model ...
Epoch 636, train_loss: 1098.1788312660613, val_loss: 952.5105758716887
Validation loss decreased (1048.237403 --> 1048.086890).  Saving model ...
Epoch 637, train_loss: 1082.2264457703345, val_loss: 970.3098248978458
Validation loss decreased (1048.086890 --> 1047.964791).  Saving model ...
Epoch 638, train_loss: 1097.1943552444802, val_loss: 959.2054548086065
Validation loss decreased (1047.964791 --> 1047.825669).  Saving model ...
Epoch 639, train_loss: 1099.5664823478464, val_loss: 960.0738290403953
Validation loss decreased (1047.825669 --> 1047.688342).  Saving model ...
Epoch 640, train_loss: 1100.2510983653906, val_loss: 964.4728505422896
Validation loss decreased (1047.688342 --> 1047.558318).  Saving model ...
Epoch 641, train_loss: 1097.6382495114685, val_loss: 959.5637915619218
Validation loss decreased (1047.558318 --> 1047.421041).  Saving model ...
Epoch 642, train_loss: 1083.8354757111981, val_loss: 960.3346570627781
Validation loss decreased (1047.421041 --> 1047.285393).  Saving model ...
Epoch 643, train_loss: 1099.4670347779327, val_loss: 952.7554728488572
Validation loss decreased (1047.285393 --> 1047.138379).  Saving model ...
Epoch 644, train_loss: 1089.5132946302735, val_loss: 959.7054884344562
Validation loss decreased (1047.138379 --> 1047.002614).  Saving model ...
Epoch 645, train_loss: 1093.8784499763692, val_loss: 963.9184360547423
Validation loss decreased (1047.002614 --> 1046.873801).  Saving model ...
Epoch 646, train_loss: 1097.1889512996079, val_loss: 956.6570767714361
Validation loss decreased (1046.873801 --> 1046.734146).  Saving model ...
Epoch 647, train_loss: 1089.7416187803565, val_loss: 955.9971354944179
Validation loss decreased (1046.734146 --> 1046.593904).  Saving model ...
Epoch 648, train_loss: 1092.8011816394944, val_loss: 952.4319274733689
Validation loss decreased (1046.593904 --> 1046.448592).  Saving model ...
Epoch 649, train_loss: 1086.2870886269068, val_loss: 962.6150735361933
Validation loss decreased (1046.448592 --> 1046.319419).  Saving model ...
Epoch 650, train_loss: 1092.4722810107385, val_loss: 954.0212228043437
Validation loss decreased (1046.319419 --> 1046.177422).  Saving model ...
Epoch 651, train_loss: 1095.3897427060442, val_loss: 964.2499039117057
Validation loss decreased (1046.177422 --> 1046.051573).  Saving model ...
Epoch 652, train_loss: 1095.2683988366714, val_loss: 954.8689084767416
Validation loss decreased (1046.051573 --> 1045.911722).  Saving model ...
Epoch 653, train_loss: 1084.0492660940456, val_loss: 960.6004860942454
Validation loss decreased (1045.911722 --> 1045.781077).  Saving model ...
Epoch 654, train_loss: 1097.5960631247601, val_loss: 952.2483129157405
Validation loss decreased (1045.781077 --> 1045.638061).  Saving model ...
Epoch 655, train_loss: 1094.8108093791059, val_loss: 959.7385296378316
Validation loss decreased (1045.638061 --> 1045.506916).  Saving model ...
Epoch 656, train_loss: 1086.0393079898708, val_loss: 950.7965583713411
Validation loss decreased (1045.506916 --> 1045.362541).  Saving model ...
Epoch 657, train_loss: 1092.1909869179747, val_loss: 953.9445489390254
Validation loss decreased (1045.362541 --> 1045.223396).  Saving model ...
Epoch 658, train_loss: 1096.6555654277502, val_loss: 953.719430105598
Validation loss decreased (1045.223396 --> 1045.084332).  Saving model ...
Epoch 659, train_loss: 1091.811940909071, val_loss: 951.4525775225519
Validation loss decreased (1045.084332 --> 1044.942251).  Saving model ...
Epoch 660, train_loss: 1096.3795305374363, val_loss: 952.8347228898386
Validation loss decreased (1044.942251 --> 1044.802694).  Saving model ...
Epoch 661, train_loss: 1088.9606969710433, val_loss: 958.2600856407929
Validation loss decreased (1044.802694 --> 1044.671767).  Saving model ...
Epoch 662, train_loss: 1094.854005544275, val_loss: 958.2002491240152
Validation loss decreased (1044.671767 --> 1044.541145).  Saving model ...
Epoch 663, train_loss: 1090.1494290721944, val_loss: 957.140168468202
Validation loss decreased (1044.541145 --> 1044.409319).  Saving model ...
Epoch 664, train_loss: 1093.0848138614167, val_loss: 956.1714196587054
Validation loss decreased (1044.409319 --> 1044.276431).  Saving model ...
Epoch 665, train_loss: 1094.3339050863372, val_loss: 957.3858762526073
Validation loss decreased (1044.276431 --> 1044.145768).  Saving model ...
Epoch 666, train_loss: 1080.5738821594873, val_loss: 961.8182206060272
Validation loss decreased (1044.145768 --> 1044.022153).  Saving model ...
Epoch 667, train_loss: 1096.3674475633818, val_loss: 952.7072657214716
Validation loss decreased (1044.022153 --> 1043.885249).  Saving model ...
Epoch 668, train_loss: 1088.0327378276647, val_loss: 952.6947885321689
Validation loss decreased (1043.885249 --> 1043.748737).  Saving model ...
Epoch 669, train_loss: 1088.1242954901147, val_loss: 964.2437461398268
Validation loss decreased (1043.748737 --> 1043.629895).  Saving model ...
Epoch 670, train_loss: 1087.0384709591547, val_loss: 964.950995536204
Validation loss decreased (1043.629895 --> 1043.512464).  Saving model ...
Epoch 671, train_loss: 1095.7864550586871, val_loss: 961.226598057394
Validation loss decreased (1043.512464 --> 1043.389832).  Saving model ...
Epoch 672, train_loss: 1087.7093475883726, val_loss: 962.7133156755681
Validation loss decreased (1043.389832 --> 1043.269778).  Saving model ...
Epoch 673, train_loss: 1097.2471570684327, val_loss: 960.7666887904983
Validation loss decreased (1043.269778 --> 1043.147188).  Saving model ...
Epoch 674, train_loss: 1092.2660417359589, val_loss: 952.867326776231
Validation loss decreased (1043.147188 --> 1043.013241).  Saving model ...
Epoch 675, train_loss: 1085.1544986838258, val_loss: 952.7530837887308
Validation loss decreased (1043.013241 --> 1042.879523).  Saving model ...
Epoch 676, train_loss: 1091.1677856859926, val_loss: 952.3148691422853
Validation loss decreased (1042.879523 --> 1042.745551).  Saving model ...
Epoch 677, train_loss: 1090.2443327570388, val_loss: 957.4730232169455
Validation loss decreased (1042.745551 --> 1042.619595).  Saving model ...
Epoch 678, train_loss: 1095.052093932936, val_loss: 953.1556877606007
Validation loss decreased (1042.619595 --> 1042.487642).  Saving model ...
Epoch 679, train_loss: 1086.880180297191, val_loss: 953.302372066975
Validation loss decreased (1042.487642 --> 1042.356294).  Saving model ...
Epoch 680, train_loss: 1087.333656135623, val_loss: 948.839300865421
Validation loss decreased (1042.356294 --> 1042.218769).  Saving model ...
Epoch 681, train_loss: 1085.4759523606685, val_loss: 954.2850975779696
Validation loss decreased (1042.218769 --> 1042.089645).  Saving model ...
Epoch 682, train_loss: 1090.2672258622829, val_loss: 955.6766023382435
Validation loss decreased (1042.089645 --> 1041.962940).  Saving model ...
Epoch 683, train_loss: 1085.002944275463, val_loss: 949.8986578098494
Validation loss decreased (1041.962940 --> 1041.828146).  Saving model ...
Epoch 684, train_loss: 1084.2017189318663, val_loss: 958.4786416887358
Validation loss decreased (1041.828146 --> 1041.706290).  Saving model ...
Epoch 685, train_loss: 1087.547829786914, val_loss: 965.9436798701907
Validation loss decreased (1041.706290 --> 1041.595687).  Saving model ...
Epoch 686, train_loss: 1090.5622085642249, val_loss: 957.853036108856
Validation loss decreased (1041.595687 --> 1041.473613).  Saving model ...
Epoch 687, train_loss: 1095.6521074983382, val_loss: 952.9584049914062
Validation loss decreased (1041.473613 --> 1041.344770).  Saving model ...
Epoch 688, train_loss: 1085.7690525958853, val_loss: 948.4786059889974
Validation loss decreased (1041.344770 --> 1041.209790).  Saving model ...
Epoch 689, train_loss: 1085.1549640301769, val_loss: 949.1340266596834
Validation loss decreased (1041.209790 --> 1041.076154).  Saving model ...
Epoch 690, train_loss: 1087.714474328629, val_loss: 954.4955806699509
Validation loss decreased (1041.076154 --> 1040.950674).  Saving model ...
Epoch 691, train_loss: 1087.5655084457192, val_loss: 958.2718057167975
Validation loss decreased (1040.950674 --> 1040.831023).  Saving model ...
Epoch 692, train_loss: 1085.319342680177, val_loss: 957.0111137871833
Validation loss decreased (1040.831023 --> 1040.709896).  Saving model ...
Epoch 693, train_loss: 1090.4855036622855, val_loss: 951.889326998658
Validation loss decreased (1040.709896 --> 1040.581728).  Saving model ...
Epoch 694, train_loss: 1085.0993773195858, val_loss: 948.5694601812189
Validation loss decreased (1040.581728 --> 1040.449146).  Saving model ...
Epoch 695, train_loss: 1087.4747135203654, val_loss: 950.2111706921793
Validation loss decreased (1040.449146 --> 1040.319307).  Saving model ...
Epoch 696, train_loss: 1082.6998269645826, val_loss: 954.1410390039731
Validation loss decreased (1040.319307 --> 1040.195488).  Saving model ...
Epoch 697, train_loss: 1080.6317748956644, val_loss: 959.8795243596592
Validation loss decreased (1040.195488 --> 1040.080257).  Saving model ...
Epoch 698, train_loss: 1093.9868072858264, val_loss: 943.160911445309
Validation loss decreased (1040.080257 --> 1039.941404).  Saving model ...
Epoch 699, train_loss: 1086.2973118752568, val_loss: 956.2224958604356
Validation loss decreased (1039.941404 --> 1039.821634).  Saving model ...
Epoch 700, train_loss: 1086.3412788016033, val_loss: 947.8653102240302
Validation loss decreased (1039.821634 --> 1039.690268).  Saving model ...
Epoch 701, train_loss: 1090.348752100184, val_loss: 945.2399336618852
Validation loss decreased (1039.690268 --> 1039.555531).  Saving model ...
Epoch 702, train_loss: 1090.1271299489486, val_loss: 946.7928146542448
Validation loss decreased (1039.555531 --> 1039.423391).  Saving model ...
Epoch 703, train_loss: 1087.6523721422757, val_loss: 946.6431835327327
Validation loss decreased (1039.423391 --> 1039.291413).  Saving model ...
Epoch 704, train_loss: 1090.0947888442406, val_loss: 949.3180511704642
Validation loss decreased (1039.291413 --> 1039.163610).  Saving model ...
Epoch 705, train_loss: 1086.1859586279588, val_loss: 952.7172440456465
Validation loss decreased (1039.163610 --> 1039.040991).  Saving model ...
Epoch 706, train_loss: 1082.4896754178033, val_loss: 956.15220039743
Validation loss decreased (1039.040991 --> 1038.923585).  Saving model ...
Epoch 707, train_loss: 1091.392984310569, val_loss: 949.5528392935685
Validation loss decreased (1038.923585 --> 1038.797177).  Saving model ...
Epoch 708, train_loss: 1088.6767278066663, val_loss: 955.455079434139
Validation loss decreased (1038.797177 --> 1038.679462).  Saving model ...
Epoch 709, train_loss: 1093.7930842756375, val_loss: 955.892863814522
Validation loss decreased (1038.679462 --> 1038.562696).  Saving model ...
Epoch 710, train_loss: 1079.4402229273512, val_loss: 965.0085503973346
Validation loss decreased (1038.562696 --> 1038.459099).  Saving model ...
Epoch 711, train_loss: 1081.3637798520929, val_loss: 957.7901181872248
Validation loss decreased (1038.459099 --> 1038.345641).  Saving model ...
Epoch 712, train_loss: 1085.620075591278, val_loss: 962.1970598649099
Validation loss decreased (1038.345641 --> 1038.238690).  Saving model ...
Epoch 713, train_loss: 1088.6403924366227, val_loss: 954.239452327755
Validation loss decreased (1038.238690 --> 1038.120879).  Saving model ...
Epoch 714, train_loss: 1088.6231259709841, val_loss: 938.3380717537583
Validation loss decreased (1038.120879 --> 1037.981127).  Saving model ...
Epoch 715, train_loss: 1081.8511912305344, val_loss: 952.5255387432048
Validation loss decreased (1037.981127 --> 1037.861609).  Saving model ...
Epoch 716, train_loss: 1097.6263840779707, val_loss: 943.8056811824554
Validation loss decreased (1037.861609 --> 1037.730246).  Saving model ...
Epoch 717, train_loss: 1084.9899841227964, val_loss: 948.6759839578473
Validation loss decreased (1037.730246 --> 1037.606042).  Saving model ...
Epoch 718, train_loss: 1073.223147550675, val_loss: 942.267723826391
Validation loss decreased (1037.606042 --> 1037.473259).  Saving model ...
Epoch 719, train_loss: 1083.220003491607, val_loss: 949.4134888975713
Validation loss decreased (1037.473259 --> 1037.350784).  Saving model ...
Epoch 720, train_loss: 1080.2672093291806, val_loss: 966.9851988203881
Validation loss decreased (1037.350784 --> 1037.253054).  Saving model ...
Epoch 721, train_loss: 1080.8445839014325, val_loss: 963.5939969835462
Validation loss decreased (1037.253054 --> 1037.150891).  Saving model ...
Epoch 722, train_loss: 1090.153581942907, val_loss: 950.8649248118314
Validation loss decreased (1037.150891 --> 1037.031382).  Saving model ...
Epoch 723, train_loss: 1078.5539843907059, val_loss: 939.1109650512095
Validation loss decreased (1037.031382 --> 1036.895945).  Saving model ...
Epoch 724, train_loss: 1082.5126508970259, val_loss: 955.4414740512108
Validation loss decreased (1036.895945 --> 1036.783439).  Saving model ...
Epoch 725, train_loss: 1077.1409339006411, val_loss: 948.2940298053073
Validation loss decreased (1036.783439 --> 1036.661385).  Saving model ...
Epoch 726, train_loss: 1090.7819261195884, val_loss: 948.5152462003853
Validation loss decreased (1036.661385 --> 1036.539971).  Saving model ...
Epoch 727, train_loss: 1084.6564996986783, val_loss: 943.1324099689064
Validation loss decreased (1036.539971 --> 1036.411488).  Saving model ...
Epoch 728, train_loss: 1085.2594561176177, val_loss: 949.6457738858244
Validation loss decreased (1036.411488 --> 1036.292304).  Saving model ...
Epoch 729, train_loss: 1080.4811630172064, val_loss: 953.4666401897539
Validation loss decreased (1036.292304 --> 1036.178689).  Saving model ...
Epoch 730, train_loss: 1076.3645064944455, val_loss: 938.8986961245981
Validation loss decreased (1036.178689 --> 1036.045428).  Saving model ...
Epoch 731, train_loss: 1081.330563054969, val_loss: 954.5904701005534
Validation loss decreased (1036.045428 --> 1035.933999).  Saving model ...
Epoch 732, train_loss: 1083.8452664404542, val_loss: 939.7357285453659
Validation loss decreased (1035.933999 --> 1035.802581).  Saving model ...
Epoch 733, train_loss: 1076.610711370328, val_loss: 959.5009925504529
Validation loss decreased (1035.802581 --> 1035.698486).  Saving model ...
Epoch 734, train_loss: 1078.8295687933344, val_loss: 961.5858504988531
Validation loss decreased (1035.698486 --> 1035.597515).  Saving model ...
Epoch 735, train_loss: 1084.0931604350046, val_loss: 947.492774674981
Validation loss decreased (1035.597515 --> 1035.477644).  Saving model ...
Epoch 736, train_loss: 1083.0642123246344, val_loss: 948.9025250372183
Validation loss decreased (1035.477644 --> 1035.360015).  Saving model ...
Epoch 737, train_loss: 1082.9527248488114, val_loss: 956.6817814651686
Validation loss decreased (1035.360015 --> 1035.253260).  Saving model ...
Epoch 738, train_loss: 1074.7256822985742, val_loss: 948.4985187369367
Validation loss decreased (1035.253260 --> 1035.135707).  Saving model ...
Epoch 739, train_loss: 1090.5797082539777, val_loss: 946.878086393542
Validation loss decreased (1035.135707 --> 1035.016278).  Saving model ...
Epoch 740, train_loss: 1085.369161363491, val_loss: 944.3302941522778
Validation loss decreased (1035.016278 --> 1034.893729).  Saving model ...
Epoch 741, train_loss: 1079.6376308047386, val_loss: 954.4899698049936
Validation loss decreased (1034.893729 --> 1034.785222).  Saving model ...
Epoch 742, train_loss: 1071.805118295811, val_loss: 956.5767934711779
Validation loss decreased (1034.785222 --> 1034.679820).  Saving model ...
Epoch 743, train_loss: 1081.905035292724, val_loss: 943.0945302117315
Validation loss decreased (1034.679820 --> 1034.556556).  Saving model ...
Epoch 744, train_loss: 1076.0604885013288, val_loss: 947.9616238595381
Validation loss decreased (1034.556556 --> 1034.440165).  Saving model ...
Epoch 745, train_loss: 1089.0584195721015, val_loss: 937.3615525896463
Validation loss decreased (1034.440165 --> 1034.309858).  Saving model ...
Epoch 746, train_loss: 1080.3275171845542, val_loss: 943.8564986542864
Validation loss decreased (1034.309858 --> 1034.188607).  Saving model ...
Epoch 747, train_loss: 1085.2460162359096, val_loss: 938.740096905894
Validation loss decreased (1034.188607 --> 1034.060831).  Saving model ...
Epoch 748, train_loss: 1080.230375289105, val_loss: 940.4339069338199
Validation loss decreased (1034.060831 --> 1033.935661).  Saving model ...
Epoch 749, train_loss: 1073.6396945464237, val_loss: 954.2639625708266
Validation loss decreased (1033.935661 --> 1033.829291).  Saving model ...
Epoch 750, train_loss: 1084.9044779207404, val_loss: 939.929323469224
Validation loss decreased (1033.829291 --> 1033.704091).  Saving model ...
Epoch 751, train_loss: 1079.5108640251558, val_loss: 942.8309501365824
Validation loss decreased (1033.704091 --> 1033.583088).  Saving model ...
Epoch 752, train_loss: 1078.9831246372303, val_loss: 947.3553602250862
Validation loss decreased (1033.583088 --> 1033.468423).  Saving model ...
Epoch 753, train_loss: 1080.2557975412947, val_loss: 952.8855426678396
Validation loss decreased (1033.468423 --> 1033.361408).  Saving model ...
Epoch 754, train_loss: 1081.2781123397044, val_loss: 955.5809903154994
Validation loss decreased (1033.361408 --> 1033.258251).  Saving model ...
Epoch 755, train_loss: 1078.8944787611188, val_loss: 942.5657975278078
Validation loss decreased (1033.258251 --> 1033.138128).  Saving model ...
Epoch 756, train_loss: 1085.9071803581098, val_loss: 947.3405928939806
Validation loss decreased (1033.138128 --> 1033.024639).  Saving model ...
Epoch 757, train_loss: 1079.9455676953753, val_loss: 958.742293110159
Validation loss decreased (1033.024639 --> 1032.926512).  Saving model ...
Epoch 758, train_loss: 1083.4716687481557, val_loss: 947.066538522332
Validation loss decreased (1032.926512 --> 1032.813240).  Saving model ...
Epoch 759, train_loss: 1078.4371407757585, val_loss: 947.9730166248925
Validation loss decreased (1032.813240 --> 1032.701461).  Saving model ...
Epoch 760, train_loss: 1082.106003822869, val_loss: 949.217835287165
Validation loss decreased (1032.701461 --> 1032.591614).  Saving model ...
Epoch 761, train_loss: 1076.1835405496947, val_loss: 942.9418545838199
Validation loss decreased (1032.591614 --> 1032.473809).  Saving model ...
Epoch 762, train_loss: 1088.8725728177183, val_loss: 940.2092090007995
Validation loss decreased (1032.473809 --> 1032.352727).  Saving model ...
Epoch 763, train_loss: 1076.5923617989868, val_loss: 952.0901907855937
Validation loss decreased (1032.352727 --> 1032.247534).  Saving model ...
Epoch 764, train_loss: 1078.762661306802, val_loss: 950.6083982793493
Validation loss decreased (1032.247534 --> 1032.140676).  Saving model ...
Epoch 765, train_loss: 1084.5487596595058, val_loss: 944.3463362809025
Validation loss decreased (1032.140676 --> 1032.025912).  Saving model ...
Epoch 766, train_loss: 1082.058476707363, val_loss: 942.9960943482984
Validation loss decreased (1032.025912 --> 1031.909685).  Saving model ...
Epoch 767, train_loss: 1069.2930444714664, val_loss: 957.798772672371
Validation loss decreased (1031.909685 --> 1031.813061).  Saving model ...
Epoch 768, train_loss: 1079.3463685656454, val_loss: 956.4971915777087
Validation loss decreased (1031.813061 --> 1031.714994).  Saving model ...
Epoch 769, train_loss: 1071.135763029494, val_loss: 956.9137170837988
Validation loss decreased (1031.714994 --> 1031.617723).  Saving model ...
Epoch 770, train_loss: 1081.9098175897154, val_loss: 945.0650485278502
Validation loss decreased (1031.617723 --> 1031.505317).  Saving model ...
Epoch 771, train_loss: 1079.1141553099674, val_loss: 946.495994438772
Validation loss decreased (1031.505317 --> 1031.395058).  Saving model ...
Epoch 772, train_loss: 1076.6543059432183, val_loss: 948.6412000688362
Validation loss decreased (1031.395058 --> 1031.287864).  Saving model ...
Epoch 773, train_loss: 1076.0491254381247, val_loss: 946.3916366133868
Validation loss decreased (1031.287864 --> 1031.178037).  Saving model ...
Epoch 774, train_loss: 1075.618580333965, val_loss: 954.6903598635287
Validation loss decreased (1031.178037 --> 1031.079216).  Saving model ...
Epoch 775, train_loss: 1086.1562795743782, val_loss: 952.6355295652816
Validation loss decreased (1031.079216 --> 1030.977998).  Saving model ...
Epoch 776, train_loss: 1077.5249081758282, val_loss: 953.2114211805664
Validation loss decreased (1030.977998 --> 1030.877783).  Saving model ...
Epoch 777, train_loss: 1076.617480760268, val_loss: 945.4506572649658
Validation loss decreased (1030.877783 --> 1030.767839).  Saving model ...
Epoch 778, train_loss: 1084.2612236434497, val_loss: 948.1032144668369
Validation loss decreased (1030.767839 --> 1030.661586).  Saving model ...
Epoch 779, train_loss: 1079.1292656878395, val_loss: 954.5370447003403
Validation loss decreased (1030.661586 --> 1030.563865).  Saving model ...
Epoch 780, train_loss: 1080.4383404565099, val_loss: 959.5376348281352
Validation loss decreased (1030.563865 --> 1030.472806).  Saving model ...
Epoch 781, train_loss: 1076.0797972575633, val_loss: 952.7178830956091
Validation loss decreased (1030.472806 --> 1030.373248).  Saving model ...
Epoch 782, train_loss: 1077.8509229058225, val_loss: 952.7493329750172
Validation loss decreased (1030.373248 --> 1030.273984).  Saving model ...
Epoch 783, train_loss: 1078.200110339419, val_loss: 949.635574563477
Validation loss decreased (1030.273984 --> 1030.170998).  Saving model ...
Epoch 784, train_loss: 1076.7432444007864, val_loss: 948.7907679596657
Validation loss decreased (1030.170998 --> 1030.067196).  Saving model ...
Epoch 785, train_loss: 1071.026890771905, val_loss: 951.3128165160288
Validation loss decreased (1030.067196 --> 1029.966872).  Saving model ...
Epoch 786, train_loss: 1075.7504732590592, val_loss: 955.3786514562593
Validation loss decreased (1029.966872 --> 1029.871976).  Saving model ...
Epoch 787, train_loss: 1081.9934769736071, val_loss: 955.324480500045
Validation loss decreased (1029.871976 --> 1029.777253).  Saving model ...
Epoch 788, train_loss: 1082.8896934667284, val_loss: 948.887282240965
Validation loss decreased (1029.777253 --> 1029.674601).  Saving model ...
Epoch 789, train_loss: 1081.5204100665976, val_loss: 957.0729313620818
Validation loss decreased (1029.674601 --> 1029.582583).  Saving model ...
Epoch 790, train_loss: 1073.6418956638706, val_loss: 950.3373769539377
Validation loss decreased (1029.582583 --> 1029.482273).  Saving model ...
Epoch 791, train_loss: 1076.1085471862139, val_loss: 957.9443333210771
Validation loss decreased (1029.482273 --> 1029.391833).  Saving model ...
Epoch 792, train_loss: 1082.0169619786034, val_loss: 952.7124510580966
Validation loss decreased (1029.391833 --> 1029.295016).  Saving model ...
Epoch 793, train_loss: 1077.6336261507397, val_loss: 953.1943858669869
Validation loss decreased (1029.295016 --> 1029.199050).  Saving model ...
Epoch 794, train_loss: 1080.8916568654533, val_loss: 941.7266580593147
Validation loss decreased (1029.199050 --> 1029.088883).  Saving model ...
Epoch 795, train_loss: 1072.356137592164, val_loss: 958.2678797716568
Validation loss decreased (1029.088883 --> 1028.999800).  Saving model ...
Epoch 796, train_loss: 1087.9270379975826, val_loss: 942.9485472045125
Validation loss decreased (1028.999800 --> 1028.891696).  Saving model ...
Epoch 797, train_loss: 1073.4409361531486, val_loss: 949.415442825512
Validation loss decreased (1028.891696 --> 1028.791977).  Saving model ...
Epoch 798, train_loss: 1078.1870173665, val_loss: 953.2202103767573
Validation loss decreased (1028.791977 --> 1028.697275).  Saving model ...
Epoch 799, train_loss: 1078.7058768024144, val_loss: 961.2383143931852
Validation loss decreased (1028.697275 --> 1028.612846).  Saving model ...
Epoch 800, train_loss: 1077.67166889012, val_loss: 953.5800263115656
Validation loss decreased (1028.612846 --> 1028.519055).  Saving model ...
Epoch 801, train_loss: 1069.7025382579889, val_loss: 958.1661920565148
Validation loss decreased (1028.519055 --> 1028.431223).  Saving model ...
Epoch 802, train_loss: 1088.80917906589, val_loss: 946.6807017997904
Validation loss decreased (1028.431223 --> 1028.329290).  Saving model ...
Epoch 803, train_loss: 1075.3099959143287, val_loss: 948.2674763015467
Validation loss decreased (1028.329290 --> 1028.229587).  Saving model ...
Epoch 804, train_loss: 1077.6930366916604, val_loss: 954.3280691787053
Validation loss decreased (1028.229587 --> 1028.137669).  Saving model ...
Epoch 805, train_loss: 1067.7607687288385, val_loss: 960.2422357605565
Validation loss decreased (1028.137669 --> 1028.053327).  Saving model ...
Epoch 806, train_loss: 1078.7913915098384, val_loss: 950.1427267725381
Validation loss decreased (1028.053327 --> 1027.956664).  Saving model ...
Epoch 807, train_loss: 1074.8424496703688, val_loss: 946.7663278139963
Validation loss decreased (1027.956664 --> 1027.856056).  Saving model ...
Epoch 808, train_loss: 1073.669122318535, val_loss: 960.9124254690278
Validation loss decreased (1027.856056 --> 1027.773205).  Saving model ...
Epoch 809, train_loss: 1070.0732775557233, val_loss: 964.2399429321291
Validation loss decreased (1027.773205 --> 1027.694672).  Saving model ...
Epoch 810, train_loss: 1078.1601965008138, val_loss: 961.304768418383
Validation loss decreased (1027.694672 --> 1027.612710).  Saving model ...
Epoch 811, train_loss: 1083.2809228869332, val_loss: 948.2448160922531
Validation loss decreased (1027.612710 --> 1027.514845).  Saving model ...
Epoch 812, train_loss: 1075.9284935580367, val_loss: 954.6467923441643
Validation loss decreased (1027.514845 --> 1027.425106).  Saving model ...
Epoch 813, train_loss: 1072.8714967443452, val_loss: 956.9369941923356
Validation loss decreased (1027.425106 --> 1027.338405).  Saving model ...
Epoch 814, train_loss: 1079.9045246013195, val_loss: 958.3100548858116
Validation loss decreased (1027.338405 --> 1027.253604).  Saving model ...
Epoch 815, train_loss: 1080.659005833273, val_loss: 959.1781698615467
Validation loss decreased (1027.253604 --> 1027.170075).  Saving model ...
Epoch 816, train_loss: 1076.7431349625754, val_loss: 958.3250857831375
Validation loss decreased (1027.170075 --> 1027.085707).  Saving model ...
Epoch 817, train_loss: 1071.4958143857314, val_loss: 959.494327055746
Validation loss decreased (1027.085707 --> 1027.002975).  Saving model ...
Epoch 818, train_loss: 1078.574623612629, val_loss: 960.8561102026042
Validation loss decreased (1027.002975 --> 1026.922111).  Saving model ...
Epoch 819, train_loss: 1076.488201650495, val_loss: 948.7814686552687
Validation loss decreased (1026.922111 --> 1026.826701).  Saving model ...
Epoch 820, train_loss: 1077.8530850507766, val_loss: 948.2254491435821
Validation loss decreased (1026.826701 --> 1026.730846).  Saving model ...
Epoch 821, train_loss: 1067.4653045978673, val_loss: 963.7214913441079
Validation loss decreased (1026.730846 --> 1026.654099).  Saving model ...
Epoch 822, train_loss: 1075.0354051631648, val_loss: 951.1467734290937
Validation loss decreased (1026.654099 --> 1026.562241).  Saving model ...
Epoch 823, train_loss: 1074.949593038332, val_loss: 960.4830721590257
Validation loss decreased (1026.562241 --> 1026.481951).  Saving model ...
Epoch 824, train_loss: 1069.7108250654362, val_loss: 959.7051958448361
Validation loss decreased (1026.481951 --> 1026.400911).  Saving model ...
Epoch 825, train_loss: 1070.1668251825615, val_loss: 959.0951661950133
Validation loss decreased (1026.400911 --> 1026.319328).  Saving model ...
Epoch 826, train_loss: 1081.7736699598086, val_loss: 954.8174035213614
Validation loss decreased (1026.319328 --> 1026.232764).  Saving model ...
Epoch 827, train_loss: 1079.4939878124383, val_loss: 949.6273715729627
Validation loss decreased (1026.232764 --> 1026.140134).  Saving model ...
Epoch 828, train_loss: 1074.790851805991, val_loss: 956.3751182862126
Validation loss decreased (1026.140134 --> 1026.055876).  Saving model ...
Epoch 829, train_loss: 1074.6202512102277, val_loss: 945.9111955318631
Validation loss decreased (1026.055876 --> 1025.959200).  Saving model ...
Epoch 830, train_loss: 1075.3650615104411, val_loss: 948.9234602506294
Validation loss decreased (1025.959200 --> 1025.866386).  Saving model ...
Epoch 831, train_loss: 1069.4457007721398, val_loss: 955.1524595637237
Validation loss decreased (1025.866386 --> 1025.781291).  Saving model ...
Epoch 832, train_loss: 1071.1503487067146, val_loss: 961.1000347960882
Validation loss decreased (1025.781291 --> 1025.703549).  Saving model ...
Epoch 833, train_loss: 1076.1057650725986, val_loss: 959.0700679237538
Validation loss decreased (1025.703549 --> 1025.623557).  Saving model ...
Epoch 834, train_loss: 1072.947625313789, val_loss: 950.1783142606861
Validation loss decreased (1025.623557 --> 1025.533095).  Saving model ...
Epoch 835, train_loss: 1062.5146394413196, val_loss: 952.7438930501763
Validation loss decreased (1025.533095 --> 1025.445922).  Saving model ...
Epoch 836, train_loss: 1076.2476470164324, val_loss: 962.4563398689256
Validation loss decreased (1025.445922 --> 1025.370576).  Saving model ...
Epoch 837, train_loss: 1074.0942745080733, val_loss: 957.7730467201827
Validation loss decreased (1025.370576 --> 1025.289814).  Saving model ...
Epoch 838, train_loss: 1069.5710601576795, val_loss: 961.6351969503918
Validation loss decreased (1025.289814 --> 1025.213854).  Saving model ...
Epoch 839, train_loss: 1071.7243883796677, val_loss: 961.3626431716153
Validation loss decreased (1025.213854 --> 1025.137750).  Saving model ...
Epoch 840, train_loss: 1066.3740720318094, val_loss: 962.1095405017892
Validation loss decreased (1025.137750 --> 1025.062716).  Saving model ...
Epoch 841, train_loss: 1079.132376934405, val_loss: 951.869103493205
Validation loss decreased (1025.062716 --> 1024.975685).  Saving model ...
Epoch 842, train_loss: 1074.3025743602996, val_loss: 954.6291481330662
Validation loss decreased (1024.975685 --> 1024.892138).  Saving model ...
Epoch 843, train_loss: 1069.3606717440775, val_loss: 954.3491193762976
Validation loss decreased (1024.892138 --> 1024.808457).  Saving model ...
Epoch 844, train_loss: 1062.5280077238178, val_loss: 951.6585576301595
Validation loss decreased (1024.808457 --> 1024.721786).  Saving model ...
Epoch 845, train_loss: 1077.4362298060698, val_loss: 952.0847759357649
Validation loss decreased (1024.721786 --> 1024.635825).  Saving model ...
Epoch 846, train_loss: 1065.161517851617, val_loss: 962.1519607756318
Validation loss decreased (1024.635825 --> 1024.561967).  Saving model ...
Epoch 847, train_loss: 1072.780729288715, val_loss: 950.5566217556267
Validation loss decreased (1024.561967 --> 1024.474594).  Saving model ...
Epoch 848, train_loss: 1070.8434134588454, val_loss: 962.9421055909884
Validation loss decreased (1024.474594 --> 1024.402032).  Saving model ...
Epoch 849, train_loss: 1067.7512543177086, val_loss: 962.270705353022
Validation loss decreased (1024.402032 --> 1024.328850).  Saving model ...
Epoch 850, train_loss: 1066.0453237121635, val_loss: 961.308651786822
Validation loss decreased (1024.328850 --> 1024.254709).  Saving model ...
Epoch 851, train_loss: 1075.4068363626325, val_loss: 950.4425412369219
Validation loss decreased (1024.254709 --> 1024.167973).  Saving model ...
Epoch 852, train_loss: 1062.5712401283022, val_loss: 954.9559739804271
Validation loss decreased (1024.167973 --> 1024.086738).  Saving model ...
Epoch 853, train_loss: 1065.7093777436205, val_loss: 962.0875994219165
Validation loss decreased (1024.086738 --> 1024.014055).  Saving model ...
Epoch 854, train_loss: 1060.5725192262541, val_loss: 959.3785439791505
Validation loss decreased (1024.014055 --> 1023.938369).  Saving model ...
Epoch 855, train_loss: 1077.4024367926188, val_loss: 949.8771409013981
Validation loss decreased (1023.938369 --> 1023.851748).  Saving model ...
Epoch 856, train_loss: 1059.6645883906895, val_loss: 954.7084296500685
Validation loss decreased (1023.851748 --> 1023.770973).  Saving model ...
Epoch 857, train_loss: 1072.0038456738937, val_loss: 954.6820475456892
Validation loss decreased (1023.770973 --> 1023.690356).  Saving model ...
Epoch 858, train_loss: 1060.7337158662756, val_loss: 961.5196115978562
Validation loss decreased (1023.690356 --> 1023.617896).  Saving model ...
Epoch 859, train_loss: 1063.4827175730518, val_loss: 959.4999892498832
Validation loss decreased (1023.617896 --> 1023.543253).  Saving model ...
Epoch 860, train_loss: 1072.008710154986, val_loss: 956.0018169180775
Validation loss decreased (1023.543253 --> 1023.464717).  Saving model ...
Epoch 861, train_loss: 1065.5717998380555, val_loss: 962.8891615336032
Validation loss decreased (1023.464717 --> 1023.394362).  Saving model ...
Epoch 862, train_loss: 1077.7237170404585, val_loss: 938.6697741908721
Validation loss decreased (1023.394362 --> 1023.296073).  Saving model ...
Epoch 863, train_loss: 1060.6236407457227, val_loss: 939.6542647981647
Validation loss decreased (1023.296073 --> 1023.199153).  Saving model ...
Epoch 864, train_loss: 1063.2464558602612, val_loss: 949.3800251504231
Validation loss decreased (1023.199153 --> 1023.113715).  Saving model ...
Epoch 865, train_loss: 1063.8351552410688, val_loss: 956.9974528041595
Validation loss decreased (1023.113715 --> 1023.037280).  Saving model ...
Epoch 866, train_loss: 1061.4628379941175, val_loss: 951.4981984957946
Validation loss decreased (1023.037280 --> 1022.954671).  Saving model ...
Epoch 867, train_loss: 1057.9161715184266, val_loss: 956.5026709029192
Validation loss decreased (1022.954671 --> 1022.878025).  Saving model ...
Epoch 868, train_loss: 1067.4245900376454, val_loss: 949.4928563322406
Validation loss decreased (1022.878025 --> 1022.793480).  Saving model ...
Epoch 869, train_loss: 1064.7165243123736, val_loss: 956.691516164939
Validation loss decreased (1022.793480 --> 1022.717413).  Saving model ...
Epoch 870, train_loss: 1065.1836063288893, val_loss: 956.4845582750112
Validation loss decreased (1022.717413 --> 1022.641284).  Saving model ...
Epoch 871, train_loss: 1071.5974266300923, val_loss: 956.5320303079599
Validation loss decreased (1022.641284 --> 1022.565383).  Saving model ...
Epoch 872, train_loss: 1059.6882706471804, val_loss: 956.8238403589861
Validation loss decreased (1022.565383 --> 1022.489991).  Saving model ...
Epoch 873, train_loss: 1065.5856355901706, val_loss: 947.1679191920938
Validation loss decreased (1022.489991 --> 1022.403712).  Saving model ...
Epoch 874, train_loss: 1064.9326023304982, val_loss: 952.7143248601536
Validation loss decreased (1022.403712 --> 1022.323976).  Saving model ...
Epoch 875, train_loss: 1068.7081009800909, val_loss: 955.5944544660165
Validation loss decreased (1022.323976 --> 1022.247713).  Saving model ...
Epoch 876, train_loss: 1062.4553188820114, val_loss: 958.0450426486027
Validation loss decreased (1022.247713 --> 1022.174423).  Saving model ...
Epoch 877, train_loss: 1068.1387580450946, val_loss: 955.1894385502518
Validation loss decreased (1022.174423 --> 1022.098043).  Saving model ...
Epoch 878, train_loss: 1060.040571454366, val_loss: 957.4106114006928
Validation loss decreased (1022.098043 --> 1022.024367).  Saving model ...
Epoch 879, train_loss: 1065.6699405867578, val_loss: 957.1262304753509
Validation loss decreased (1022.024367 --> 1021.950535).  Saving model ...
Epoch 880, train_loss: 1069.9430483898095, val_loss: 954.1638199425851
Validation loss decreased (1021.950535 --> 1021.873505).  Saving model ...
Epoch 881, train_loss: 1064.6069176284711, val_loss: 951.5728508329615
Validation loss decreased (1021.873505 --> 1021.793709).  Saving model ...
Epoch 882, train_loss: 1070.5084907523656, val_loss: 948.5096261336188
Validation loss decreased (1021.793709 --> 1021.710620).  Saving model ...
Epoch 883, train_loss: 1062.0653103304564, val_loss: 953.8350729214266
Validation loss decreased (1021.710620 --> 1021.633751).  Saving model ...
Epoch 884, train_loss: 1066.128652880917, val_loss: 947.6388841785106
Validation loss decreased (1021.633751 --> 1021.550046).  Saving model ...
Epoch 885, train_loss: 1063.5604889276767, val_loss: 946.9679270950072
Validation loss decreased (1021.550046 --> 1021.465773).  Saving model ...
Epoch 886, train_loss: 1057.5898461369766, val_loss: 953.8740349059195
Validation loss decreased (1021.465773 --> 1021.389484).  Saving model ...
Epoch 887, train_loss: 1071.0725489021347, val_loss: 951.387199301455
Validation loss decreased (1021.389484 --> 1021.310564).  Saving model ...
Epoch 888, train_loss: 1065.2330602715374, val_loss: 956.3015608712703
Validation loss decreased (1021.310564 --> 1021.237355).  Saving model ...
Epoch 889, train_loss: 1068.191869016621, val_loss: 946.2900930947068
Validation loss decreased (1021.237355 --> 1021.153050).  Saving model ...
Epoch 890, train_loss: 1061.9768463408147, val_loss: 955.4996098849512
Validation loss decreased (1021.153050 --> 1021.079282).  Saving model ...
Epoch 891, train_loss: 1066.7833303864657, val_loss: 948.869614489697
Validation loss decreased (1021.079282 --> 1020.998239).  Saving model ...
Epoch 892, train_loss: 1053.395211405593, val_loss: 951.3124066424813
Validation loss decreased (1020.998239 --> 1020.920116).  Saving model ...
Epoch 893, train_loss: 1064.9259506516084, val_loss: 955.1396748143217
Validation loss decreased (1020.920116 --> 1020.846453).  Saving model ...
Epoch 894, train_loss: 1069.1122459383334, val_loss: 949.4067777531459
Validation loss decreased (1020.846453 --> 1020.766543).  Saving model ...
Epoch 895, train_loss: 1069.0937569237178, val_loss: 949.9209069902589
Validation loss decreased (1020.766543 --> 1020.687386).  Saving model ...
Epoch 896, train_loss: 1056.9169398376255, val_loss: 948.5981727789289
Validation loss decreased (1020.687386 --> 1020.606929).  Saving model ...
Epoch 897, train_loss: 1065.208679117613, val_loss: 951.6918570108768
Validation loss decreased (1020.606929 --> 1020.530101).  Saving model ...
Epoch 898, train_loss: 1065.3479449205831, val_loss: 940.3838640098
Validation loss decreased (1020.530101 --> 1020.440851).  Saving model ...
Epoch 899, train_loss: 1060.755801269739, val_loss: 943.3564365231992
Validation loss decreased (1020.440851 --> 1020.355107).  Saving model ...
Epoch 900, train_loss: 1057.9631104510458, val_loss: 943.2124065702052
Validation loss decreased (1020.355107 --> 1020.269393).  Saving model ...
Epoch 901, train_loss: 1056.7253990710537, val_loss: 946.5900983038215
Validation loss decreased (1020.269393 --> 1020.187618).  Saving model ...
Epoch 902, train_loss: 1060.0654829563796, val_loss: 940.3093502095013
Validation loss decreased (1020.187618 --> 1020.099061).  Saving model ...
Epoch 903, train_loss: 1061.8318300646695, val_loss: 946.7750128343813
Validation loss decreased (1020.099061 --> 1020.017860).  Saving model ...
Epoch 904, train_loss: 1056.276798264555, val_loss: 946.4962994336643
Validation loss decreased (1020.017860 --> 1019.936531).  Saving model ...
Epoch 905, train_loss: 1056.1842580910957, val_loss: 947.4494137493992
Validation loss decreased (1019.936531 --> 1019.856435).  Saving model ...
Epoch 906, train_loss: 1056.9474457772765, val_loss: 944.9234733107359
Validation loss decreased (1019.856435 --> 1019.773727).  Saving model ...
Epoch 907, train_loss: 1060.2558091871877, val_loss: 947.5061246944359
Validation loss decreased (1019.773727 --> 1019.694050).  Saving model ...
Epoch 908, train_loss: 1053.7624017622456, val_loss: 952.2277121892022
Validation loss decreased (1019.694050 --> 1019.619748).  Saving model ...
Epoch 909, train_loss: 1069.2101437539056, val_loss: 947.2820729490122
Validation loss decreased (1019.619748 --> 1019.540168).  Saving model ...
Epoch 910, train_loss: 1048.9582797919418, val_loss: 946.8201555207926
Validation loss decreased (1019.540168 --> 1019.460256).  Saving model ...
Epoch 911, train_loss: 1058.5411870961912, val_loss: 949.6234667489929
Validation loss decreased (1019.460256 --> 1019.383597).  Saving model ...
Epoch 912, train_loss: 1057.4192892656351, val_loss: 945.212816417394
Validation loss decreased (1019.383597 --> 1019.302269).  Saving model ...
Epoch 913, train_loss: 1062.2939230205332, val_loss: 921.3608677429847
Validation loss decreased (1019.302269 --> 1019.194995).  Saving model ...
Epoch 914, train_loss: 1051.8246756919891, val_loss: 933.3311554074731
Validation loss decreased (1019.194995 --> 1019.101052).  Saving model ...
Epoch 915, train_loss: 1054.7874224978073, val_loss: 935.5123896204104
Validation loss decreased (1019.101052 --> 1019.009698).  Saving model ...
Epoch 916, train_loss: 1056.9204412403144, val_loss: 939.1196994609526
Validation loss decreased (1019.009698 --> 1018.922482).  Saving model ...
Epoch 917, train_loss: 1065.8555275595809, val_loss: 945.6073497563824
Validation loss decreased (1018.922482 --> 1018.842531).  Saving model ...
Epoch 918, train_loss: 1056.9559076490673, val_loss: 937.2199397598816
Validation loss decreased (1018.842531 --> 1018.753617).  Saving model ...
Epoch 919, train_loss: 1054.6052654869115, val_loss: 947.6321371404332
Validation loss decreased (1018.753617 --> 1018.676227).  Saving model ...
Epoch 920, train_loss: 1058.9206065517287, val_loss: 942.0084843010376
Validation loss decreased (1018.676227 --> 1018.592893).  Saving model ...
Epoch 921, train_loss: 1064.9647370889872, val_loss: 945.0883370262605
Validation loss decreased (1018.592893 --> 1018.513083).  Saving model ...
Epoch 922, train_loss: 1055.3234986525827, val_loss: 938.4619589266294
Validation loss decreased (1018.513083 --> 1018.426260).  Saving model ...
Epoch 923, train_loss: 1049.6010974626174, val_loss: 949.4792941069604
Validation loss decreased (1018.426260 --> 1018.351561).  Saving model ...
Epoch 924, train_loss: 1053.0929706996862, val_loss: 944.2194581219005
Validation loss decreased (1018.351561 --> 1018.271332).  Saving model ...
Epoch 925, train_loss: 1056.768131199782, val_loss: 949.1766560933547
Validation loss decreased (1018.271332 --> 1018.196635).  Saving model ...
Epoch 926, train_loss: 1062.4191542021015, val_loss: 944.8316218729815
Validation loss decreased (1018.196635 --> 1018.117407).  Saving model ...
Epoch 927, train_loss: 1063.0632043905434, val_loss: 938.5983203892798
Validation loss decreased (1018.117407 --> 1018.031626).  Saving model ...
Epoch 928, train_loss: 1050.461442329198, val_loss: 945.7371331363255
Validation loss decreased (1018.031626 --> 1017.953722).  Saving model ...
Epoch 929, train_loss: 1062.4250509595588, val_loss: 939.2182768809357
Validation loss decreased (1017.953722 --> 1017.868969).  Saving model ...
Epoch 930, train_loss: 1052.2364797164857, val_loss: 944.7309794673437
Validation loss decreased (1017.868969 --> 1017.790326).  Saving model ...
Epoch 931, train_loss: 1057.2444191422298, val_loss: 940.7800494982802
Validation loss decreased (1017.790326 --> 1017.707608).  Saving model ...
Epoch 932, train_loss: 1065.4902522319178, val_loss: 929.5749577453403
Validation loss decreased (1017.707608 --> 1017.613046).  Saving model ...
Epoch 933, train_loss: 1050.8597339066207, val_loss: 931.8250812283712
Validation loss decreased (1017.613046 --> 1017.521097).  Saving model ...
Epoch 934, train_loss: 1055.4695439174113, val_loss: 948.1132465484188
Validation loss decreased (1017.521097 --> 1017.446785).  Saving model ...
Epoch 935, train_loss: 1060.771412987122, val_loss: 936.9717500771859
Validation loss decreased (1017.446785 --> 1017.360715).  Saving model ...
Epoch 936, train_loss: 1056.210767839447, val_loss: 932.8665302020976
Validation loss decreased (1017.360715 --> 1017.270443).  Saving model ...
Epoch 937, train_loss: 1051.3929707621348, val_loss: 937.5586698754631
Validation loss decreased (1017.270443 --> 1017.185372).  Saving model ...
Epoch 938, train_loss: 1063.0758386152847, val_loss: 929.1714530160693
Validation loss decreased (1017.185372 --> 1017.091541).  Saving model ...
Epoch 939, train_loss: 1052.8655568145152, val_loss: 928.5371720053976
Validation loss decreased (1017.091541 --> 1016.997234).  Saving model ...
Epoch 940, train_loss: 1057.0545372242166, val_loss: 928.2164578734286
Validation loss decreased (1016.997234 --> 1016.902786).  Saving model ...
Epoch 941, train_loss: 1050.4376442441678, val_loss: 937.136035786161
Validation loss decreased (1016.902786 --> 1016.818018).  Saving model ...
Epoch 942, train_loss: 1052.2909595208469, val_loss: 941.4400642344909
Validation loss decreased (1016.818018 --> 1016.737999).  Saving model ...
Epoch 943, train_loss: 1055.2196217613514, val_loss: 942.3917857367023
Validation loss decreased (1016.737999 --> 1016.659159).  Saving model ...
Epoch 944, train_loss: 1049.119305585737, val_loss: 932.557215323316
Validation loss decreased (1016.659159 --> 1016.570068).  Saving model ...
Epoch 945, train_loss: 1054.8278919441923, val_loss: 937.3089141177693
Validation loss decreased (1016.570068 --> 1016.486193).  Saving model ...
Epoch 946, train_loss: 1051.1264289871517, val_loss: 942.5267406883286
Validation loss decreased (1016.486193 --> 1016.408012).  Saving model ...
Epoch 947, train_loss: 1056.56619405983, val_loss: 942.2176978928073
Validation loss decreased (1016.408012 --> 1016.329670).  Saving model ...
Epoch 948, train_loss: 1047.010911348902, val_loss: 936.8171508947348
Validation loss decreased (1016.329670 --> 1016.245796).  Saving model ...
Epoch 949, train_loss: 1053.459075092664, val_loss: 934.172094066364
Validation loss decreased (1016.245796 --> 1016.159311).  Saving model ...
Epoch 950, train_loss: 1057.718199361771, val_loss: 933.1975947644536
Validation loss decreased (1016.159311 --> 1016.071983).  Saving model ...
Epoch 951, train_loss: 1051.7321389750543, val_loss: 935.3946584789181
Validation loss decreased (1016.071983 --> 1015.987149).  Saving model ...
Epoch 952, train_loss: 1060.1666692680838, val_loss: 934.7886637379287
Validation loss decreased (1015.987149 --> 1015.901857).  Saving model ...
Epoch 953, train_loss: 1051.5664179712621, val_loss: 926.1533144334293
Validation loss decreased (1015.901857 --> 1015.807682).  Saving model ...
Epoch 954, train_loss: 1043.547756924469, val_loss: 944.3664559814888
Validation loss decreased (1015.807682 --> 1015.732796).  Saving model ...
Epoch 955, train_loss: 1056.508946804651, val_loss: 930.1756927809673
Validation loss decreased (1015.732796 --> 1015.643207).  Saving model ...
Epoch 956, train_loss: 1052.376880568427, val_loss: 942.1348596715267
Validation loss decreased (1015.643207 --> 1015.566316).  Saving model ...
Epoch 957, train_loss: 1046.3335013064604, val_loss: 931.8551878519853
Validation loss decreased (1015.566316 --> 1015.478843).  Saving model ...
Epoch 958, train_loss: 1045.8025448640765, val_loss: 935.5063050796149
Validation loss decreased (1015.478843 --> 1015.395365).  Saving model ...
Epoch 959, train_loss: 1047.0641310338326, val_loss: 919.758789440526
Validation loss decreased (1015.395365 --> 1015.295639).  Saving model ...
Epoch 960, train_loss: 1045.313641170874, val_loss: 930.822049762342
Validation loss decreased (1015.295639 --> 1015.207646).  Saving model ...
Epoch 961, train_loss: 1041.3248095474596, val_loss: 947.1918866296611
Validation loss decreased (1015.207646 --> 1015.136870).  Saving model ...
Epoch 962, train_loss: 1047.4890820859262, val_loss: 942.978572628123
Validation loss decreased (1015.136870 --> 1015.061861).  Saving model ...
Epoch 963, train_loss: 1054.2346671962646, val_loss: 937.6782094585677
Validation loss decreased (1015.061861 --> 1014.981504).  Saving model ...
Epoch 964, train_loss: 1049.772722511287, val_loss: 931.2145761305757
Validation loss decreased (1014.981504 --> 1014.894609).  Saving model ...
Epoch 965, train_loss: 1054.9918557253006, val_loss: 916.2224836977103
Validation loss decreased (1014.894609 --> 1014.792358).  Saving model ...
Epoch 966, train_loss: 1050.3059428960048, val_loss: 926.4299359882984
Validation loss decreased (1014.792358 --> 1014.700886).  Saving model ...
Epoch 967, train_loss: 1047.9060940401755, val_loss: 923.0620418509511
Validation loss decreased (1014.700886 --> 1014.606120).  Saving model ...
Epoch 968, train_loss: 1051.4520905496643, val_loss: 923.2565531370377
Validation loss decreased (1014.606120 --> 1014.511750).  Saving model ...
Epoch 969, train_loss: 1049.951657271697, val_loss: 927.5665486733561
Validation loss decreased (1014.511750 --> 1014.422024).  Saving model ...
Epoch 970, train_loss: 1050.4103952773837, val_loss: 928.4239361125233
Validation loss decreased (1014.422024 --> 1014.333366).  Saving model ...
Epoch 971, train_loss: 1049.2660208029881, val_loss: 923.9241019837726
Validation loss decreased (1014.333366 --> 1014.240256).  Saving model ...
Epoch 972, train_loss: 1048.5568264110748, val_loss: 932.7924963570968
Validation loss decreased (1014.240256 --> 1014.156462).  Saving model ...
Epoch 973, train_loss: 1048.9073571789693, val_loss: 922.0488248289295
Validation loss decreased (1014.156462 --> 1014.061799).  Saving model ...
Epoch 974, train_loss: 1043.5366725978495, val_loss: 936.4072883729142
Validation loss decreased (1014.061799 --> 1013.982071).  Saving model ...
Epoch 975, train_loss: 1048.7463760682328, val_loss: 930.4303901601061
Validation loss decreased (1013.982071 --> 1013.896377).  Saving model ...
Epoch 976, train_loss: 1051.2111738370763, val_loss: 918.5374944186434
Validation loss decreased (1013.896377 --> 1013.798674).  Saving model ...
Epoch 977, train_loss: 1040.7232633884746, val_loss: 928.8414707870838
Validation loss decreased (1013.798674 --> 1013.711716).  Saving model ...
Epoch 978, train_loss: 1048.6775354749768, val_loss: 928.0070586727285
Validation loss decreased (1013.711716 --> 1013.624084).  Saving model ...
Epoch 979, train_loss: 1043.8310212714475, val_loss: 932.3630540340258
Validation loss decreased (1013.624084 --> 1013.541080).  Saving model ...
Epoch 980, train_loss: 1047.8449518005395, val_loss: 930.0973549678151
Validation loss decreased (1013.541080 --> 1013.455933).  Saving model ...
Epoch 981, train_loss: 1043.739353670317, val_loss: 939.1317215485045
Validation loss decreased (1013.455933 --> 1013.380169).  Saving model ...
Epoch 982, train_loss: 1047.5098266081402, val_loss: 928.8639520698345
Validation loss decreased (1013.380169 --> 1013.294104).  Saving model ...
Epoch 983, train_loss: 1053.1836061867223, val_loss: 915.0076766794922
Validation loss decreased (1013.294104 --> 1013.194118).  Saving model ...
Epoch 984, train_loss: 1046.9548548178784, val_loss: 929.9994658412317
Validation loss decreased (1013.194118 --> 1013.109570).  Saving model ...
Epoch 985, train_loss: 1050.1524847369487, val_loss: 912.7610090570097
Validation loss decreased (1013.109570 --> 1013.007694).  Saving model ...
Epoch 986, train_loss: 1040.270263755099, val_loss: 926.1391689935881
Validation loss decreased (1013.007694 --> 1012.919592).  Saving model ...
Epoch 987, train_loss: 1047.4838548384307, val_loss: 919.0052795956314
Validation loss decreased (1012.919592 --> 1012.824440).  Saving model ...
Epoch 988, train_loss: 1046.2021960051106, val_loss: 932.2395556841296
Validation loss decreased (1012.824440 --> 1012.742877).  Saving model ...
Epoch 989, train_loss: 1049.7630779628912, val_loss: 925.8105758316652
Validation loss decreased (1012.742877 --> 1012.654977).  Saving model ...
Epoch 990, train_loss: 1048.2829289261797, val_loss: 912.9158228389423
Validation loss decreased (1012.654977 --> 1012.554231).  Saving model ...
Epoch 991, train_loss: 1042.314865672428, val_loss: 920.8646437882938
Validation loss decreased (1012.554231 --> 1012.461709).  Saving model ...
Epoch 992, train_loss: 1040.7757103998463, val_loss: 923.5198156237383
Validation loss decreased (1012.461709 --> 1012.372049).  Saving model ...
Epoch 993, train_loss: 1049.0826994458835, val_loss: 925.8413730952035
Validation loss decreased (1012.372049 --> 1012.284909).  Saving model ...
Epoch 994, train_loss: 1054.0871852725884, val_loss: 928.6138408375672
Validation loss decreased (1012.284909 --> 1012.200733).  Saving model ...
Epoch 995, train_loss: 1039.614299919256, val_loss: 930.021259804258
Validation loss decreased (1012.200733 --> 1012.118140).  Saving model ...
Epoch 996, train_loss: 1052.9914699240057, val_loss: 914.6154459017957
Validation loss decreased (1012.118140 --> 1012.020246).  Saving model ...
Epoch 997, train_loss: 1038.5955038414643, val_loss: 922.7753119207755
Validation loss decreased (1012.020246 --> 1011.930732).  Saving model ...
Epoch 998, train_loss: 1040.2432189313856, val_loss: 924.7709823765139
Validation loss decreased (1011.930732 --> 1011.843398).  Saving model ...
Epoch 999, train_loss: 1044.4756039816189, val_loss: 939.4812997334537
Validation loss decreased (1011.843398 --> 1011.770963).  Saving model ...
Epoch 1000, train_loss: 1041.8182594002058, val_loss: 945.7277514830124
Validation loss decreased (1011.770963 --> 1011.704920).  Saving model ...
Epoch 1001, train_loss: 1054.516889085102, val_loss: 929.7172619814123
Validation loss decreased (1011.704920 --> 1011.623015).  Saving model ...
Epoch 1002, train_loss: 1050.135641126765, val_loss: 921.7179711135892
Validation loss decreased (1011.623015 --> 1011.533289).  Saving model ...
Epoch 1003, train_loss: 1052.589837398397, val_loss: 915.4525227313352
Validation loss decreased (1011.533289 --> 1011.437496).  Saving model ...
Epoch 1004, train_loss: 1049.9014270649827, val_loss: 918.5539232715192
Validation loss decreased (1011.437496 --> 1011.344982).  Saving model ...
Epoch 1005, train_loss: 1037.9449460469739, val_loss: 908.9769499570131
Validation loss decreased (1011.344982 --> 1011.243123).  Saving model ...
Epoch 1006, train_loss: 1036.8960954818783, val_loss: 921.7116348494205
Validation loss decreased (1011.243123 --> 1011.154126).  Saving model ...
Epoch 1007, train_loss: 1048.2854314277465, val_loss: 920.9287495332075
Validation loss decreased (1011.154126 --> 1011.064528).  Saving model ...
Epoch 1008, train_loss: 1046.8867095751577, val_loss: 918.2386508534795
Validation loss decreased (1011.064528 --> 1010.972438).  Saving model ...
Epoch 1009, train_loss: 1043.7352488802633, val_loss: 923.1137680862349
Validation loss decreased (1010.972438 --> 1010.885363).  Saving model ...
Epoch 1010, train_loss: 1034.5839792896695, val_loss: 926.4705064853919
Validation loss decreased (1010.885363 --> 1010.801784).  Saving model ...
Epoch 1011, train_loss: 1050.5324856444347, val_loss: 913.6235118506794
Validation loss decreased (1010.801784 --> 1010.705663).  Saving model ...
Epoch 1012, train_loss: 1041.313190128018, val_loss: 914.973710508435
Validation loss decreased (1010.705663 --> 1010.611067).  Saving model ...
Epoch 1013, train_loss: 1037.9683984728467, val_loss: 922.2482891953874
Validation loss decreased (1010.611067 --> 1010.523838).  Saving model ...
Epoch 1014, train_loss: 1051.9940519244565, val_loss: 913.4835942348949
Validation loss decreased (1010.523838 --> 1010.428137).  Saving model ...
Epoch 1015, train_loss: 1034.2989786720568, val_loss: 923.2213113444383
Validation loss decreased (1010.428137 --> 1010.342219).  Saving model ...
Epoch 1016, train_loss: 1043.4988614508984, val_loss: 924.7445264371459
Validation loss decreased (1010.342219 --> 1010.257970).  Saving model ...
Epoch 1017, train_loss: 1043.8183596823424, val_loss: 928.4533742572203
Validation loss decreased (1010.257970 --> 1010.177532).  Saving model ...
Epoch 1018, train_loss: 1046.559369623889, val_loss: 921.6520620611201
Validation loss decreased (1010.177532 --> 1010.090572).  Saving model ...
Epoch 1019, train_loss: 1043.6646416847666, val_loss: 917.9833298870371
Validation loss decreased (1010.090572 --> 1010.000182).  Saving model ...
Epoch 1020, train_loss: 1033.8388170544924, val_loss: 926.9997439577405
Validation loss decreased (1010.000182 --> 1009.918809).  Saving model ...
Epoch 1021, train_loss: 1058.3325562664772, val_loss: 914.5448641676154
Validation loss decreased (1009.918809 --> 1009.825397).  Saving model ...
Epoch 1022, train_loss: 1040.1247228499537, val_loss: 912.9800251168896
Validation loss decreased (1009.825397 --> 1009.730637).  Saving model ...
Epoch 1023, train_loss: 1040.6837255583775, val_loss: 924.7049875304656
Validation loss decreased (1009.730637 --> 1009.647523).  Saving model ...
Epoch 1024, train_loss: 1041.6269550043346, val_loss: 917.4294314642307
Validation loss decreased (1009.647523 --> 1009.557466).  Saving model ...
Epoch 1025, train_loss: 1041.7567279790928, val_loss: 916.7360499378268
Validation loss decreased (1009.557466 --> 1009.466908).  Saving model ...
Epoch 1026, train_loss: 1041.945872661179, val_loss: 915.9325143507677
Validation loss decreased (1009.466908 --> 1009.375744).  Saving model ...
Epoch 1027, train_loss: 1038.2197310853533, val_loss: 919.5705261431802
Validation loss decreased (1009.375744 --> 1009.288300).  Saving model ...
Epoch 1028, train_loss: 1041.723353623341, val_loss: 923.5159955138411
Validation loss decreased (1009.288300 --> 1009.204864).  Saving model ...
Epoch 1029, train_loss: 1040.7205905125986, val_loss: 921.7878287841437
Validation loss decreased (1009.204864 --> 1009.119910).  Saving model ...
Epoch 1030, train_loss: 1046.877803940765, val_loss: 915.113676277068
Validation loss decreased (1009.119910 --> 1009.028642).  Saving model ...
Epoch 1031, train_loss: 1044.2519863234963, val_loss: 904.7168096394008
Validation loss decreased (1009.028642 --> 1008.927467).  Saving model ...
Epoch 1032, train_loss: 1041.211677239595, val_loss: 913.3535768829673
Validation loss decreased (1008.927467 --> 1008.834857).  Saving model ...
Epoch 1033, train_loss: 1040.826909456552, val_loss: 908.9319346155725
Validation loss decreased (1008.834857 --> 1008.738145).  Saving model ...
Epoch 1034, train_loss: 1033.1593647891482, val_loss: 909.719526016315
Validation loss decreased (1008.738145 --> 1008.642382).  Saving model ...
Epoch 1035, train_loss: 1048.2774324022923, val_loss: 912.788751341524
Validation loss decreased (1008.642382 --> 1008.549770).  Saving model ...
Epoch 1036, train_loss: 1033.6396411049984, val_loss: 914.6912833695501
Validation loss decreased (1008.549770 --> 1008.459173).  Saving model ...
Epoch 1037, train_loss: 1037.4747531797154, val_loss: 914.1292901037579
Validation loss decreased (1008.459173 --> 1008.368209).  Saving model ...
Epoch 1038, train_loss: 1033.0082742957036, val_loss: 920.2335503466043
Validation loss decreased (1008.368209 --> 1008.283301).  Saving model ...
Epoch 1039, train_loss: 1038.5544574094683, val_loss: 911.7346659976465
Validation loss decreased (1008.283301 --> 1008.190376).  Saving model ...
Epoch 1040, train_loss: 1039.4385701207937, val_loss: 913.1292470305716
Validation loss decreased (1008.190376 --> 1008.098971).  Saving model ...
Epoch 1041, train_loss: 1041.812867981101, val_loss: 910.2861609650541
Validation loss decreased (1008.098971 --> 1008.005011).  Saving model ...
Epoch 1042, train_loss: 1034.5918288678456, val_loss: 909.9985193969364
Validation loss decreased (1008.005011 --> 1007.910955).  Saving model ...
Epoch 1043, train_loss: 1042.9620086519355, val_loss: 910.4575950512843
Validation loss decreased (1007.910955 --> 1007.817519).  Saving model ...
Epoch 1044, train_loss: 1040.3884757601231, val_loss: 918.7534305663465
Validation loss decreased (1007.817519 --> 1007.732209).  Saving model ...
Epoch 1045, train_loss: 1042.3902481920425, val_loss: 913.1194845907556
Validation loss decreased (1007.732209 --> 1007.641670).  Saving model ...
Epoch 1046, train_loss: 1036.8982642683811, val_loss: 915.1543177455004
Validation loss decreased (1007.641670 --> 1007.553250).  Saving model ...
Epoch 1047, train_loss: 1047.2965706221305, val_loss: 910.0817620969924
Validation loss decreased (1007.553250 --> 1007.460154).  Saving model ...
Epoch 1048, train_loss: 1031.7935588703892, val_loss: 911.4856828186689
Validation loss decreased (1007.460154 --> 1007.368576).  Saving model ...
Epoch 1049, train_loss: 1041.6508136222476, val_loss: 900.5673333816836
Validation loss decreased (1007.368576 --> 1007.266763).  Saving model ...
Epoch 1050, train_loss: 1028.125935555787, val_loss: 914.8994871255646
Validation loss decreased (1007.266763 --> 1007.178794).  Saving model ...
Epoch 1051, train_loss: 1042.826175669148, val_loss: 913.0255995288381
Validation loss decreased (1007.178794 --> 1007.089210).  Saving model ...
Epoch 1052, train_loss: 1032.2388727021105, val_loss: 923.0302735715222
Validation loss decreased (1007.089210 --> 1007.009306).  Saving model ...
Epoch 1053, train_loss: 1037.6551089022944, val_loss: 908.4052596653611
Validation loss decreased (1007.009306 --> 1006.915665).  Saving model ...
Epoch 1054, train_loss: 1045.7975230693064, val_loss: 903.5523499499205
Validation loss decreased (1006.915665 --> 1006.817597).  Saving model ...
Epoch 1055, train_loss: 1032.1863572012912, val_loss: 906.4260782691725
Validation loss decreased (1006.817597 --> 1006.722439).  Saving model ...
Epoch 1056, train_loss: 1041.650471985979, val_loss: 910.6828822661108
Validation loss decreased (1006.722439 --> 1006.631493).  Saving model ...
Epoch 1057, train_loss: 1039.0839374647537, val_loss: 906.3988995804388
Validation loss decreased (1006.631493 --> 1006.536665).  Saving model ...
Epoch 1058, train_loss: 1038.7157743248683, val_loss: 901.2613004411369
Validation loss decreased (1006.536665 --> 1006.437161).  Saving model ...
Epoch 1059, train_loss: 1036.2182087114213, val_loss: 912.7137208060644
Validation loss decreased (1006.437161 --> 1006.348659).  Saving model ...
Epoch 1060, train_loss: 1043.353720436705, val_loss: 894.4049710017224
Validation loss decreased (1006.348659 --> 1006.243052).  Saving model ...
Epoch 1061, train_loss: 1026.2353083745222, val_loss: 908.8611502249154
Validation loss decreased (1006.243052 --> 1006.151269).  Saving model ...
Epoch 1062, train_loss: 1036.2816098164246, val_loss: 919.6235117033898
Validation loss decreased (1006.151269 --> 1006.069793).  Saving model ...
Epoch 1063, train_loss: 1032.0889121101925, val_loss: 922.1340194590667
Validation loss decreased (1006.069793 --> 1005.990832).  Saving model ...
Epoch 1064, train_loss: 1038.6940437639475, val_loss: 921.5952061182043
Validation loss decreased (1005.990832 --> 1005.911512).  Saving model ...
Epoch 1065, train_loss: 1039.4858468015059, val_loss: 905.834591160814
Validation loss decreased (1005.911512 --> 1005.817543).  Saving model ...
Epoch 1066, train_loss: 1032.9417599157262, val_loss: 912.3680858903022
Validation loss decreased (1005.817543 --> 1005.729880).  Saving model ...
Epoch 1067, train_loss: 1031.5473417611336, val_loss: 924.1335129232099
Validation loss decreased (1005.729880 --> 1005.653407).  Saving model ...
Epoch 1068, train_loss: 1038.834426071937, val_loss: 917.5050056557966
Validation loss decreased (1005.653407 --> 1005.570871).  Saving model ...
Epoch 1069, train_loss: 1036.0278520187317, val_loss: 919.9852809590544
Validation loss decreased (1005.570871 --> 1005.490810).  Saving model ...
Epoch 1070, train_loss: 1035.8443730600918, val_loss: 911.0861996274745
Validation loss decreased (1005.490810 --> 1005.402581).  Saving model ...
Epoch 1071, train_loss: 1036.549185096603, val_loss: 901.9701385506877
Validation loss decreased (1005.402581 --> 1005.306006).  Saving model ...
Epoch 1072, train_loss: 1024.3107056241902, val_loss: 915.3483365199303
Validation loss decreased (1005.306006 --> 1005.222090).  Saving model ...
Epoch 1073, train_loss: 1033.7954960177353, val_loss: 920.2196496365469
Validation loss decreased (1005.222090 --> 1005.142870).  Saving model ...
Epoch 1074, train_loss: 1037.7413992589002, val_loss: 911.8635852937567
Validation loss decreased (1005.142870 --> 1005.056018).  Saving model ...
Epoch 1075, train_loss: 1032.8904388445387, val_loss: 901.1550693951932
Validation loss decreased (1005.056018 --> 1004.959366).  Saving model ...
Epoch 1076, train_loss: 1031.135768961916, val_loss: 918.1645388006283
Validation loss decreased (1004.959366 --> 1004.878702).  Saving model ...
Epoch 1077, train_loss: 1037.3601994245876, val_loss: 926.3862328755414
Validation loss decreased (1004.878702 --> 1004.805821).  Saving model ...
Epoch 1078, train_loss: 1039.1779001924829, val_loss: 914.9080534677154
Validation loss decreased (1004.805821 --> 1004.722428).  Saving model ...
Epoch 1079, train_loss: 1026.712124463841, val_loss: 927.9992651365202
Validation loss decreased (1004.722428 --> 1004.651322).  Saving model ...
Epoch 1080, train_loss: 1050.7160735945952, val_loss: 902.541283613046
Validation loss decreased (1004.651322 --> 1004.556776).  Saving model ...
Epoch 1081, train_loss: 1023.602560418509, val_loss: 918.9745502156462
Validation loss decreased (1004.556776 --> 1004.477606).  Saving model ...
Epoch 1082, train_loss: 1041.9800463055574, val_loss: 905.7631199034718
Validation loss decreased (1004.477606 --> 1004.386373).  Saving model ...
Epoch 1083, train_loss: 1029.1444314864618, val_loss: 930.34357452046
Validation loss decreased (1004.386373 --> 1004.318005).  Saving model ...
Epoch 1084, train_loss: 1036.2111999520846, val_loss: 910.3124381604458
Validation loss decreased (1004.318005 --> 1004.231284).  Saving model ...
Epoch 1085, train_loss: 1035.1104200280001, val_loss: 904.7425569020378
Validation loss decreased (1004.231284 --> 1004.139589).  Saving model ...
Epoch 1086, train_loss: 1034.4267261226262, val_loss: 905.2266573459351
Validation loss decreased (1004.139589 --> 1004.048509).  Saving model ...
Epoch 1087, train_loss: 1034.2389936078168, val_loss: 899.6440615268107
Validation loss decreased (1004.048509 --> 1003.952461).  Saving model ...
Epoch 1088, train_loss: 1034.5395077837604, val_loss: 909.6466385264529
Validation loss decreased (1003.952461 --> 1003.865783).  Saving model ...
Epoch 1089, train_loss: 1034.6086931299883, val_loss: 912.7467636071314
Validation loss decreased (1003.865783 --> 1003.782111).  Saving model ...
Epoch 1090, train_loss: 1030.5944378217964, val_loss: 908.623310617319
Validation loss decreased (1003.782111 --> 1003.694809).  Saving model ...
Epoch 1091, train_loss: 1028.6447009921935, val_loss: 911.8774128017162
Validation loss decreased (1003.694809 --> 1003.610650).  Saving model ...
Epoch 1092, train_loss: 1031.0746123097622, val_loss: 921.0194713215697
Validation loss decreased (1003.610650 --> 1003.535017).  Saving model ...
Epoch 1093, train_loss: 1032.6380545378352, val_loss: 908.03261350486
Validation loss decreased (1003.535017 --> 1003.447641).  Saving model ...
Epoch 1094, train_loss: 1033.251362248376, val_loss: 902.6261669764917
Validation loss decreased (1003.447641 --> 1003.355482).  Saving model ...
Epoch 1095, train_loss: 1024.268238913124, val_loss: 922.8986588385814
Validation loss decreased (1003.355482 --> 1003.282006).  Saving model ...
Epoch 1096, train_loss: 1036.8743611609518, val_loss: 911.06779988556
Validation loss decreased (1003.282006 --> 1003.197868).  Saving model ...
Epoch 1097, train_loss: 1028.968912420391, val_loss: 911.0034468163385
Validation loss decreased (1003.197868 --> 1003.113826).  Saving model ...
Epoch 1098, train_loss: 1041.1361322829555, val_loss: 893.538540862291
Validation loss decreased (1003.113826 --> 1003.014031).  Saving model ...
Epoch 1099, train_loss: 1023.1439172410218, val_loss: 909.7694508062691
Validation loss decreased (1003.014031 --> 1002.929186).  Saving model ...
Epoch 1100, train_loss: 1028.9457830643848, val_loss: 919.7988440592203
Validation loss decreased (1002.929186 --> 1002.853613).  Saving model ...
Epoch 1101, train_loss: 1029.6007896471124, val_loss: 902.9913902912316
Validation loss decreased (1002.853613 --> 1002.762911).  Saving model ...
Epoch 1102, train_loss: 1027.5827951296885, val_loss: 900.7136752954458
Validation loss decreased (1002.762911 --> 1002.670308).  Saving model ...
Epoch 1103, train_loss: 1020.0417318185315, val_loss: 924.6975262093766
Validation loss decreased (1002.670308 --> 1002.599616).  Saving model ...
Epoch 1104, train_loss: 1030.6319557887468, val_loss: 925.5354145486489
Validation loss decreased (1002.599616 --> 1002.529812).  Saving model ...
Epoch 1105, train_loss: 1033.3012128756584, val_loss: 902.6832533533044
Validation loss decreased (1002.529812 --> 1002.439453).  Saving model ...
Epoch 1106, train_loss: 1025.4868495611088, val_loss: 927.8235231085179
Validation loss decreased (1002.439453 --> 1002.371988).  Saving model ...
Epoch 1107, train_loss: 1029.2818836998572, val_loss: 927.8415687944274
Validation loss decreased (1002.371988 --> 1002.304662).  Saving model ...
Epoch 1108, train_loss: 1026.0707570275433, val_loss: 922.6566434580312
Validation loss decreased (1002.304662 --> 1002.232777).  Saving model ...
Epoch 1109, train_loss: 1033.3471158616937, val_loss: 926.6201088973991
Validation loss decreased (1002.232777 --> 1002.164596).  Saving model ...
Epoch 1110, train_loss: 1032.9236777292774, val_loss: 912.8013120817036
Validation loss decreased (1002.164596 --> 1002.084089).  Saving model ...
Epoch 1111, train_loss: 1033.1347890429504, val_loss: 907.4258309873608
Validation loss decreased (1002.084089 --> 1001.998888).  Saving model ...
Epoch 1112, train_loss: 1032.7446698980343, val_loss: 915.5750931488145
Validation loss decreased (1001.998888 --> 1001.921169).  Saving model ...
Epoch 1113, train_loss: 1028.5706298821547, val_loss: 898.0708313103297
Validation loss decreased (1001.921169 --> 1001.827862).  Saving model ...
Epoch 1114, train_loss: 1018.2726167082483, val_loss: 922.2592944340576
Validation loss decreased (1001.827862 --> 1001.756436).  Saving model ...
Epoch 1115, train_loss: 1025.535739987436, val_loss: 925.237301218885
Validation loss decreased (1001.756436 --> 1001.687809).  Saving model ...
Epoch 1116, train_loss: 1024.569599866697, val_loss: 915.2043725013956
Validation loss decreased (1001.687809 --> 1001.610315).  Saving model ...
Epoch 1117, train_loss: 1024.0558455713544, val_loss: 906.1166608558983
Validation loss decreased (1001.610315 --> 1001.524824).  Saving model ...
Epoch 1118, train_loss: 1022.2801160779088, val_loss: 913.1639364752726
Validation loss decreased (1001.524824 --> 1001.445789).  Saving model ...
Epoch 1119, train_loss: 1028.0198097501911, val_loss: 911.5110489149889
Validation loss decreased (1001.445789 --> 1001.365418).  Saving model ...
Epoch 1120, train_loss: 1024.3411808968344, val_loss: 917.8569180342224
Validation loss decreased (1001.365418 --> 1001.290857).  Saving model ...
Epoch 1121, train_loss: 1035.9360988526116, val_loss: 895.7141616054597
Validation loss decreased (1001.290857 --> 1001.196676).  Saving model ...
Epoch 1122, train_loss: 1026.066581192424, val_loss: 903.8687311930126
Validation loss decreased (1001.196676 --> 1001.109931).  Saving model ...
Epoch 1123, train_loss: 1029.6106171464642, val_loss: 907.3294398429219
Validation loss decreased (1001.109931 --> 1001.026422).  Saving model ...
Epoch 1124, train_loss: 1031.5230971592714, val_loss: 890.9912365937013
Validation loss decreased (1001.026422 --> 1000.928526).  Saving model ...
Epoch 1125, train_loss: 1018.4259968923808, val_loss: 900.6894186905357
Validation loss decreased (1000.928526 --> 1000.839425).  Saving model ...
Epoch 1126, train_loss: 1028.6193231324694, val_loss: 891.9801245052948
Validation loss decreased (1000.839425 --> 1000.742747).  Saving model ...
Epoch 1127, train_loss: 1025.5976354733398, val_loss: 906.3718211925915
Validation loss decreased (1000.742747 --> 1000.659010).  Saving model ...
Epoch 1128, train_loss: 1035.0345417865271, val_loss: 901.943301850712
Validation loss decreased (1000.659010 --> 1000.571497).  Saving model ...
Epoch 1129, train_loss: 1025.9576453989273, val_loss: 919.338478371479
Validation loss decreased (1000.571497 --> 1000.499545).  Saving model ...
Epoch 1130, train_loss: 1027.93018264859, val_loss: 911.8798640192881
Validation loss decreased (1000.499545 --> 1000.421121).  Saving model ...
Epoch 1131, train_loss: 1025.7194835827283, val_loss: 926.1079395429075
Validation loss decreased (1000.421121 --> 1000.355415).  Saving model ...
Epoch 1132, train_loss: 1027.9654496037067, val_loss: 919.18568888119
Validation loss decreased (1000.355415 --> 1000.283710).  Saving model ...
Epoch 1133, train_loss: 1023.3504023945294, val_loss: 900.0695188237783
Validation loss decreased (1000.283710 --> 1000.195260).  Saving model ...
Epoch 1134, train_loss: 1030.3490234682533, val_loss: 897.4152522914056
Validation loss decreased (1000.195260 --> 1000.104625).  Saving model ...
Epoch 1135, train_loss: 1020.7788855194193, val_loss: 898.1362152643779
Validation loss decreased (1000.104625 --> 1000.014785).  Saving model ...
Epoch 1136, train_loss: 1016.0596639893123, val_loss: 896.1955544658725
Validation loss decreased (1000.014785 --> 999.923395).  Saving model ...
Epoch 1137, train_loss: 1022.1317056297887, val_loss: 919.3140977308489
Validation loss decreased (999.923395 --> 999.852498).  Saving model ...
Epoch 1138, train_loss: 1034.68788906965, val_loss: 892.2958002845668
Validation loss decreased (999.852498 --> 999.757985).  Saving model ...
Epoch 1139, train_loss: 1023.1233635743984, val_loss: 892.3698438961197
Validation loss decreased (999.757985 --> 999.663702).  Saving model ...
Epoch 1140, train_loss: 1019.3864376977663, val_loss: 908.370738477398
Validation loss decreased (999.663702 --> 999.583620).  Saving model ...
Epoch 1141, train_loss: 1026.3887696579757, val_loss: 903.5863448119827
Validation loss decreased (999.583620 --> 999.499486).  Saving model ...
Epoch 1142, train_loss: 1018.24429248659, val_loss: 910.6863794047305
Validation loss decreased (999.499486 --> 999.421716).  Saving model ...
Epoch 1143, train_loss: 1020.2140212456482, val_loss: 923.2443933236382
Validation loss decreased (999.421716 --> 999.355069).  Saving model ...
Epoch 1144, train_loss: 1032.6003833196285, val_loss: 903.4258840065312
Validation loss decreased (999.355069 --> 999.271215).  Saving model ...
Epoch 1145, train_loss: 1025.3690087265015, val_loss: 880.9565233624645
Validation loss decreased (999.271215 --> 999.167883).  Saving model ...
Epoch 1146, train_loss: 1016.3202050339381, val_loss: 916.6633115465776
Validation loss decreased (999.167883 --> 999.095890).  Saving model ...
Epoch 1147, train_loss: 1017.0303003722062, val_loss: 902.6770779394443
Validation loss decreased (999.095890 --> 999.011828).  Saving model ...
Epoch 1148, train_loss: 1020.8050719178955, val_loss: 908.5138577910488
Validation loss decreased (999.011828 --> 998.932997).  Saving model ...
Epoch 1149, train_loss: 1021.7666360760305, val_loss: 903.2939659674965
Validation loss decreased (998.932997 --> 998.849760).  Saving model ...
Epoch 1150, train_loss: 1023.3925180780936, val_loss: 907.2007718348946
Validation loss decreased (998.849760 --> 998.770066).  Saving model ...
Epoch 1151, train_loss: 1013.8042455989031, val_loss: 935.3623892673081
Validation loss decreased (998.770066 --> 998.714976).  Saving model ...
Epoch 1152, train_loss: 1025.6935673173705, val_loss: 903.1815683519843
Validation loss decreased (998.714976 --> 998.632048).  Saving model ...
Epoch 1153, train_loss: 1019.423291386465, val_loss: 894.1470132216701
Validation loss decreased (998.632048 --> 998.541428).  Saving model ...
Epoch 1154, train_loss: 1017.9163648267453, val_loss: 910.833946183015
Validation loss decreased (998.541428 --> 998.465425).  Saving model ...
Epoch 1155, train_loss: 1016.129253846436, val_loss: 927.2410753189193
Validation loss decreased (998.465425 --> 998.403759).  Saving model ...
Epoch 1156, train_loss: 1022.1117573486872, val_loss: 909.6279602896508
Validation loss decreased (998.403759 --> 998.326963).  Saving model ...
Epoch 1157, train_loss: 1026.3191448439552, val_loss: 902.4203794746709
Validation loss decreased (998.326963 --> 998.244071).  Saving model ...
Epoch 1158, train_loss: 1015.0064113532366, val_loss: 922.5085343714337
Validation loss decreased (998.244071 --> 998.178669).  Saving model ...
Epoch 1159, train_loss: 1024.1457049902715, val_loss: 904.1618867519829
Validation loss decreased (998.178669 --> 998.097550).  Saving model ...
Epoch 1160, train_loss: 1020.4034741479261, val_loss: 892.0478575804722
Validation loss decreased (998.097550 --> 998.006128).  Saving model ...
Epoch 1161, train_loss: 1024.5128689153657, val_loss: 882.8737823704218
Validation loss decreased (998.006128 --> 997.906961).  Saving model ...
Epoch 1162, train_loss: 1014.6106805477983, val_loss: 901.458176979224
Validation loss decreased (997.906961 --> 997.823959).  Saving model ...
Epoch 1163, train_loss: 1022.0282978003677, val_loss: 903.2352396418654
Validation loss decreased (997.823959 --> 997.742627).  Saving model ...
Epoch 1164, train_loss: 1022.5350743027718, val_loss: 893.9279950124246
Validation loss decreased (997.742627 --> 997.653439).  Saving model ...
Epoch 1165, train_loss: 1018.7647129930583, val_loss: 908.6994590287964
Validation loss decreased (997.653439 --> 997.577084).  Saving model ...
Epoch 1166, train_loss: 1024.9085866018306, val_loss: 902.7588727033802
Validation loss decreased (997.577084 --> 997.495765).  Saving model ...
Epoch 1167, train_loss: 1016.3326350904506, val_loss: 893.0759340681634
Validation loss decreased (997.495765 --> 997.406288).  Saving model ...
Epoch 1168, train_loss: 1020.3395641027888, val_loss: 900.7295078969665
Validation loss decreased (997.406288 --> 997.323516).  Saving model ...
Epoch 1169, train_loss: 1018.4401506905377, val_loss: 895.7211360991224
Validation loss decreased (997.323516 --> 997.236602).  Saving model ...
Epoch 1170, train_loss: 1013.2435636086977, val_loss: 920.4155091717071
Validation loss decreased (997.236602 --> 997.170943).  Saving model ...
Epoch 1171, train_loss: 1021.0558398569909, val_loss: 904.6039066886461
Validation loss decreased (997.170943 --> 997.091894).  Saving model ...
Epoch 1172, train_loss: 1021.1868027594398, val_loss: 891.6722233561455
Validation loss decreased (997.091894 --> 997.001945).  Saving model ...
Epoch 1173, train_loss: 1013.5695668312435, val_loss: 919.655106198236
Validation loss decreased (997.001945 --> 996.936006).  Saving model ...
Epoch 1174, train_loss: 1024.4047969462763, val_loss: 891.9090230714393
Validation loss decreased (996.936006 --> 996.846545).  Saving model ...
Epoch 1175, train_loss: 1018.088122886637, val_loss: 887.2009757118094
Validation loss decreased (996.846545 --> 996.753230).  Saving model ...
Epoch 1176, train_loss: 1010.5010197617477, val_loss: 911.121197306779
Validation loss decreased (996.753230 --> 996.680413).  Saving model ...
Epoch 1177, train_loss: 1019.065260930072, val_loss: 901.712803881588
Validation loss decreased (996.680413 --> 996.599727).  Saving model ...
Epoch 1178, train_loss: 1018.2936958084321, val_loss: 896.5972510596121
Validation loss decreased (996.599727 --> 996.514836).  Saving model ...
Epoch 1179, train_loss: 1006.1358668974284, val_loss: 915.1221778876916
Validation loss decreased (996.514836 --> 996.445800).  Saving model ...
Epoch 1180, train_loss: 1029.9862541391262, val_loss: 891.3365910248846
Validation loss decreased (996.445800 --> 996.356725).  Saving model ...
Epoch 1181, train_loss: 1007.67229963155, val_loss: 916.4460978732067
Validation loss decreased (996.356725 --> 996.289061).  Saving model ...
Epoch 1182, train_loss: 1024.7742820624132, val_loss: 892.8933650517025
Validation loss decreased (996.289061 --> 996.201586).  Saving model ...
Epoch 1183, train_loss: 1014.0657214672092, val_loss: 895.936029341729
Validation loss decreased (996.201586 --> 996.116831).  Saving model ...
Epoch 1184, train_loss: 1019.1905035615758, val_loss: 893.7820659888012
Validation loss decreased (996.116831 --> 996.030399).  Saving model ...
Epoch 1185, train_loss: 1017.938415861925, val_loss: 880.2963076858613
Validation loss decreased (996.030399 --> 995.932733).  Saving model ...
Epoch 1186, train_loss: 1013.6087006146665, val_loss: 906.1130200960241
Validation loss decreased (995.932733 --> 995.857000).  Saving model ...
Epoch 1187, train_loss: 1014.7526589214251, val_loss: 903.5525239669836
Validation loss decreased (995.857000 --> 995.779237).  Saving model ...
Epoch 1188, train_loss: 1015.2941543720979, val_loss: 883.3535988841016
Validation loss decreased (995.779237 --> 995.684603).  Saving model ...
Epoch 1189, train_loss: 1009.3527062528575, val_loss: 882.625070945356
Validation loss decreased (995.684603 --> 995.589515).  Saving model ...
Epoch 1190, train_loss: 1016.5896196769305, val_loss: 888.3141723067897
Validation loss decreased (995.589515 --> 995.499367).  Saving model ...
Epoch 1191, train_loss: 1012.5298460641649, val_loss: 895.2760680961832
Validation loss decreased (995.499367 --> 995.415217).  Saving model ...
Epoch 1192, train_loss: 1015.0543400678185, val_loss: 891.0000300849368
Validation loss decreased (995.415217 --> 995.327620).  Saving model ...
Epoch 1193, train_loss: 1018.677422024565, val_loss: 886.2170128894517
Validation loss decreased (995.327620 --> 995.236161).  Saving model ...
Epoch 1194, train_loss: 1012.6016296557351, val_loss: 901.4915300176322
Validation loss decreased (995.236161 --> 995.157648).  Saving model ...
Epoch 1195, train_loss: 1009.2037820671293, val_loss: 914.8298856001212
Validation loss decreased (995.157648 --> 995.090428).  Saving model ...
Epoch 1196, train_loss: 1013.7397995646043, val_loss: 906.3448949322218
Validation loss decreased (995.090428 --> 995.016226).  Saving model ...
Epoch 1197, train_loss: 1020.6686297712534, val_loss: 889.5290397443376
Validation loss decreased (995.016226 --> 994.928100).  Saving model ...
Epoch 1198, train_loss: 1009.0670168903523, val_loss: 905.6349766136319
Validation loss decreased (994.928100 --> 994.853565).  Saving model ...
Epoch 1199, train_loss: 1014.0408337074848, val_loss: 893.9762536609838
Validation loss decreased (994.853565 --> 994.769430).  Saving model ...
Epoch 1200, train_loss: 1015.455541269118, val_loss: 903.6664946212812
Validation loss decreased (994.769430 --> 994.693511).  Saving model ...
Epoch 1201, train_loss: 1012.7131506570468, val_loss: 895.6365180502338
Validation loss decreased (994.693511 --> 994.611032).  Saving model ...
Epoch 1202, train_loss: 1008.1559763688987, val_loss: 893.1343075327304
Validation loss decreased (994.611032 --> 994.526609).  Saving model ...
Epoch 1203, train_loss: 1016.7084963360348, val_loss: 895.7906721806088
Validation loss decreased (994.526609 --> 994.444534).  Saving model ...
Epoch 1204, train_loss: 1017.0391142190499, val_loss: 880.7379060031312
Validation loss decreased (994.444534 --> 994.350094).  Saving model ...
Epoch 1205, train_loss: 1014.1840158469447, val_loss: 872.3846557135275
Validation loss decreased (994.350094 --> 994.248878).  Saving model ...
Epoch 1206, train_loss: 1006.2709251569669, val_loss: 897.9693477929745
Validation loss decreased (994.248878 --> 994.169044).  Saving model ...
Epoch 1207, train_loss: 1010.93549929002, val_loss: 898.2531208482056
Validation loss decreased (994.169044 --> 994.089577).  Saving model ...
Epoch 1208, train_loss: 1018.1849700363771, val_loss: 899.358550899338
Validation loss decreased (994.089577 --> 994.011158).  Saving model ...
Epoch 1209, train_loss: 1016.3717230291744, val_loss: 897.6985846300921
Validation loss decreased (994.011158 --> 993.931495).  Saving model ...
Epoch 1210, train_loss: 1012.8387499478416, val_loss: 891.9854007592911
Validation loss decreased (993.931495 --> 993.847242).  Saving model ...
Epoch 1211, train_loss: 1012.9578213364501, val_loss: 924.0249677981936
Validation loss decreased (993.847242 --> 993.789585).  Saving model ...
Epoch 1212, train_loss: 1021.2155930926407, val_loss: 886.175309414312
Validation loss decreased (993.789585 --> 993.700794).  Saving model ...
Epoch 1213, train_loss: 1014.9223253438577, val_loss: 875.2682286196508
Validation loss decreased (993.700794 --> 993.603158).  Saving model ...
Epoch 1214, train_loss: 1011.923226013378, val_loss: 888.4353999838787
Validation loss decreased (993.603158 --> 993.516529).  Saving model ...
Epoch 1215, train_loss: 1019.5185993417962, val_loss: 876.0268740496375
Validation loss decreased (993.516529 --> 993.419830).  Saving model ...
Epoch 1216, train_loss: 1005.0574653704265, val_loss: 894.5337861531315
Validation loss decreased (993.419830 --> 993.338509).  Saving model ...
Epoch 1217, train_loss: 1022.4960126145361, val_loss: 876.5101511734729
Validation loss decreased (993.338509 --> 993.242512).  Saving model ...
Epoch 1218, train_loss: 1011.4000956968941, val_loss: 874.0857788038479
Validation loss decreased (993.242512 --> 993.144682).  Saving model ...
Epoch 1219, train_loss: 1005.251673316033, val_loss: 897.3321621293054
Validation loss decreased (993.144682 --> 993.066083).  Saving model ...
Epoch 1220, train_loss: 1014.0502189717694, val_loss: 907.3587002845829
Validation loss decreased (993.066083 --> 992.995831).  Saving model ...
Epoch 1221, train_loss: 1007.2893894666653, val_loss: 900.6182974617573
Validation loss decreased (992.995831 --> 992.920174).  Saving model ...
Epoch 1222, train_loss: 1009.4182072847846, val_loss: 882.5283488553105
Validation loss decreased (992.920174 --> 992.829837).  Saving model ...
Epoch 1223, train_loss: 1012.6179717777088, val_loss: 892.7077979659815
Validation loss decreased (992.829837 --> 992.747971).  Saving model ...
Epoch 1224, train_loss: 1011.9437363876314, val_loss: 903.9914868111745
Validation loss decreased (992.747971 --> 992.675457).  Saving model ...
Epoch 1225, train_loss: 1012.0557572618889, val_loss: 895.9415208107897
Validation loss decreased (992.675457 --> 992.596491).  Saving model ...
Epoch 1226, train_loss: 1012.2357557510871, val_loss: 886.292600002797
Validation loss decreased (992.596491 --> 992.509783).  Saving model ...
Epoch 1227, train_loss: 1007.6390043931448, val_loss: 882.598475503061
Validation loss decreased (992.509783 --> 992.420206).  Saving model ...
Epoch 1228, train_loss: 1012.2982433560479, val_loss: 890.5322309792928
Validation loss decreased (992.420206 --> 992.337235).  Saving model ...
Epoch 1229, train_loss: 1013.218405496582, val_loss: 895.1815678953025
Validation loss decreased (992.337235 --> 992.258182).  Saving model ...
Epoch 1230, train_loss: 1008.7466048260349, val_loss: 893.2485141854598
Validation loss decreased (992.258182 --> 992.177687).  Saving model ...
Epoch 1231, train_loss: 1007.3066509617607, val_loss: 911.4277856407125
Validation loss decreased (992.177687 --> 992.112090).  Saving model ...
Epoch 1232, train_loss: 1014.7440496803372, val_loss: 879.8784242288056
Validation loss decreased (992.112090 --> 992.020991).  Saving model ...
Epoch 1233, train_loss: 1014.9671572190106, val_loss: 870.1295062895839
Validation loss decreased (992.020991 --> 991.922133).  Saving model ...
Epoch 1234, train_loss: 1013.7378623957444, val_loss: 875.5384509720411
Validation loss decreased (991.922133 --> 991.827819).  Saving model ...
Epoch 1235, train_loss: 1005.8931783433951, val_loss: 879.478419539112
Validation loss decreased (991.827819 --> 991.736848).  Saving model ...
Epoch 1236, train_loss: 1002.4454812415541, val_loss: 893.0738654615926
Validation loss decreased (991.736848 --> 991.657024).  Saving model ...
Epoch 1237, train_loss: 1004.8907386458078, val_loss: 910.2371977869674
Validation loss decreased (991.657024 --> 991.591203).  Saving model ...
Epoch 1238, train_loss: 1016.7023867601154, val_loss: 871.787440447587
Validation loss decreased (991.591203 --> 991.494431).  Saving model ...
Epoch 1239, train_loss: 1000.633836053421, val_loss: 885.9740329945535
Validation loss decreased (991.494431 --> 991.409265).  Saving model ...
Epoch 1240, train_loss: 1009.0753536812282, val_loss: 882.2293459711476
Validation loss decreased (991.409265 --> 991.321217).  Saving model ...
Epoch 1241, train_loss: 1000.2782955699215, val_loss: 882.2555206550277
Validation loss decreased (991.321217 --> 991.233332).  Saving model ...
Epoch 1242, train_loss: 1009.7897846002242, val_loss: 880.4902862737803
Validation loss decreased (991.233332 --> 991.144167).  Saving model ...
Epoch 1243, train_loss: 1010.9947295436788, val_loss: 893.6705920633345
Validation loss decreased (991.144167 --> 991.065749).  Saving model ...
Epoch 1244, train_loss: 1006.7527398113373, val_loss: 893.0456032961832
Validation loss decreased (991.065749 --> 990.986954).  Saving model ...
Epoch 1245, train_loss: 1011.0575876310419, val_loss: 890.4771426633774
Validation loss decreased (990.986954 --> 990.906224).  Saving model ...
Epoch 1246, train_loss: 1014.9738419280826, val_loss: 870.7407837051156
Validation loss decreased (990.906224 --> 990.809783).  Saving model ...
Epoch 1247, train_loss: 1008.1818255322861, val_loss: 869.0456297702264
Validation loss decreased (990.809783 --> 990.712137).  Saving model ...
Epoch 1248, train_loss: 1005.7140120302599, val_loss: 887.997990067138
Validation loss decreased (990.712137 --> 990.629834).  Saving model ...
Epoch 1249, train_loss: 1008.6966567219077, val_loss: 876.4549639053703
Validation loss decreased (990.629834 --> 990.538421).  Saving model ...
Epoch 1250, train_loss: 1013.3747714662512, val_loss: 877.9624125518407
Validation loss decreased (990.538421 --> 990.448360).  Saving model ...
Epoch 1251, train_loss: 1012.5680021997343, val_loss: 877.4339741785442
Validation loss decreased (990.448360 --> 990.358021).  Saving model ...
Epoch 1252, train_loss: 1004.9644344099798, val_loss: 876.9971263155898
Validation loss decreased (990.358021 --> 990.267477).  Saving model ...
Epoch 1253, train_loss: 1007.626514172564, val_loss: 880.7467412092955
Validation loss decreased (990.267477 --> 990.180070).  Saving model ...
Epoch 1254, train_loss: 1004.1883067414265, val_loss: 889.3535461215182
Validation loss decreased (990.180070 --> 990.099666).  Saving model ...
Epoch 1255, train_loss: 1013.3659190909881, val_loss: 890.9383058054583
Validation loss decreased (990.099666 --> 990.020653).  Saving model ...
Epoch 1256, train_loss: 1004.9896807317135, val_loss: 882.6696317585534
Validation loss decreased (990.020653 --> 989.935183).  Saving model ...
Epoch 1257, train_loss: 1012.3099973510381, val_loss: 871.4440159440045
Validation loss decreased (989.935183 --> 989.840918).  Saving model ...
Epoch 1258, train_loss: 1007.1932496717058, val_loss: 873.3850580036865
Validation loss decreased (989.840918 --> 989.748345).  Saving model ...
Epoch 1259, train_loss: 999.8449373331393, val_loss: 888.4241460582948
Validation loss decreased (989.748345 --> 989.667866).  Saving model ...
Epoch 1260, train_loss: 1009.3177618705237, val_loss: 874.8666950697153
Validation loss decreased (989.667866 --> 989.576753).  Saving model ...
Epoch 1261, train_loss: 1007.7136963871601, val_loss: 890.1716591881163
Validation loss decreased (989.576753 --> 989.497923).  Saving model ...
Epoch 1262, train_loss: 1011.2408968977844, val_loss: 884.2281440490707
Validation loss decreased (989.497923 --> 989.414508).  Saving model ...
Epoch 1263, train_loss: 1004.7402424801433, val_loss: 880.2968353548762
Validation loss decreased (989.414508 --> 989.328112).  Saving model ...
Epoch 1264, train_loss: 1003.259773359852, val_loss: 904.1957283248286
Validation loss decreased (989.328112 --> 989.260761).  Saving model ...
Epoch 1265, train_loss: 1024.0325016944894, val_loss: 868.4899766603447
Validation loss decreased (989.260761 --> 989.165290).  Saving model ...
Epoch 1266, train_loss: 1003.3316129821126, val_loss: 867.7007264976154
Validation loss decreased (989.165290 --> 989.069346).  Saving model ...
Epoch 1267, train_loss: 1007.3246634133667, val_loss: 865.6311797819317
Validation loss decreased (989.069346 --> 988.971921).  Saving model ...
Epoch 1268, train_loss: 1002.1637069908498, val_loss: 891.6719308875449
Validation loss decreased (988.971921 --> 988.895186).  Saving model ...
Epoch 1269, train_loss: 1009.7699097845021, val_loss: 869.0454394415577
Validation loss decreased (988.895186 --> 988.800742).  Saving model ...
Epoch 1270, train_loss: 1005.0366006803752, val_loss: 871.9615517199046
Validation loss decreased (988.800742 --> 988.708742).  Saving model ...
Epoch 1271, train_loss: 1007.3813530406263, val_loss: 873.2394295518051
Validation loss decreased (988.708742 --> 988.617893).  Saving model ...
Epoch 1272, train_loss: 1001.7417092910626, val_loss: 884.7721873955599
Validation loss decreased (988.617893 --> 988.536253).  Saving model ...
Epoch 1273, train_loss: 1002.9115234631832, val_loss: 882.899590285752
Validation loss decreased (988.536253 --> 988.453271).  Saving model ...
Epoch 1274, train_loss: 1007.5932825092098, val_loss: 878.1644704959134
Validation loss decreased (988.453271 --> 988.366702).  Saving model ...
Epoch 1275, train_loss: 1003.5100009268674, val_loss: 893.635172220491
Validation loss decreased (988.366702 --> 988.292403).  Saving model ...
Epoch 1276, train_loss: 1006.622210228397, val_loss: 877.8163237392906
Validation loss decreased (988.292403 --> 988.205823).  Saving model ...
Epoch 1277, train_loss: 1006.299208010464, val_loss: 868.8165653713991
Validation loss decreased (988.205823 --> 988.112331).  Saving model ...
Epoch 1278, train_loss: 1000.526430998521, val_loss: 886.4724280156474
Validation loss decreased (988.112331 --> 988.032800).  Saving model ...
Epoch 1279, train_loss: 1008.1070317180148, val_loss: 865.8235788899665
Validation loss decreased (988.032800 --> 987.937250).  Saving model ...
Epoch 1280, train_loss: 1012.4377934397372, val_loss: 859.057271240663
Validation loss decreased (987.937250 --> 987.836562).  Saving model ...
Epoch 1281, train_loss: 1000.6184940445239, val_loss: 870.0326797129936
Validation loss decreased (987.836562 --> 987.744600).  Saving model ...
Epoch 1282, train_loss: 1002.4374698847596, val_loss: 867.8883356117767
Validation loss decreased (987.744600 --> 987.651108).  Saving model ...
Epoch 1283, train_loss: 1011.173892942511, val_loss: 856.2632140912838
Validation loss decreased (987.651108 --> 987.548701).  Saving model ...
Epoch 1284, train_loss: 1000.8151106849133, val_loss: 866.6712189579897
Validation loss decreased (987.548701 --> 987.454560).  Saving model ...
Epoch 1285, train_loss: 1006.3264755554246, val_loss: 870.0847863409703
Validation loss decreased (987.454560 --> 987.363222).  Saving model ...
Epoch 1286, train_loss: 995.4820106821078, val_loss: 881.2851974378256
Validation loss decreased (987.363222 --> 987.280735).  Saving model ...
Epoch 1287, train_loss: 1009.1389928068245, val_loss: 869.0631618778137
Validation loss decreased (987.280735 --> 987.188880).  Saving model ...
Epoch 1288, train_loss: 1004.5417776228194, val_loss: 879.0427271933914
Validation loss decreased (987.188880 --> 987.104915).  Saving model ...
Epoch 1289, train_loss: 1000.2258215866731, val_loss: 883.6908761867776
Validation loss decreased (987.104915 --> 987.024687).  Saving model ...
Epoch 1290, train_loss: 1008.0529908840393, val_loss: 867.1419596023255
Validation loss decreased (987.024687 --> 986.931755).  Saving model ...
Epoch 1291, train_loss: 1003.0611487396756, val_loss: 869.7959208297734
Validation loss decreased (986.931755 --> 986.841022).  Saving model ...
Epoch 1292, train_loss: 1008.3803064099726, val_loss: 867.6046775406603
Validation loss decreased (986.841022 --> 986.748734).  Saving model ...
Epoch 1293, train_loss: 999.1673027686995, val_loss: 891.5743774809445
Validation loss decreased (986.748734 --> 986.675127).  Saving model ...
Epoch 1294, train_loss: 1008.2628620062807, val_loss: 882.930368066298
Validation loss decreased (986.675127 --> 986.594953).  Saving model ...
Epoch 1295, train_loss: 1007.2602016865077, val_loss: 874.0108865878543
Validation loss decreased (986.594953 --> 986.508015).  Saving model ...
Epoch 1296, train_loss: 1009.2218369246006, val_loss: 859.859814369392
Validation loss decreased (986.508015 --> 986.410293).  Saving model ...
Epoch 1297, train_loss: 994.3984188510743, val_loss: 881.7893750330036
Validation loss decreased (986.410293 --> 986.329629).  Saving model ...
Epoch 1298, train_loss: 1007.8332983653745, val_loss: 871.6340295663813
Validation loss decreased (986.329629 --> 986.241266).  Saving model ...
Epoch 1299, train_loss: 1002.4530235348764, val_loss: 873.3042420230757
Validation loss decreased (986.241266 --> 986.154324).  Saving model ...
Epoch 1300, train_loss: 1004.4332587413093, val_loss: 882.2360977064685
Validation loss decreased (986.154324 --> 986.074387).  Saving model ...
Epoch 1301, train_loss: 1000.730284145059, val_loss: 880.7507425634072
Validation loss decreased (986.074387 --> 985.993431).  Saving model ...
Epoch 1302, train_loss: 1002.7062484445605, val_loss: 875.1973966168702
Validation loss decreased (985.993431 --> 985.908335).  Saving model ...
Epoch 1303, train_loss: 1007.0937337736059, val_loss: 865.0292806165531
Validation loss decreased (985.908335 --> 985.815565).  Saving model ...
Epoch 1304, train_loss: 998.8475771549729, val_loss: 874.8144855001684
Validation loss decreased (985.815565 --> 985.730441).  Saving model ...
Epoch 1305, train_loss: 1000.7760047223036, val_loss: 872.8479617072925
Validation loss decreased (985.730441 --> 985.643941).  Saving model ...
Epoch 1306, train_loss: 1004.1432696417405, val_loss: 863.6260660535986
Validation loss decreased (985.643941 --> 985.550513).  Saving model ...
Epoch 1307, train_loss: 1001.3996977788505, val_loss: 866.9486671678893
Validation loss decreased (985.550513 --> 985.459769).  Saving model ...
Epoch 1308, train_loss: 995.9140304121904, val_loss: 874.7513987250023
Validation loss decreased (985.459769 --> 985.375130).  Saving model ...
Epoch 1309, train_loss: 1000.0074662190594, val_loss: 880.9030619435183
Validation loss decreased (985.375130 --> 985.295319).  Saving model ...
Epoch 1310, train_loss: 1004.1530492581079, val_loss: 870.1068316566067
Validation loss decreased (985.295319 --> 985.207389).  Saving model ...
Epoch 1311, train_loss: 1006.3395807391753, val_loss: 855.3466651093742
Validation loss decreased (985.207389 --> 985.108334).  Saving model ...
Epoch 1312, train_loss: 1002.3370486914655, val_loss: 862.741798484591
Validation loss decreased (985.108334 --> 985.015067).  Saving model ...
Epoch 1313, train_loss: 996.3037336443876, val_loss: 868.4577111565632
Validation loss decreased (985.015067 --> 984.926295).  Saving model ...
Epoch 1314, train_loss: 994.5442510501597, val_loss: 887.6418524524464
Validation loss decreased (984.926295 --> 984.852258).  Saving model ...
Epoch 1315, train_loss: 1010.5747123460923, val_loss: 865.9987697516773
Validation loss decreased (984.852258 --> 984.761875).  Saving model ...
Epoch 1316, train_loss: 996.5909053197418, val_loss: 873.112165280559
Validation loss decreased (984.761875 --> 984.677035).  Saving model ...
Epoch 1317, train_loss: 1004.2648103469434, val_loss: 879.1472114507142
Validation loss decreased (984.677035 --> 984.596906).  Saving model ...
Epoch 1318, train_loss: 1009.4753210451636, val_loss: 863.9765688284023
Validation loss decreased (984.596906 --> 984.505389).  Saving model ...
Epoch 1319, train_loss: 995.9930544352441, val_loss: 876.7003468478393
Validation loss decreased (984.505389 --> 984.423656).  Saving model ...
Epoch 1320, train_loss: 1009.0264986709627, val_loss: 862.1356451906987
Validation loss decreased (984.423656 --> 984.331014).  Saving model ...
Epoch 1321, train_loss: 996.4223739605535, val_loss: 876.1313384468253
Validation loss decreased (984.331014 --> 984.249106).  Saving model ...
Epoch 1322, train_loss: 1004.3842315931171, val_loss: 859.6483760008773
Validation loss decreased (984.249106 --> 984.154855).  Saving model ...
Epoch 1323, train_loss: 1006.256961947766, val_loss: 875.5798049144619
Validation loss decreased (984.154855 --> 984.072787).  Saving model ...
Epoch 1324, train_loss: 999.3733376650454, val_loss: 873.7144345880223
Validation loss decreased (984.072787 --> 983.989435).  Saving model ...
Epoch 1325, train_loss: 1000.0233250356058, val_loss: 872.5651292243937
Validation loss decreased (983.989435 --> 983.905341).  Saving model ...
Epoch 1326, train_loss: 998.1929888547573, val_loss: 868.1141151212328
Validation loss decreased (983.905341 --> 983.818018).  Saving model ...
Epoch 1327, train_loss: 1002.2991438164466, val_loss: 866.4887717750785
Validation loss decreased (983.818018 --> 983.729601).  Saving model ...
Epoch 1328, train_loss: 993.1396710131949, val_loss: 890.9493100319529
Validation loss decreased (983.729601 --> 983.659736).  Saving model ...
Epoch 1329, train_loss: 1005.7958426632113, val_loss: 875.4801304004154
Validation loss decreased (983.659736 --> 983.578337).  Saving model ...
Epoch 1330, train_loss: 1001.7456138944393, val_loss: 865.031078099344
Validation loss decreased (983.578337 --> 983.489203).  Saving model ...
Epoch 1331, train_loss: 996.7160604133503, val_loss: 859.358697138694
Validation loss decreased (983.489203 --> 983.395942).  Saving model ...
Epoch 1332, train_loss: 997.176622442443, val_loss: 866.3405072634314
Validation loss decreased (983.395942 --> 983.308063).  Saving model ...
Epoch 1333, train_loss: 999.1662800411723, val_loss: 857.4690880486042
Validation loss decreased (983.308063 --> 983.213660).  Saving model ...
Epoch 1334, train_loss: 1000.6763706332115, val_loss: 865.3291456011935
Validation loss decreased (983.213660 --> 983.125291).  Saving model ...
Epoch 1335, train_loss: 994.4801647641561, val_loss: 867.4239558762757
Validation loss decreased (983.125291 --> 983.038623).  Saving model ...
Epoch 1336, train_loss: 999.6775169231177, val_loss: 860.0985931069326
Validation loss decreased (983.038623 --> 982.946602).  Saving model ...
Epoch 1337, train_loss: 997.4747718917248, val_loss: 867.9048333947972
Validation loss decreased (982.946602 --> 982.860558).  Saving model ...
Epoch 1338, train_loss: 996.9435744591703, val_loss: 855.7058640791096
Validation loss decreased (982.860558 --> 982.765524).  Saving model ...
Epoch 1339, train_loss: 996.9422199989133, val_loss: 861.3228565220926
Validation loss decreased (982.765524 --> 982.674828).  Saving model ...
Epoch 1340, train_loss: 991.7231048121396, val_loss: 871.3993218889286
Validation loss decreased (982.674828 --> 982.591786).  Saving model ...
Epoch 1341, train_loss: 1001.3872027492678, val_loss: 863.2359192123462
Validation loss decreased (982.591786 --> 982.502781).  Saving model ...
Epoch 1342, train_loss: 993.7404590718428, val_loss: 861.2382585548035
Validation loss decreased (982.502781 --> 982.412420).  Saving model ...
Epoch 1343, train_loss: 999.7226981311203, val_loss: 861.7881264978652
Validation loss decreased (982.412420 --> 982.322603).  Saving model ...
Epoch 1344, train_loss: 1005.5931923240721, val_loss: 856.5416706490964
Validation loss decreased (982.322603 --> 982.229016).  Saving model ...
Epoch 1345, train_loss: 1001.6399968230498, val_loss: 852.7357969813439
Validation loss decreased (982.229016 --> 982.132738).  Saving model ...
Epoch 1346, train_loss: 989.6424835529227, val_loss: 874.7008473089894
Validation loss decreased (982.132738 --> 982.052923).  Saving model ...
Epoch 1347, train_loss: 1001.215368132299, val_loss: 860.1326666058659
Validation loss decreased (982.052923 --> 981.962410).  Saving model ...
Epoch 1348, train_loss: 1006.3408693922671, val_loss: 853.5515787810754
Validation loss decreased (981.962410 --> 981.867150).  Saving model ...
Epoch 1349, train_loss: 995.9920684491651, val_loss: 854.3373040477883
Validation loss decreased (981.867150 --> 981.772614).  Saving model ...
Epoch 1350, train_loss: 995.4261422569753, val_loss: 866.9421743888993
Validation loss decreased (981.772614 --> 981.687554).  Saving model ...
Epoch 1351, train_loss: 996.1635015808135, val_loss: 861.6403085160701
Validation loss decreased (981.687554 --> 981.598696).  Saving model ...
Epoch 1352, train_loss: 1000.9154800607712, val_loss: 860.110953026304
Validation loss decreased (981.598696 --> 981.508838).  Saving model ...
Epoch 1353, train_loss: 992.0423933584162, val_loss: 865.701436184314
Validation loss decreased (981.508838 --> 981.423245).  Saving model ...
Epoch 1354, train_loss: 993.6032429785674, val_loss: 859.99858738354
Validation loss decreased (981.423245 --> 981.333567).  Saving model ...
Epoch 1355, train_loss: 1002.0088181279112, val_loss: 859.527999717969
Validation loss decreased (981.333567 --> 981.243673).  Saving model ...
Epoch 1356, train_loss: 987.7549828963527, val_loss: 874.9608523244555
Validation loss decreased (981.243673 --> 981.165293).  Saving model ...
Epoch 1357, train_loss: 1002.9905709959555, val_loss: 856.311927701125
Validation loss decreased (981.165293 --> 981.073287).  Saving model ...
Epoch 1358, train_loss: 994.4145985033413, val_loss: 860.3236182537348
Validation loss decreased (981.073287 --> 980.984369).  Saving model ...
Epoch 1359, train_loss: 1002.6305267641537, val_loss: 857.7440085022985
Validation loss decreased (980.984369 --> 980.893685).  Saving model ...
Epoch 1360, train_loss: 989.7269579381276, val_loss: 878.7023877604144
Validation loss decreased (980.893685 --> 980.818544).  Saving model ...
Epoch 1361, train_loss: 997.6338039223604, val_loss: 858.9637856264471
Validation loss decreased (980.818544 --> 980.729011).  Saving model ...
Epoch 1362, train_loss: 993.9767653244172, val_loss: 866.0579835977163
Validation loss decreased (980.729011 --> 980.644818).  Saving model ...
Epoch 1363, train_loss: 996.7568697530372, val_loss: 864.9122709011375
Validation loss decreased (980.644818 --> 980.559908).  Saving model ...
Epoch 1364, train_loss: 999.7994392711696, val_loss: 854.1329238813897
Validation loss decreased (980.559908 --> 980.467219).  Saving model ...
Epoch 1365, train_loss: 993.7253791842201, val_loss: 866.0740172174909
Validation loss decreased (980.467219 --> 980.383415).  Saving model ...
Epoch 1366, train_loss: 992.8057938453279, val_loss: 865.5866386845379
Validation loss decreased (980.383415 --> 980.299376).  Saving model ...
Epoch 1367, train_loss: 990.8439001042079, val_loss: 883.3978520430904
Validation loss decreased (980.299376 --> 980.228490).  Saving model ...
Epoch 1368, train_loss: 998.3117698399568, val_loss: 863.639173296271
Validation loss decreased (980.228490 --> 980.143264).  Saving model ...
Epoch 1369, train_loss: 995.9395779675303, val_loss: 855.3114282179323
Validation loss decreased (980.143264 --> 980.052079).  Saving model ...
Epoch 1370, train_loss: 994.9604976398239, val_loss: 858.7631520469768
Validation loss decreased (980.052079 --> 979.963547).  Saving model ...
Epoch 1371, train_loss: 992.4683944869103, val_loss: 868.2302897189285
Validation loss decreased (979.963547 --> 979.882049).  Saving model ...
Epoch 1372, train_loss: 999.8796680154461, val_loss: 854.3524862711744
Validation loss decreased (979.882049 --> 979.790555).  Saving model ...
Epoch 1373, train_loss: 996.6061224973212, val_loss: 857.6527839795975
Validation loss decreased (979.790555 --> 979.701598).  Saving model ...
Epoch 1374, train_loss: 994.8828352942365, val_loss: 865.2478396901162
Validation loss decreased (979.701598 --> 979.618299).  Saving model ...
Epoch 1375, train_loss: 995.3016328580144, val_loss: 855.4057524834301
Validation loss decreased (979.618299 --> 979.527962).  Saving model ...
Epoch 1376, train_loss: 997.466599176083, val_loss: 854.0917611125888
Validation loss decreased (979.527962 --> 979.436802).  Saving model ...
Epoch 1377, train_loss: 992.5161037813156, val_loss: 864.3205215629829
Validation loss decreased (979.436802 --> 979.353203).  Saving model ...
Epoch 1378, train_loss: 995.8125869287871, val_loss: 866.2719023317765
Validation loss decreased (979.353203 --> 979.271141).  Saving model ...
Epoch 1379, train_loss: 990.8155324939611, val_loss: 865.9319582109985
Validation loss decreased (979.271141 --> 979.188952).  Saving model ...
Epoch 1380, train_loss: 996.0821265324529, val_loss: 868.9647080738682
Validation loss decreased (979.188952 --> 979.109079).  Saving model ...
Epoch 1381, train_loss: 1000.6746630115883, val_loss: 859.1914153227767
Validation loss decreased (979.109079 --> 979.022245).  Saving model ...
Epoch 1382, train_loss: 994.9136258813604, val_loss: 854.4969451349976
Validation loss decreased (979.022245 --> 978.932140).  Saving model ...
Epoch 1383, train_loss: 995.4455790083244, val_loss: 852.0107397304204
Validation loss decreased (978.932140 --> 978.840367).  Saving model ...
Epoch 1384, train_loss: 990.252536810321, val_loss: 856.467329370711
Validation loss decreased (978.840367 --> 978.751948).  Saving model ...
Epoch 1385, train_loss: 991.569661844771, val_loss: 874.9020891301725
Validation loss decreased (978.751948 --> 978.676966).  Saving model ...
Epoch 1386, train_loss: 1004.5138183693996, val_loss: 849.479868218259
Validation loss decreased (978.676966 --> 978.583750).  Saving model ...
Epoch 1387, train_loss: 990.5039388223553, val_loss: 849.7562895363793
Validation loss decreased (978.583750 --> 978.490868).  Saving model ...
Epoch 1388, train_loss: 983.8702705773542, val_loss: 859.3529396420942
Validation loss decreased (978.490868 --> 978.405034).  Saving model ...
Epoch 1389, train_loss: 994.5535171558565, val_loss: 860.2252990874762
Validation loss decreased (978.405034 --> 978.319951).  Saving model ...
Epoch 1390, train_loss: 991.6730742209114, val_loss: 857.0915360095106
Validation loss decreased (978.319951 --> 978.232736).  Saving model ...
Epoch 1391, train_loss: 992.5499504859068, val_loss: 852.842342143898
Validation loss decreased (978.232736 --> 978.142592).  Saving model ...
Epoch 1392, train_loss: 991.4450808549225, val_loss: 850.8039980375106
Validation loss decreased (978.142592 --> 978.051113).  Saving model ...
Epoch 1393, train_loss: 986.6129105967203, val_loss: 853.359911434165
Validation loss decreased (978.051113 --> 977.961601).  Saving model ...
Epoch 1394, train_loss: 988.8803444184545, val_loss: 848.6876624619302
Validation loss decreased (977.961601 --> 977.868865).  Saving model ...
Epoch 1395, train_loss: 986.4941429279116, val_loss: 867.649591749973
Validation loss decreased (977.868865 --> 977.789855).  Saving model ...
Epoch 1396, train_loss: 992.5560442501923, val_loss: 861.1306691868222
Validation loss decreased (977.789855 --> 977.706288).  Saving model ...
Epoch 1397, train_loss: 993.921902144614, val_loss: 852.2787468237792
Validation loss decreased (977.706288 --> 977.616504).  Saving model ...
Epoch 1398, train_loss: 989.8893982802937, val_loss: 865.414605554144
Validation loss decreased (977.616504 --> 977.536245).  Saving model ...
Epoch 1399, train_loss: 988.2617480577898, val_loss: 879.485466859098
Validation loss decreased (977.536245 --> 977.466159).  Saving model ...
Epoch 1400, train_loss: 995.7838030373716, val_loss: 866.3389772043848
Validation loss decreased (977.466159 --> 977.386783).  Saving model ...
Epoch 1401, train_loss: 991.8025332972512, val_loss: 847.3918711737352
Validation loss decreased (977.386783 --> 977.293995).  Saving model ...
Epoch 1402, train_loss: 993.2761113803257, val_loss: 848.8087694493491
Validation loss decreased (977.293995 --> 977.202351).  Saving model ...
Epoch 1403, train_loss: 992.9216718444338, val_loss: 844.3181064486507
Validation loss decreased (977.202351 --> 977.107637).  Saving model ...
Epoch 1404, train_loss: 993.2998652071723, val_loss: 845.2033773641679
Validation loss decreased (977.107637 --> 977.013688).  Saving model ...
Epoch 1405, train_loss: 985.6190790075323, val_loss: 879.3429655273097
Validation loss decreased (977.013688 --> 976.944171).  Saving model ...
Epoch 1406, train_loss: 994.5021317602447, val_loss: 862.2674885483585
Validation loss decreased (976.944171 --> 976.862609).  Saving model ...
Epoch 1407, train_loss: 990.7355654071107, val_loss: 844.5038897440169
Validation loss decreased (976.862609 --> 976.768537).  Saving model ...
Epoch 1408, train_loss: 988.3496024753751, val_loss: 868.1121589837034
Validation loss decreased (976.768537 --> 976.691367).  Saving model ...
Epoch 1409, train_loss: 994.0222020964927, val_loss: 864.7853726670479
Validation loss decreased (976.691367 --> 976.611944).  Saving model ...
Epoch 1410, train_loss: 997.8977653893126, val_loss: 865.2011387281508
Validation loss decreased (976.611944 --> 976.532930).  Saving model ...
Epoch 1411, train_loss: 989.9307519312675, val_loss: 862.519272960756
Validation loss decreased (976.532930 --> 976.452126).  Saving model ...
Epoch 1412, train_loss: 991.0902234921348, val_loss: 847.9366181011555
Validation loss decreased (976.452126 --> 976.361109).  Saving model ...
Epoch 1413, train_loss: 987.5195383399969, val_loss: 852.2437086862328
Validation loss decreased (976.361109 --> 976.273270).  Saving model ...
Epoch 1414, train_loss: 989.8486947449677, val_loss: 852.7850517739856
Validation loss decreased (976.273270 --> 976.185937).  Saving model ...
Epoch 1415, train_loss: 988.4985239552324, val_loss: 856.0198505312209
Validation loss decreased (976.185937 --> 976.101014).  Saving model ...
Epoch 1416, train_loss: 985.8859581755659, val_loss: 848.3715536737445
Validation loss decreased (976.101014 --> 976.010810).  Saving model ...
Epoch 1417, train_loss: 991.4072013973307, val_loss: 857.2916700333138
Validation loss decreased (976.010810 --> 975.927028).  Saving model ...
Epoch 1418, train_loss: 987.398550667101, val_loss: 862.4933453464732
Validation loss decreased (975.927028 --> 975.847032).  Saving model ...
Epoch 1419, train_loss: 985.7322368596105, val_loss: 877.9202555201014
Validation loss decreased (975.847032 --> 975.778021).  Saving model ...
Epoch 1420, train_loss: 991.0114401318159, val_loss: 856.8430685508916
Validation loss decreased (975.778021 --> 975.694264).  Saving model ...
Epoch 1421, train_loss: 983.350005345588, val_loss: 837.4370805178529
Validation loss decreased (975.694264 --> 975.596968).  Saving model ...
Epoch 1422, train_loss: 989.990390813962, val_loss: 850.4235014488082
Validation loss decreased (975.596968 --> 975.508942).  Saving model ...
Epoch 1423, train_loss: 983.6557735336497, val_loss: 850.3531937567836
Validation loss decreased (975.508942 --> 975.420990).  Saving model ...
Epoch 1424, train_loss: 988.43434956607, val_loss: 856.5625378128337
Validation loss decreased (975.420990 --> 975.337522).  Saving model ...
Epoch 1425, train_loss: 988.1989297847384, val_loss: 863.7314595772824
Validation loss decreased (975.337522 --> 975.259202).  Saving model ...
Epoch 1426, train_loss: 995.8525799690702, val_loss: 851.3341721698093
Validation loss decreased (975.259202 --> 975.172298).  Saving model ...
Epoch 1427, train_loss: 980.4107812189832, val_loss: 858.8474256119907
Validation loss decreased (975.172298 --> 975.090781).  Saving model ...
Epoch 1428, train_loss: 992.8940234133752, val_loss: 860.209015110886
Validation loss decreased (975.090781 --> 975.010332).  Saving model ...
Epoch 1429, train_loss: 995.249834919394, val_loss: 864.9641547290929
Validation loss decreased (975.010332 --> 974.933322).  Saving model ...
Epoch 1430, train_loss: 980.6066708335145, val_loss: 862.7702622304363
Validation loss decreased (974.933322 --> 974.854887).  Saving model ...
Epoch 1431, train_loss: 987.0702340701326, val_loss: 869.3849332696424
Validation loss decreased (974.854887 --> 974.781183).  Saving model ...
Epoch 1432, train_loss: 983.7857895665572, val_loss: 871.5444105559591
Validation loss decreased (974.781183 --> 974.709090).  Saving model ...
Epoch 1433, train_loss: 988.3930057460083, val_loss: 849.180207026866
Validation loss decreased (974.709090 --> 974.621492).  Saving model ...
Epoch 1434, train_loss: 984.1472138855198, val_loss: 839.235844025568
Validation loss decreased (974.621492 --> 974.527080).  Saving model ...
Epoch 1435, train_loss: 982.1095629883491, val_loss: 845.1234766711572
Validation loss decreased (974.527080 --> 974.436904).  Saving model ...
Epoch 1436, train_loss: 990.1079312457551, val_loss: 861.0622584878075
Validation loss decreased (974.436904 --> 974.357952).  Saving model ...
Epoch 1437, train_loss: 982.0929775687497, val_loss: 839.683134511003
Validation loss decreased (974.357952 --> 974.264233).  Saving model ...
Epoch 1438, train_loss: 993.1605733756662, val_loss: 836.3421905979845
Validation loss decreased (974.264233 --> 974.168320).  Saving model ...
Epoch 1439, train_loss: 980.0307326661035, val_loss: 868.6842935110466
Validation loss decreased (974.168320 --> 974.095016).  Saving model ...
Epoch 1440, train_loss: 983.3083531381035, val_loss: 856.3241934837237
Validation loss decreased (974.095016 --> 974.013231).  Saving model ...
Epoch 1441, train_loss: 983.734398051137, val_loss: 847.6837005349224
Validation loss decreased (974.013231 --> 973.925563).  Saving model ...
Epoch 1442, train_loss: 988.8667815131766, val_loss: 857.7676488445646
Validation loss decreased (973.925563 --> 973.845010).  Saving model ...
Epoch 1443, train_loss: 988.1789427937266, val_loss: 852.6512434952571
Validation loss decreased (973.845010 --> 973.761022).  Saving model ...
Epoch 1444, train_loss: 986.7830504044101, val_loss: 873.5276441406104
Validation loss decreased (973.761022 --> 973.691609).  Saving model ...
Epoch 1445, train_loss: 986.2648224977344, val_loss: 843.1593432745449
Validation loss decreased (973.691609 --> 973.601275).  Saving model ...
Epoch 1446, train_loss: 976.014246566642, val_loss: 854.5430983269438
Validation loss decreased (973.601275 --> 973.518939).  Saving model ...
Epoch 1447, train_loss: 988.1846122418241, val_loss: 864.4216494815884
Validation loss decreased (973.518939 --> 973.443543).  Saving model ...
Epoch 1448, train_loss: 986.5578654447403, val_loss: 863.0179932856782
Validation loss decreased (973.443543 --> 973.367283).  Saving model ...
Epoch 1449, train_loss: 990.6930138328969, val_loss: 854.7638640216991
Validation loss decreased (973.367283 --> 973.285431).  Saving model ...
Epoch 1450, train_loss: 973.8881206788403, val_loss: 851.3891673273292
Validation loss decreased (973.285431 --> 973.201364).  Saving model ...
Epoch 1451, train_loss: 983.1621998032521, val_loss: 854.6210010661904
Validation loss decreased (973.201364 --> 973.119641).  Saving model ...
Epoch 1452, train_loss: 989.010303799109, val_loss: 846.5827610388952
Validation loss decreased (973.119641 --> 973.032494).  Saving model ...
Epoch 1453, train_loss: 984.5018112684022, val_loss: 832.2763767988373
Validation loss decreased (973.032494 --> 972.935622).  Saving model ...
Epoch 1454, train_loss: 976.8951615953034, val_loss: 863.4363911839331
Validation loss decreased (972.935622 --> 972.860313).  Saving model ...
Epoch 1455, train_loss: 981.9792407437455, val_loss: 842.6140153017312
Validation loss decreased (972.860313 --> 972.770796).  Saving model ...
Epoch 1456, train_loss: 984.6342372492484, val_loss: 841.5231409860984
Validation loss decreased (972.770796 --> 972.680654).  Saving model ...
Epoch 1457, train_loss: 978.9624377483336, val_loss: 859.7310909778765
Validation loss decreased (972.680654 --> 972.603132).  Saving model ...
Epoch 1458, train_loss: 993.1595929102936, val_loss: 840.0771565549908
Validation loss decreased (972.603132 --> 972.512236).  Saving model ...
Epoch 1459, train_loss: 977.8426804922984, val_loss: 859.5769924822562
Validation loss decreased (972.512236 --> 972.434830).  Saving model ...
Epoch 1460, train_loss: 974.5569057784378, val_loss: 873.1936485093615
Validation loss decreased (972.434830 --> 972.366857).  Saving model ...
Epoch 1461, train_loss: 987.2104821925093, val_loss: 851.8622276474812
Validation loss decreased (972.366857 --> 972.284376).  Saving model ...
Epoch 1462, train_loss: 989.2841850283613, val_loss: 840.4086956051547
Validation loss decreased (972.284376 --> 972.194174).  Saving model ...
Epoch 1463, train_loss: 986.1036753801997, val_loss: 843.1920591464753
Validation loss decreased (972.194174 --> 972.105997).  Saving model ...
Epoch 1464, train_loss: 987.0755845829198, val_loss: 854.5896356302063
Validation loss decreased (972.105997 --> 972.025726).  Saving model ...
Epoch 1465, train_loss: 989.3794494729582, val_loss: 836.2309050818286
Validation loss decreased (972.025726 --> 971.933034).  Saving model ...
Epoch 1466, train_loss: 979.4566930492254, val_loss: 852.666675686174
Validation loss decreased (971.933034 --> 971.851679).  Saving model ...
Epoch 1467, train_loss: 983.7848963198097, val_loss: 829.8861461117314
Validation loss decreased (971.851679 --> 971.754906).  Saving model ...
Epoch 1468, train_loss: 979.0706862991563, val_loss: 850.5270857896852
Validation loss decreased (971.754906 --> 971.672326).  Saving model ...
Epoch 1469, train_loss: 983.5023925091216, val_loss: 858.1770377680992
Validation loss decreased (971.672326 --> 971.595066).  Saving model ...
Epoch 1470, train_loss: 987.3504579427746, val_loss: 831.4570468417361
Validation loss decreased (971.595066 --> 971.499734).  Saving model ...
Epoch 1471, train_loss: 976.8929032484015, val_loss: 871.2414272889387
Validation loss decreased (971.499734 --> 971.431577).  Saving model ...
Epoch 1472, train_loss: 993.4122571054868, val_loss: 853.8801699692234
Validation loss decreased (971.431577 --> 971.351719).  Saving model ...
Epoch 1473, train_loss: 981.9774869128511, val_loss: 855.8638818811269
Validation loss decreased (971.351719 --> 971.273316).  Saving model ...
Epoch 1474, train_loss: 980.6628275697743, val_loss: 849.0381926230812
Validation loss decreased (971.273316 --> 971.190388).  Saving model ...
Epoch 1475, train_loss: 980.9570892615844, val_loss: 852.3051885822086
Validation loss decreased (971.190388 --> 971.109788).  Saving model ...
Epoch 1476, train_loss: 979.1220897771631, val_loss: 833.2866765987433
Validation loss decreased (971.109788 --> 971.016412).  Saving model ...
Epoch 1477, train_loss: 972.8388455539676, val_loss: 852.7734098275286
Validation loss decreased (971.016412 --> 970.936356).  Saving model ...
Epoch 1478, train_loss: 987.6598804241057, val_loss: 846.178256326693
Validation loss decreased (970.936356 --> 970.851946).  Saving model ...
Epoch 1479, train_loss: 977.5208282880284, val_loss: 850.4651383537717
Validation loss decreased (970.851946 --> 970.770548).  Saving model ...
Epoch 1480, train_loss: 988.438160461695, val_loss: 853.6252902517498
Validation loss decreased (970.770548 --> 970.691396).  Saving model ...
Epoch 1481, train_loss: 979.5041183730975, val_loss: 836.2710832096914
Validation loss decreased (970.691396 --> 970.600633).  Saving model ...
Epoch 1482, train_loss: 978.2742183469015, val_loss: 839.9683657232262
Validation loss decreased (970.600633 --> 970.512487).  Saving model ...
Epoch 1483, train_loss: 983.8745433493234, val_loss: 857.0263217133285
Validation loss decreased (970.512487 --> 970.435962).  Saving model ...
Epoch 1484, train_loss: 978.8996417235987, val_loss: 835.7982713913701
Validation loss decreased (970.435962 --> 970.345236).  Saving model ...
Epoch 1485, train_loss: 975.1003515704963, val_loss: 860.8137607274015
Validation loss decreased (970.345236 --> 970.271477).  Saving model ...
Epoch 1486, train_loss: 987.88030662917, val_loss: 835.8044031433709
Validation loss decreased (970.271477 --> 970.180988).  Saving model ...
Epoch 1487, train_loss: 973.001519379755, val_loss: 856.764309090354
Validation loss decreased (970.180988 --> 970.104716).  Saving model ...
Epoch 1488, train_loss: 984.1383320730421, val_loss: 839.0935098057106
Validation loss decreased (970.104716 --> 970.016671).  Saving model ...
Epoch 1489, train_loss: 980.3863934463005, val_loss: 859.2271174951617
Validation loss decreased (970.016671 --> 969.942265).  Saving model ...
Epoch 1490, train_loss: 977.7635412236162, val_loss: 844.4780131426787
Validation loss decreased (969.942265 --> 969.858061).  Saving model ...
Epoch 1491, train_loss: 979.5881039434779, val_loss: 849.9065062826212
Validation loss decreased (969.858061 --> 969.777611).  Saving model ...
Epoch 1492, train_loss: 978.4004028765822, val_loss: 852.5729870808347
Validation loss decreased (969.777611 --> 969.699055).  Saving model ...
Epoch 1493, train_loss: 988.7695741260346, val_loss: 832.6664343979405
Validation loss decreased (969.699055 --> 969.607272).  Saving model ...
Epoch 1494, train_loss: 980.3737294276027, val_loss: 834.877597346571
Validation loss decreased (969.607272 --> 969.517091).  Saving model ...
Epoch 1495, train_loss: 970.7428854337625, val_loss: 859.014044172212
Validation loss decreased (969.517091 --> 969.443176).  Saving model ...
Epoch 1496, train_loss: 975.5003596291668, val_loss: 837.6865319164817
Validation loss decreased (969.443176 --> 969.355104).  Saving model ...
Epoch 1497, train_loss: 979.2383637366563, val_loss: 833.9084935582347
Validation loss decreased (969.355104 --> 969.264625).  Saving model ...
Epoch 1498, train_loss: 979.7410741797624, val_loss: 834.8727923370293
Validation loss decreased (969.264625 --> 969.174911).  Saving model ...
Epoch 1499, train_loss: 977.481114662677, val_loss: 844.2792612500765
Validation loss decreased (969.174911 --> 969.091592).  Saving model ...
Epoch 1500, train_loss: 987.3708060323726, val_loss: 840.9769851282572
Validation loss decreased (969.091592 --> 969.006182).  Saving model ...
Epoch 1501, train_loss: 978.2242053296515, val_loss: 861.542824567976
Validation loss decreased (969.006182 --> 968.934587).  Saving model ...
Epoch 1502, train_loss: 981.1261443172338, val_loss: 843.4454061185653
Validation loss decreased (968.934587 --> 968.851039).  Saving model ...
Epoch 1503, train_loss: 974.0518031243548, val_loss: 840.6578808603464
Validation loss decreased (968.851039 --> 968.765748).  Saving model ...
Epoch 1504, train_loss: 973.9282236579219, val_loss: 849.6864965079009
Validation loss decreased (968.765748 --> 968.686573).  Saving model ...
Epoch 1505, train_loss: 972.5103319660315, val_loss: 849.2570207600243
Validation loss decreased (968.686573 --> 968.607217).  Saving model ...
Epoch 1506, train_loss: 975.7029376119608, val_loss: 856.1951272377042
Validation loss decreased (968.607217 --> 968.532575).  Saving model ...
Epoch 1507, train_loss: 979.9197115570718, val_loss: 861.3712157256958
Validation loss decreased (968.532575 --> 968.461466).  Saving model ...
Epoch 1508, train_loss: 980.7443541816128, val_loss: 839.202951028833
Validation loss decreased (968.461466 --> 968.375750).  Saving model ...
Epoch 1509, train_loss: 973.1200953932217, val_loss: 848.5831123495544
Validation loss decreased (968.375750 --> 968.296365).  Saving model ...
Epoch 1510, train_loss: 973.849724164105, val_loss: 842.723797059523
Validation loss decreased (968.296365 --> 968.213204).  Saving model ...
Epoch 1511, train_loss: 970.9325242528047, val_loss: 846.8111488481364
Validation loss decreased (968.213204 --> 968.132859).  Saving model ...
Epoch 1512, train_loss: 972.7017394924821, val_loss: 860.9395701780145
Validation loss decreased (968.132859 --> 968.061964).  Saving model ...
Epoch 1513, train_loss: 983.2879333207396, val_loss: 843.7691793288127
Validation loss decreased (968.061964 --> 967.979814).  Saving model ...
Epoch 1514, train_loss: 979.7227042979821, val_loss: 839.3248383650075
Validation loss decreased (967.979814 --> 967.894837).  Saving model ...
Epoch 1515, train_loss: 970.5186426499193, val_loss: 854.8405678396757
Validation loss decreased (967.894837 --> 967.820214).  Saving model ...
Epoch 1516, train_loss: 976.536981867501, val_loss: 848.4115367212562
Validation loss decreased (967.820214 --> 967.741448).  Saving model ...
Epoch 1517, train_loss: 971.1889274186984, val_loss: 845.3694343026259
Validation loss decreased (967.741448 --> 967.660781).  Saving model ...
Epoch 1518, train_loss: 979.9843518121108, val_loss: 853.6838274996371
Validation loss decreased (967.660781 --> 967.585697).  Saving model ...
Epoch 1519, train_loss: 984.9176673577755, val_loss: 842.4584468826101
Validation loss decreased (967.585697 --> 967.503323).  Saving model ...
Epoch 1520, train_loss: 975.1405053862898, val_loss: 844.8594260761033
Validation loss decreased (967.503323 --> 967.422636).  Saving model ...
Epoch 1521, train_loss: 969.3259605325728, val_loss: 853.4547264499798
Validation loss decreased (967.422636 --> 967.347706).  Saving model ...
Epoch 1522, train_loss: 975.4311985660555, val_loss: 840.4901776754195
Validation loss decreased (967.347706 --> 967.264357).  Saving model ...
Epoch 1523, train_loss: 976.1910889103995, val_loss: 843.2396507150156
Validation loss decreased (967.264357 --> 967.182923).  Saving model ...
Epoch 1524, train_loss: 973.29970645446, val_loss: 828.3390534852833
Validation loss decreased (967.182923 --> 967.091818).  Saving model ...
Epoch 1525, train_loss: 973.7908184772785, val_loss: 847.4022818035554
Validation loss decreased (967.091818 --> 967.013333).  Saving model ...
Epoch 1526, train_loss: 973.860755273924, val_loss: 858.0820399785263
Validation loss decreased (967.013333 --> 966.941949).  Saving model ...
Epoch 1527, train_loss: 974.3259508971499, val_loss: 844.8405447168485
Validation loss decreased (966.941949 --> 966.861988).  Saving model ...
Epoch 1528, train_loss: 976.464190723235, val_loss: 836.9393370972522
Validation loss decreased (966.861988 --> 966.776960).  Saving model ...
Epoch 1529, train_loss: 969.8196780232439, val_loss: 837.7502891015124
Validation loss decreased (966.776960 --> 966.692573).  Saving model ...
Epoch 1530, train_loss: 978.1877220380308, val_loss: 849.3571948176182
Validation loss decreased (966.692573 --> 966.615884).  Saving model ...
Epoch 1531, train_loss: 983.7164274357256, val_loss: 837.965978196396
Validation loss decreased (966.615884 --> 966.531854).  Saving model ...
Epoch 1532, train_loss: 970.3952056508185, val_loss: 850.0106711180124
Validation loss decreased (966.531854 --> 966.455795).  Saving model ...
Epoch 1533, train_loss: 978.3087354510042, val_loss: 837.2580881881717
Validation loss decreased (966.455795 --> 966.371518).  Saving model ...
Epoch 1534, train_loss: 968.2628516408114, val_loss: 837.0065198964544
Validation loss decreased (966.371518 --> 966.287186).  Saving model ...
Epoch 1535, train_loss: 978.4004250486988, val_loss: 828.396113781598
Validation loss decreased (966.287186 --> 966.197355).  Saving model ...
Epoch 1536, train_loss: 973.1081514524815, val_loss: 849.9759210556748
Validation loss decreased (966.197355 --> 966.121690).  Saving model ...
Epoch 1537, train_loss: 978.8852309975606, val_loss: 843.3794971143757
Validation loss decreased (966.121690 --> 966.041831).  Saving model ...
Epoch 1538, train_loss: 973.989025199296, val_loss: 846.9936335752631
Validation loss decreased (966.041831 --> 965.964427).  Saving model ...
Epoch 1539, train_loss: 965.7004919301492, val_loss: 840.1646964305199
Validation loss decreased (965.964427 --> 965.882685).  Saving model ...
Epoch 1540, train_loss: 974.7450531167182, val_loss: 845.5589182269351
Validation loss decreased (965.882685 --> 965.804553).  Saving model ...
Epoch 1541, train_loss: 969.3429515927761, val_loss: 837.9056309032002
Validation loss decreased (965.804553 --> 965.721556).  Saving model ...
Epoch 1542, train_loss: 975.2090350081252, val_loss: 834.6221356772717
Validation loss decreased (965.721556 --> 965.636537).  Saving model ...
Epoch 1543, train_loss: 975.8223431539272, val_loss: 826.8416291629165
Validation loss decreased (965.636537 --> 965.546585).  Saving model ...
Epoch 1544, train_loss: 966.159218082884, val_loss: 832.7936069347243
Validation loss decreased (965.546585 --> 965.460605).  Saving model ...
Epoch 1545, train_loss: 968.3900231020142, val_loss: 839.7968337096551
Validation loss decreased (965.460605 --> 965.379270).  Saving model ...
Epoch 1546, train_loss: 966.6778863701189, val_loss: 839.2876075469786
Validation loss decreased (965.379270 --> 965.297710).  Saving model ...
Epoch 1547, train_loss: 976.370955163454, val_loss: 825.1885282824438
Validation loss decreased (965.297710 --> 965.207141).  Saving model ...
Epoch 1548, train_loss: 961.7562593293368, val_loss: 845.8848182270704
Validation loss decreased (965.207141 --> 965.130060).  Saving model ...
Epoch 1549, train_loss: 973.4978096222912, val_loss: 836.7083987028732
Validation loss decreased (965.130060 --> 965.047154).  Saving model ...
Epoch 1550, train_loss: 972.8986885419642, val_loss: 848.565537273619
Validation loss decreased (965.047154 --> 964.972004).  Saving model ...
Epoch 1551, train_loss: 970.5404272235755, val_loss: 843.52268061554
Validation loss decreased (964.972004 --> 964.893700).  Saving model ...
Epoch 1552, train_loss: 965.6151645119693, val_loss: 829.1010346925924
Validation loss decreased (964.893700 --> 964.806205).  Saving model ...
Epoch 1553, train_loss: 970.6331497366201, val_loss: 844.3112903572675
Validation loss decreased (964.806205 --> 964.728617).  Saving model ...
Epoch 1554, train_loss: 967.5163908178034, val_loss: 852.4024436971436
Validation loss decreased (964.728617 --> 964.656335).  Saving model ...
Epoch 1555, train_loss: 965.0375529650153, val_loss: 853.8430497267733
Validation loss decreased (964.656335 --> 964.585072).  Saving model ...
Epoch 1556, train_loss: 971.54952340982, val_loss: 835.628321817076
Validation loss decreased (964.585072 --> 964.502195).  Saving model ...
Epoch 1557, train_loss: 970.9882642804838, val_loss: 839.5270795056557
Validation loss decreased (964.502195 --> 964.421928).  Saving model ...
Epoch 1558, train_loss: 981.1818927175636, val_loss: 836.0288453083568
Validation loss decreased (964.421928 --> 964.339519).  Saving model ...
Epoch 1559, train_loss: 959.1546578155401, val_loss: 844.652165983231
Validation loss decreased (964.339519 --> 964.262748).  Saving model ...
Epoch 1560, train_loss: 979.9772624831845, val_loss: 824.8783729346152
Validation loss decreased (964.262748 --> 964.173399).  Saving model ...
Epoch 1561, train_loss: 968.9009576605947, val_loss: 829.2026993677796
Validation loss decreased (964.173399 --> 964.086934).  Saving model ...
Epoch 1562, train_loss: 962.2966705865666, val_loss: 846.0849697332029
Validation loss decreased (964.086934 --> 964.011389).  Saving model ...
Epoch 1563, train_loss: 967.1920237763712, val_loss: 850.4689180982995
Validation loss decreased (964.011389 --> 963.938745).  Saving model ...
Epoch 1564, train_loss: 966.1281224903149, val_loss: 838.7904582483902
Validation loss decreased (963.938745 --> 963.858727).  Saving model ...
Epoch 1565, train_loss: 972.257840142277, val_loss: 843.996710147372
Validation loss decreased (963.858727 --> 963.782138).  Saving model ...
Epoch 1566, train_loss: 969.7186575910958, val_loss: 835.4938489046363
Validation loss decreased (963.782138 --> 963.700217).  Saving model ...
Epoch 1567, train_loss: 961.018134547743, val_loss: 839.4420490755416
Validation loss decreased (963.700217 --> 963.620920).  Saving model ...
Epoch 1568, train_loss: 972.3820839394579, val_loss: 847.6151760705092
Validation loss decreased (963.620920 --> 963.546937).  Saving model ...
Epoch 1569, train_loss: 970.6761572399674, val_loss: 845.3007515528908
Validation loss decreased (963.546937 --> 963.471573).  Saving model ...
Epoch 1570, train_loss: 964.3119920622166, val_loss: 837.7879363971066
Validation loss decreased (963.471573 --> 963.391519).  Saving model ...
Epoch 1571, train_loss: 969.9802337474728, val_loss: 839.8299290557925
Validation loss decreased (963.391519 --> 963.312868).  Saving model ...
Epoch 1572, train_loss: 976.379456589845, val_loss: 822.6641741843358
Validation loss decreased (963.312868 --> 963.223397).  Saving model ...
Epoch 1573, train_loss: 963.0390362663013, val_loss: 830.7224068853592
Validation loss decreased (963.223397 --> 963.139162).  Saving model ...
Epoch 1574, train_loss: 969.5146520515772, val_loss: 831.6223404518764
Validation loss decreased (963.139162 --> 963.055606).  Saving model ...
Epoch 1575, train_loss: 969.7931302783854, val_loss: 833.5698430950114
Validation loss decreased (963.055606 --> 962.973393).  Saving model ...
Epoch 1576, train_loss: 966.6818895188231, val_loss: 835.2475651029528
Validation loss decreased (962.973393 --> 962.892349).  Saving model ...
Epoch 1577, train_loss: 967.4155096309393, val_loss: 830.8880026780015
Validation loss decreased (962.892349 --> 962.808643).  Saving model ...
Epoch 1578, train_loss: 970.9137569450493, val_loss: 831.2588115077771
Validation loss decreased (962.808643 --> 962.725278).  Saving model ...
Epoch 1579, train_loss: 965.6002096924584, val_loss: 845.3877897586207
Validation loss decreased (962.725278 --> 962.650967).  Saving model ...
Epoch 1580, train_loss: 964.3701967185559, val_loss: 840.0380308508212
Validation loss decreased (962.650967 --> 962.573363).  Saving model ...
Epoch 1581, train_loss: 971.9413297064266, val_loss: 829.4074723937115
Validation loss decreased (962.573363 --> 962.489135).  Saving model ...
Epoch 1582, train_loss: 964.1310990392491, val_loss: 827.3915264044869
Validation loss decreased (962.489135 --> 962.403738).  Saving model ...
Epoch 1583, train_loss: 961.4353844099221, val_loss: 821.1314886744817
Validation loss decreased (962.403738 --> 962.314494).  Saving model ...
Epoch 1584, train_loss: 965.4781185656975, val_loss: 836.0777400103765
Validation loss decreased (962.314494 --> 962.234800).  Saving model ...
Epoch 1585, train_loss: 964.3698220262633, val_loss: 832.8567155220995
Validation loss decreased (962.234800 --> 962.153173).  Saving model ...
Epoch 1586, train_loss: 970.5395387041389, val_loss: 837.8310920691492
Validation loss decreased (962.153173 --> 962.074786).  Saving model ...
Epoch 1587, train_loss: 970.2666437520933, val_loss: 825.7346593770054
Validation loss decreased (962.074786 --> 961.988875).  Saving model ...
Epoch 1588, train_loss: 968.2087123482673, val_loss: 832.3829244929334
Validation loss decreased (961.988875 --> 961.907259).  Saving model ...
Epoch 1589, train_loss: 964.418616156653, val_loss: 826.3945386434044
Validation loss decreased (961.907259 --> 961.821978).  Saving model ...
Epoch 1590, train_loss: 968.0926431617437, val_loss: 832.3942392695393
Validation loss decreased (961.821978 --> 961.740577).  Saving model ...
Epoch 1591, train_loss: 963.5415005052458, val_loss: 837.7265246331914
Validation loss decreased (961.740577 --> 961.662629).  Saving model ...
Epoch 1592, train_loss: 981.2786770578083, val_loss: 817.7440158434932
Validation loss decreased (961.662629 --> 961.572228).  Saving model ...
Epoch 1593, train_loss: 970.435307232893, val_loss: 831.0638427620025
Validation loss decreased (961.572228 --> 961.490302).  Saving model ...
Epoch 1594, train_loss: 967.5748116349394, val_loss: 831.1753094258355
Validation loss decreased (961.490302 --> 961.408549).  Saving model ...
Epoch 1595, train_loss: 966.4501305912091, val_loss: 832.1019450306894
Validation loss decreased (961.408549 --> 961.327479).  Saving model ...
Epoch 1596, train_loss: 964.9887145321836, val_loss: 833.8421290481753
Validation loss decreased (961.327479 --> 961.247601).  Saving model ...
Epoch 1597, train_loss: 965.4783351061897, val_loss: 832.149300495033
Validation loss decreased (961.247601 --> 961.166763).  Saving model ...
Epoch 1598, train_loss: 972.5658444500999, val_loss: 818.5410276507231
Validation loss decreased (961.166763 --> 961.077510).  Saving model ...
Epoch 1599, train_loss: 970.4220878946272, val_loss: 841.5308294189418
Validation loss decreased (961.077510 --> 961.002746).  Saving model ...
Epoch 1600, train_loss: 965.4481874783826, val_loss: 824.2065170081015
Validation loss decreased (961.002746 --> 960.917249).  Saving model ...
Epoch 1601, train_loss: 970.11813845136, val_loss: 842.1970627802613
Validation loss decreased (960.917249 --> 960.843095).  Saving model ...
Epoch 1602, train_loss: 961.9487297245556, val_loss: 832.9977181649209
Validation loss decreased (960.843095 --> 960.763291).  Saving model ...
Epoch 1603, train_loss: 977.6915633988202, val_loss: 824.8539148722977
Validation loss decreased (960.763291 --> 960.678507).  Saving model ...
Epoch 1604, train_loss: 970.8520704508948, val_loss: 823.2350492101467
Validation loss decreased (960.678507 --> 960.592819).  Saving model ...
Epoch 1605, train_loss: 970.6784776098939, val_loss: 843.7253512620927
Validation loss decreased (960.592819 --> 960.520004).  Saving model ...
Epoch 1606, train_loss: 958.4647328351565, val_loss: 841.2706083518929
Validation loss decreased (960.520004 --> 960.445752).  Saving model ...
Epoch 1607, train_loss: 966.4337916463556, val_loss: 836.3760286591009
Validation loss decreased (960.445752 --> 960.368546).  Saving model ...
Epoch 1608, train_loss: 966.2529191934431, val_loss: 830.0531339120424
Validation loss decreased (960.368546 --> 960.287504).  Saving model ...
Epoch 1609, train_loss: 966.7911560505743, val_loss: 828.8097898261417
Validation loss decreased (960.287504 --> 960.205790).  Saving model ...
Epoch 1610, train_loss: 963.9790646183919, val_loss: 836.5254421128608
Validation loss decreased (960.205790 --> 960.128970).  Saving model ...
Epoch 1611, train_loss: 963.2906067431201, val_loss: 824.1497156258425
Validation loss decreased (960.128970 --> 960.044564).  Saving model ...
Epoch 1612, train_loss: 962.7648185794397, val_loss: 828.6425783739709
Validation loss decreased (960.044564 --> 959.963049).  Saving model ...
Epoch 1613, train_loss: 967.8454553760414, val_loss: 830.6843369341781
Validation loss decreased (959.963049 --> 959.882901).  Saving model ...
Epoch 1614, train_loss: 962.859420889083, val_loss: 834.589515654246
Validation loss decreased (959.882901 --> 959.805272).  Saving model ...
Epoch 1615, train_loss: 967.8327450422247, val_loss: 823.0492429967723
Validation loss decreased (959.805272 --> 959.720593).  Saving model ...
Epoch 1616, train_loss: 961.1916466226428, val_loss: 831.1601569237977
Validation loss decreased (959.720593 --> 959.641038).  Saving model ...
Epoch 1617, train_loss: 960.919573746081, val_loss: 823.9121848266877
Validation loss decreased (959.641038 --> 959.557100).  Saving model ...
Epoch 1618, train_loss: 968.766283740811, val_loss: 828.6465481392103
Validation loss decreased (959.557100 --> 959.476191).  Saving model ...
Epoch 1619, train_loss: 970.2202304415392, val_loss: 820.6450921373677
Validation loss decreased (959.476191 --> 959.390440).  Saving model ...
Epoch 1620, train_loss: 957.3088303021624, val_loss: 837.8953161106507
Validation loss decreased (959.390440 --> 959.315443).  Saving model ...
Epoch 1621, train_loss: 963.0385400790371, val_loss: 828.8518119459242
Validation loss decreased (959.315443 --> 959.234959).  Saving model ...
Epoch 1622, train_loss: 963.173646191379, val_loss: 812.3147512678529
Validation loss decreased (959.234959 --> 959.144379).  Saving model ...
Epoch 1623, train_loss: 959.6262230069334, val_loss: 834.6249562288876
Validation loss decreased (959.144379 --> 959.067658).  Saving model ...
Epoch 1624, train_loss: 953.3687929121832, val_loss: 813.0402030081
Validation loss decreased (959.067658 --> 958.977739).  Saving model ...
Epoch 1625, train_loss: 965.4789228324369, val_loss: 839.9704610630318
Validation loss decreased (958.977739 --> 958.904504).  Saving model ...
Epoch 1626, train_loss: 962.8303233881737, val_loss: 834.0338716687098
Validation loss decreased (958.904504 --> 958.827708).  Saving model ...
Epoch 1627, train_loss: 964.4578713505869, val_loss: 827.0899070779484
Validation loss decreased (958.827708 --> 958.746738).  Saving model ...
Epoch 1628, train_loss: 958.4223602669227, val_loss: 818.7891041719254
Validation loss decreased (958.746738 --> 958.660769).  Saving model ...
Epoch 1629, train_loss: 965.2563614285431, val_loss: 815.822798742034
Validation loss decreased (958.660769 --> 958.573085).  Saving model ...
Epoch 1630, train_loss: 958.5679865851213, val_loss: 824.0428722334572
Validation loss decreased (958.573085 --> 958.490551).  Saving model ...
Epoch 1631, train_loss: 965.4714937930955, val_loss: 825.1306700727237
Validation loss decreased (958.490551 --> 958.408785).  Saving model ...
Epoch 1632, train_loss: 960.2277209723479, val_loss: 824.1638761239361
Validation loss decreased (958.408785 --> 958.326527).  Saving model ...
Epoch 1633, train_loss: 966.2608506649839, val_loss: 814.852739047055
Validation loss decreased (958.326527 --> 958.238668).  Saving model ...
Epoch 1634, train_loss: 957.1545353676581, val_loss: 834.5760214723482
Validation loss decreased (958.238668 --> 958.162987).  Saving model ...
Epoch 1635, train_loss: 968.7194108984813, val_loss: 822.131911037432
Validation loss decreased (958.162987 --> 958.079788).  Saving model ...
Epoch 1636, train_loss: 958.7095740330745, val_loss: 829.53219908222
Validation loss decreased (958.079788 --> 958.001213).  Saving model ...
Epoch 1637, train_loss: 958.722077083182, val_loss: 822.5072499799952
Validation loss decreased (958.001213 --> 957.918444).  Saving model ...
Epoch 1638, train_loss: 960.2406878177037, val_loss: 825.3272938566298
Validation loss decreased (957.918444 --> 957.837497).  Saving model ...
Epoch 1639, train_loss: 961.6596525681713, val_loss: 814.4862575866118
Validation loss decreased (957.837497 --> 957.750034).  Saving model ...
Epoch 1640, train_loss: 959.3424281209936, val_loss: 840.6126238192011
Validation loss decreased (957.750034 --> 957.678609).  Saving model ...
Epoch 1641, train_loss: 961.6893915598931, val_loss: 817.3642573124835
Validation loss decreased (957.678609 --> 957.593103).  Saving model ...
Epoch 1642, train_loss: 960.5417904494809, val_loss: 816.2676149136272
Validation loss decreased (957.593103 --> 957.507034).  Saving model ...
Epoch 1643, train_loss: 958.6991472968974, val_loss: 821.8162095610302
Validation loss decreased (957.507034 --> 957.424447).  Saving model ...
Epoch 1644, train_loss: 954.5420525983969, val_loss: 834.241896706886
Validation loss decreased (957.424447 --> 957.349519).  Saving model ...
Epoch 1645, train_loss: 967.2319618491583, val_loss: 821.5174324898147
Validation loss decreased (957.349519 --> 957.266946).  Saving model ...
Epoch 1646, train_loss: 963.1099702036561, val_loss: 822.8938675106014
Validation loss decreased (957.266946 --> 957.185310).  Saving model ...
Epoch 1647, train_loss: 954.5735716784766, val_loss: 825.2912451242738
Validation loss decreased (957.185310 --> 957.105228).  Saving model ...
Epoch 1648, train_loss: 961.4489844339363, val_loss: 819.9982254719075
Validation loss decreased (957.105228 --> 957.022032).  Saving model ...
Epoch 1649, train_loss: 958.6497127347753, val_loss: 822.8206617418928
Validation loss decreased (957.022032 --> 956.940649).  Saving model ...
Epoch 1650, train_loss: 961.8417626389589, val_loss: 822.7936454200748
Validation loss decreased (956.940649 --> 956.859348).  Saving model ...
Epoch 1651, train_loss: 961.8663044479619, val_loss: 823.2100472820026
Validation loss decreased (956.859348 --> 956.778397).  Saving model ...
Epoch 1652, train_loss: 965.2767284035647, val_loss: 832.3558334109521
Validation loss decreased (956.778397 --> 956.703081).  Saving model ...
Epoch 1653, train_loss: 960.9488278926123, val_loss: 821.621451857885
Validation loss decreased (956.703081 --> 956.621362).  Saving model ...
Epoch 1654, train_loss: 964.4729944621298, val_loss: 823.3051870431503
Validation loss decreased (956.621362 --> 956.540759).  Saving model ...
Epoch 1655, train_loss: 962.7915442652047, val_loss: 814.0881968598014
Validation loss decreased (956.540759 --> 956.454685).  Saving model ...
Epoch 1656, train_loss: 951.5313605679368, val_loss: 824.7879276871022
Validation loss decreased (956.454685 --> 956.375176).  Saving model ...
Epoch 1657, train_loss: 958.5648773404644, val_loss: 829.2504636069361
Validation loss decreased (956.375176 --> 956.298457).  Saving model ...
Epoch 1658, train_loss: 962.2991169174664, val_loss: 826.2125900140737
Validation loss decreased (956.298457 --> 956.219997).  Saving model ...
Epoch 1659, train_loss: 955.6337593236392, val_loss: 821.8258251938336
Validation loss decreased (956.219997 --> 956.138988).  Saving model ...
Epoch 1660, train_loss: 960.2237896296846, val_loss: 819.0052347980827
Validation loss decreased (956.138988 --> 956.056377).  Saving model ...
Epoch 1661, train_loss: 958.6231066697228, val_loss: 823.0354589862076
Validation loss decreased (956.056377 --> 955.976292).  Saving model ...
Epoch 1662, train_loss: 951.864042696308, val_loss: 818.4954432346425
Validation loss decreased (955.976292 --> 955.893572).  Saving model ...
Epoch 1663, train_loss: 961.6668745843845, val_loss: 819.210421317573
Validation loss decreased (955.893572 --> 955.811382).  Saving model ...
Epoch 1664, train_loss: 948.7100051799263, val_loss: 819.0173689353247
Validation loss decreased (955.811382 --> 955.729174).  Saving model ...
Epoch 1665, train_loss: 954.2453329191551, val_loss: 815.2306232325459
Validation loss decreased (955.729174 --> 955.644790).  Saving model ...
Epoch 1666, train_loss: 957.097877149278, val_loss: 823.4553272467633
Validation loss decreased (955.644790 --> 955.565445).  Saving model ...
Epoch 1667, train_loss: 954.6774248711401, val_loss: 823.099763339736
Validation loss decreased (955.565445 --> 955.485981).  Saving model ...
Epoch 1668, train_loss: 957.9724655145941, val_loss: 823.7766297049217
Validation loss decreased (955.485981 --> 955.407019).  Saving model ...
Epoch 1669, train_loss: 962.207192263011, val_loss: 831.0928848170133
Validation loss decreased (955.407019 --> 955.332535).  Saving model ...
Epoch 1670, train_loss: 953.2509261481908, val_loss: 818.781174757834
Validation loss decreased (955.332535 --> 955.250767).  Saving model ...
Epoch 1671, train_loss: 959.9622276499048, val_loss: 811.1218497304786
Validation loss decreased (955.250767 --> 955.164514).  Saving model ...
Epoch 1672, train_loss: 954.130214285677, val_loss: 820.1299955317932
Validation loss decreased (955.164514 --> 955.083752).  Saving model ...
Epoch 1673, train_loss: 955.7318291065612, val_loss: 824.9099303691036
Validation loss decreased (955.083752 --> 955.005943).  Saving model ...
Epoch 1674, train_loss: 947.3204726810943, val_loss: 834.4840726604951
Validation loss decreased (955.005943 --> 954.933947).  Saving model ...
Epoch 1675, train_loss: 960.7845292265596, val_loss: 816.3737708466807
Validation loss decreased (954.933947 --> 954.851224).  Saving model ...
Epoch 1676, train_loss: 960.649824057958, val_loss: 818.456849240131
Validation loss decreased (954.851224 --> 954.769844).  Saving model ...
Epoch 1677, train_loss: 957.848878256786, val_loss: 816.5746274582326
Validation loss decreased (954.769844 --> 954.687437).  Saving model ...
Epoch 1678, train_loss: 963.2226702104762, val_loss: 814.9535143600352
Validation loss decreased (954.687437 --> 954.604163).  Saving model ...
Epoch 1679, train_loss: 955.1192041788012, val_loss: 813.8165922910639
Validation loss decreased (954.604163 --> 954.520311).  Saving model ...
Epoch 1680, train_loss: 954.7130381164909, val_loss: 807.4483518908202
Validation loss decreased (954.520311 --> 954.432768).  Saving model ...
Epoch 1681, train_loss: 954.5377393248172, val_loss: 829.9909417854859
Validation loss decreased (954.432768 --> 954.358740).  Saving model ...
Epoch 1682, train_loss: 962.0514288610332, val_loss: 819.318326569553
Validation loss decreased (954.358740 --> 954.278454).  Saving model ...
Epoch 1683, train_loss: 958.7177279053974, val_loss: 821.8321003802839
Validation loss decreased (954.278454 --> 954.199758).  Saving model ...
Epoch 1684, train_loss: 958.8006820601768, val_loss: 816.879354945907
Validation loss decreased (954.199758 --> 954.118214).  Saving model ...
Epoch 1685, train_loss: 954.3505352597303, val_loss: 826.0203763519838
Validation loss decreased (954.118214 --> 954.042191).  Saving model ...
Epoch 1686, train_loss: 960.3298645652366, val_loss: 821.7726931657617
Validation loss decreased (954.042191 --> 953.963739).  Saving model ...
Epoch 1687, train_loss: 952.3853815453324, val_loss: 825.9917072776735
Validation loss decreased (953.963739 --> 953.887882).  Saving model ...
Epoch 1688, train_loss: 959.2185907610217, val_loss: 819.5547641567613
Validation loss decreased (953.887882 --> 953.808300).  Saving model ...
Epoch 1689, train_loss: 957.712505273671, val_loss: 820.2141635361426
Validation loss decreased (953.808300 --> 953.729204).  Saving model ...
Epoch 1690, train_loss: 948.3114527521739, val_loss: 826.0287788682294
Validation loss decreased (953.729204 --> 953.653642).  Saving model ...
Epoch 1691, train_loss: 957.6393026157713, val_loss: 815.6069688271374
Validation loss decreased (953.653642 --> 953.572005).  Saving model ...
Epoch 1692, train_loss: 961.4652054699276, val_loss: 824.8571838587745
Validation loss decreased (953.572005 --> 953.495933).  Saving model ...
Epoch 1693, train_loss: 958.3693096771968, val_loss: 816.7279836874981
Validation loss decreased (953.495933 --> 953.415148).  Saving model ...
Epoch 1694, train_loss: 953.168658644553, val_loss: 817.0747907757099
Validation loss decreased (953.415148 --> 953.334664).  Saving model ...
Epoch 1695, train_loss: 957.9947461498706, val_loss: 822.884791414782
Validation loss decreased (953.334664 --> 953.257703).  Saving model ...
Epoch 1696, train_loss: 950.4872563154087, val_loss: 813.7271477079835
Validation loss decreased (953.257703 --> 953.175432).  Saving model ...
Epoch 1697, train_loss: 958.755691200989, val_loss: 820.9444729157512
Validation loss decreased (953.175432 --> 953.097512).  Saving model ...
Epoch 1698, train_loss: 964.7032622245055, val_loss: 827.4114506931882
Validation loss decreased (953.097512 --> 953.023492).  Saving model ...
Epoch 1699, train_loss: 952.4627174956021, val_loss: 814.6818409774702
Validation loss decreased (953.023492 --> 952.942066).  Saving model ...
Epoch 1700, train_loss: 950.4997135016055, val_loss: 821.5529761112399
Validation loss decreased (952.942066 --> 952.864779).  Saving model ...
Epoch 1701, train_loss: 955.3302316567678, val_loss: 822.0981480058698
Validation loss decreased (952.864779 --> 952.787902).  Saving model ...
Epoch 1702, train_loss: 950.6893125336192, val_loss: 830.5587399226648
Validation loss decreased (952.787902 --> 952.716087).  Saving model ...
Epoch 1703, train_loss: 958.5949203648369, val_loss: 815.9639464552097
Validation loss decreased (952.716087 --> 952.635787).  Saving model ...
Epoch 1704, train_loss: 944.3735786580438, val_loss: 820.5529415275213
Validation loss decreased (952.635787 --> 952.558273).  Saving model ...
Epoch 1705, train_loss: 953.1540602808574, val_loss: 822.6949496472106
Validation loss decreased (952.558273 --> 952.482107).  Saving model ...
Epoch 1706, train_loss: 949.4215213979677, val_loss: 812.5061860822088
Validation loss decreased (952.482107 --> 952.400058).  Saving model ...
Epoch 1707, train_loss: 948.5081819382184, val_loss: 814.7502081241873
Validation loss decreased (952.400058 --> 952.319419).  Saving model ...
Epoch 1708, train_loss: 954.6383379333472, val_loss: 822.9372195702352
Validation loss decreased (952.319419 --> 952.243669).  Saving model ...
Epoch 1709, train_loss: 948.500417692351, val_loss: 823.5363852168017
Validation loss decreased (952.243669 --> 952.168357).  Saving model ...
Epoch 1710, train_loss: 961.7939319274293, val_loss: 814.7738422756285
Validation loss decreased (952.168357 --> 952.088010).  Saving model ...
Epoch 1711, train_loss: 947.4504113441668, val_loss: 826.5902701012074
Validation loss decreased (952.088010 --> 952.014662).  Saving model ...
Epoch 1712, train_loss: 955.7140073954862, val_loss: 830.3638547290035
Validation loss decreased (952.014662 --> 951.943604).  Saving model ...
Epoch 1713, train_loss: 945.1126853653698, val_loss: 822.7992600628403
Validation loss decreased (951.943604 --> 951.868213).  Saving model ...
Epoch 1714, train_loss: 951.8130891250513, val_loss: 830.0762173370741
Validation loss decreased (951.868213 --> 951.797156).  Saving model ...
Epoch 1715, train_loss: 959.6673367046142, val_loss: 822.8893348218779
Validation loss decreased (951.797156 --> 951.721991).  Saving model ...
Epoch 1716, train_loss: 949.166154761061, val_loss: 824.8319036249983
Validation loss decreased (951.721991 --> 951.648046).  Saving model ...
Epoch 1717, train_loss: 943.6047698198435, val_loss: 819.0880997548726
Validation loss decreased (951.648046 --> 951.570842).  Saving model ...
Epoch 1718, train_loss: 945.6232697982884, val_loss: 816.3839743143541
Validation loss decreased (951.570842 --> 951.492153).  Saving model ...
Epoch 1719, train_loss: 946.4659091001726, val_loss: 816.3539905454936
Validation loss decreased (951.492153 --> 951.413539).  Saving model ...
Epoch 1720, train_loss: 950.1589223874381, val_loss: 818.2014807464901
Validation loss decreased (951.413539 --> 951.336090).  Saving model ...
Epoch 1721, train_loss: 949.7787268329604, val_loss: 829.3479087942842
Validation loss decreased (951.336090 --> 951.265208).  Saving model ...
Epoch 1722, train_loss: 952.5958716903999, val_loss: 817.3192250694832
Validation loss decreased (951.265208 --> 951.187423).  Saving model ...
Epoch 1723, train_loss: 942.3618212190123, val_loss: 822.1532745404819
Validation loss decreased (951.187423 --> 951.112533).  Saving model ...
Epoch 1724, train_loss: 949.5750539336312, val_loss: 813.5252268611725
Validation loss decreased (951.112533 --> 951.032726).  Saving model ...
Epoch 1725, train_loss: 940.8047771879732, val_loss: 821.6260114840007
Validation loss decreased (951.032726 --> 950.957708).  Saving model ...
Epoch 1726, train_loss: 949.4149675696423, val_loss: 827.7908211801893
Validation loss decreased (950.957708 --> 950.886348).  Saving model ...
Epoch 1727, train_loss: 957.3874067420145, val_loss: 819.3915526012361
Validation loss decreased (950.886348 --> 950.810208).  Saving model ...
Epoch 1728, train_loss: 956.1115302620294, val_loss: 818.4260585097692
Validation loss decreased (950.810208 --> 950.733597).  Saving model ...
Epoch 1729, train_loss: 949.5883836736039, val_loss: 810.139094225102
Validation loss decreased (950.733597 --> 950.652281).  Saving model ...
Epoch 1730, train_loss: 948.0527394847742, val_loss: 814.3942445125625
Validation loss decreased (950.652281 --> 950.573519).  Saving model ...
Epoch 1731, train_loss: 944.1769911105822, val_loss: 819.4748781115924
Validation loss decreased (950.573519 --> 950.497783).  Saving model ...
Epoch 1732, train_loss: 949.4788511206209, val_loss: 819.3714270465684
Validation loss decreased (950.497783 --> 950.422075).  Saving model ...
Epoch 1733, train_loss: 949.0594437370283, val_loss: 819.9349173054429
Validation loss decreased (950.422075 --> 950.346780).  Saving model ...
Epoch 1734, train_loss: 953.860031840082, val_loss: 829.0698556227595
Validation loss decreased (950.346780 --> 950.276839).  Saving model ...
Epoch 1735, train_loss: 952.3989835261644, val_loss: 818.3908890943395
Validation loss decreased (950.276839 --> 950.200824).  Saving model ...
Epoch 1736, train_loss: 948.6436218249736, val_loss: 831.2566749253762
Validation loss decreased (950.200824 --> 950.132308).  Saving model ...
Epoch 1737, train_loss: 944.3113665899675, val_loss: 828.3285524100288
Validation loss decreased (950.132308 --> 950.062185).  Saving model ...
Epoch 1738, train_loss: 949.2981323640515, val_loss: 825.2532653943257
Validation loss decreased (950.062185 --> 949.990373).  Saving model ...
Epoch 1739, train_loss: 952.3973573913873, val_loss: 826.0635875475186
Validation loss decreased (949.990373 --> 949.919110).  Saving model ...
Epoch 1740, train_loss: 950.336930114708, val_loss: 828.0955296291469
Validation loss decreased (949.919110 --> 949.849096).  Saving model ...
Epoch 1741, train_loss: 940.2645029641777, val_loss: 824.0009502515531
Validation loss decreased (949.849096 --> 949.776811).  Saving model ...
Epoch 1742, train_loss: 950.4303073208966, val_loss: 821.7608141979467
Validation loss decreased (949.776811 --> 949.703323).  Saving model ...
Epoch 1743, train_loss: 948.6562480082242, val_loss: 829.233218575407
Validation loss decreased (949.703323 --> 949.634207).  Saving model ...
Epoch 1744, train_loss: 948.0100614836582, val_loss: 824.92716476138
Validation loss decreased (949.634207 --> 949.562701).  Saving model ...
Epoch 1745, train_loss: 936.8484773692524, val_loss: 820.1790671392723
Validation loss decreased (949.562701 --> 949.488555).  Saving model ...
Epoch 1746, train_loss: 947.5916233287857, val_loss: 821.1360754352146
Validation loss decreased (949.488555 --> 949.415043).  Saving model ...
Epoch 1747, train_loss: 940.1433021417637, val_loss: 828.3875492982511
Validation loss decreased (949.415043 --> 949.345766).  Saving model ...
Epoch 1748, train_loss: 954.1419680310566, val_loss: 821.4645312975736
Validation loss decreased (949.345766 --> 949.272607).  Saving model ...
Epoch 1749, train_loss: 946.7737576823266, val_loss: 818.5128414288278
Validation loss decreased (949.272607 --> 949.197844).  Saving model ...
Epoch 1750, train_loss: 951.4909466319707, val_loss: 827.2301299799815
Validation loss decreased (949.197844 --> 949.128149).  Saving model ...
Epoch 1751, train_loss: 945.8424438021046, val_loss: 807.7654886006426
Validation loss decreased (949.128149 --> 949.047416).  Saving model ...
Epoch 1752, train_loss: 938.0223628667229, val_loss: 832.7432917581665
Validation loss decreased (949.047416 --> 948.981032).  Saving model ...
Epoch 1753, train_loss: 949.909180265144, val_loss: 818.6584092392526
Validation loss decreased (948.981032 --> 948.906690).  Saving model ...
Epoch 1754, train_loss: 935.8375370348723, val_loss: 829.3954284417629
Validation loss decreased (948.906690 --> 948.838553).  Saving model ...
Epoch 1755, train_loss: 947.9346120463114, val_loss: 823.5327076801769
Validation loss decreased (948.838553 --> 948.767154).  Saving model ...
Epoch 1756, train_loss: 944.0916995255941, val_loss: 822.6522910384557
Validation loss decreased (948.767154 --> 948.695335).  Saving model ...
Epoch 1757, train_loss: 948.6547830730093, val_loss: 822.7776685251133
Validation loss decreased (948.695335 --> 948.623668).  Saving model ...
Epoch 1758, train_loss: 944.7878184085297, val_loss: 826.0019818354317
Validation loss decreased (948.623668 --> 948.553918).  Saving model ...
Epoch 1759, train_loss: 946.951131037693, val_loss: 819.4312535121045
Validation loss decreased (948.553918 --> 948.480511).  Saving model ...
Epoch 1760, train_loss: 941.9390564927182, val_loss: 826.0366281348247
Validation loss decreased (948.480511 --> 948.410940).  Saving model ...
Epoch 1761, train_loss: 939.9192895519253, val_loss: 828.5963920883559
Validation loss decreased (948.410940 --> 948.342903).  Saving model ...
Epoch 1762, train_loss: 952.130493483843, val_loss: 811.4129569386332
Validation loss decreased (948.342903 --> 948.265190).  Saving model ...
Epoch 1763, train_loss: 942.8944099211094, val_loss: 823.0133144331421
Validation loss decreased (948.265190 --> 948.194145).  Saving model ...
Epoch 1764, train_loss: 947.6935803679231, val_loss: 814.9203972665468
Validation loss decreased (948.194145 --> 948.118593).  Saving model ...
Epoch 1765, train_loss: 942.562497228659, val_loss: 810.1738511119065
Validation loss decreased (948.118593 --> 948.040437).  Saving model ...
Epoch 1766, train_loss: 945.6156272078308, val_loss: 810.0160224975924
Validation loss decreased (948.040437 --> 947.962281).  Saving model ...
Epoch 1767, train_loss: 939.6913514280501, val_loss: 825.1984204434908
Validation loss decreased (947.962281 --> 947.892805).  Saving model ...
Epoch 1768, train_loss: 943.8238218316607, val_loss: 823.2072621764963
Validation loss decreased (947.892805 --> 947.822282).  Saving model ...
Epoch 1769, train_loss: 940.1646785640232, val_loss: 834.9849683025151
Validation loss decreased (947.822282 --> 947.758496).  Saving model ...
Epoch 1770, train_loss: 949.4143354444768, val_loss: 821.9966081989252
Validation loss decreased (947.758496 --> 947.687444).  Saving model ...
Epoch 1771, train_loss: 943.6351719441311, val_loss: 833.1553589093465
Validation loss decreased (947.687444 --> 947.622773).  Saving model ...
Epoch 1772, train_loss: 944.2470662050201, val_loss: 827.9367102574421
Validation loss decreased (947.622773 --> 947.555230).  Saving model ...
Epoch 1773, train_loss: 942.1995438559771, val_loss: 811.7098104675171
Validation loss decreased (947.555230 --> 947.478611).  Saving model ...
Epoch 1774, train_loss: 935.0493739140718, val_loss: 831.0896173975865
Validation loss decreased (947.478611 --> 947.413003).  Saving model ...
Epoch 1775, train_loss: 944.3618792865183, val_loss: 820.2365808815429
Validation loss decreased (947.413003 --> 947.341354).  Saving model ...
Epoch 1776, train_loss: 944.6462649599351, val_loss: 814.8196816187877
Validation loss decreased (947.341354 --> 947.266736).  Saving model ...
Epoch 1777, train_loss: 942.1999415204504, val_loss: 822.4358850928148
Validation loss decreased (947.266736 --> 947.196488).  Saving model ...
Epoch 1778, train_loss: 943.3915009584991, val_loss: 818.419456921264
Validation loss decreased (947.196488 --> 947.124060).  Saving model ...
Epoch 1779, train_loss: 942.0332382965664, val_loss: 820.2104324511024
Validation loss decreased (947.124060 --> 947.052720).  Saving model ...
Epoch 1780, train_loss: 939.5036312152062, val_loss: 820.187499617603
Validation loss decreased (947.052720 --> 946.981447).  Saving model ...
Epoch 1781, train_loss: 940.3811132929261, val_loss: 827.131746274542
Validation loss decreased (946.981447 --> 946.914154).  Saving model ...
Epoch 1782, train_loss: 952.7493172545172, val_loss: 816.9867251188667
Validation loss decreased (946.914154 --> 946.841243).  Saving model ...
Epoch 1783, train_loss: 939.7295229308672, val_loss: 818.0686783156794
Validation loss decreased (946.841243 --> 946.769021).  Saving model ...
Epoch 1784, train_loss: 940.4942775498976, val_loss: 821.7019403617692
Validation loss decreased (946.769021 --> 946.698916).  Saving model ...
Epoch 1785, train_loss: 944.9911793154117, val_loss: 816.6253059408622
Validation loss decreased (946.698916 --> 946.626045).  Saving model ...
Epoch 1786, train_loss: 933.7930544481759, val_loss: 825.471936278211
Validation loss decreased (946.626045 --> 946.558210).  Saving model ...
Epoch 1787, train_loss: 940.9328265450958, val_loss: 818.2180091554811
Validation loss decreased (946.558210 --> 946.486391).  Saving model ...
Epoch 1788, train_loss: 934.17774632894, val_loss: 833.7066033394472
Validation loss decreased (946.486391 --> 946.423315).  Saving model ...
Epoch 1789, train_loss: 947.9212370253796, val_loss: 813.6401759922946
Validation loss decreased (946.423315 --> 946.349093).  Saving model ...
Epoch 1790, train_loss: 930.2455566894926, val_loss: 830.887228307371
Validation loss decreased (946.349093 --> 946.284589).  Saving model ...
Epoch 1791, train_loss: 949.8129595716927, val_loss: 819.9499701540999
Validation loss decreased (946.284589 --> 946.214051).  Saving model ...
Epoch 1792, train_loss: 934.3536451055955, val_loss: 824.239475982697
Validation loss decreased (946.214051 --> 946.145984).  Saving model ...
Epoch 1793, train_loss: 945.0638401857151, val_loss: 813.3623322718455
Validation loss decreased (946.145984 --> 946.071928).  Saving model ...
Epoch 1794, train_loss: 935.0694194536138, val_loss: 831.5775376690317
Validation loss decreased (946.071928 --> 946.008107).  Saving model ...
Epoch 1795, train_loss: 934.6680273800339, val_loss: 823.1556706317048
Validation loss decreased (946.008107 --> 945.939666).  Saving model ...
Epoch 1796, train_loss: 938.015383376518, val_loss: 816.7421098757894
Validation loss decreased (945.939666 --> 945.867729).  Saving model ...
Epoch 1797, train_loss: 937.815464030354, val_loss: 817.5026080438166
Validation loss decreased (945.867729 --> 945.796296).  Saving model ...
Epoch 1798, train_loss: 936.8058965814059, val_loss: 824.9352534613786
Validation loss decreased (945.796296 --> 945.729077).  Saving model ...
Epoch 1799, train_loss: 945.1443105904467, val_loss: 811.0509160585538
Validation loss decreased (945.729077 --> 945.654214).  Saving model ...
Epoch 1800, train_loss: 933.5770777098636, val_loss: 811.1321389731875
Validation loss decreased (945.654214 --> 945.579479).  Saving model ...
Epoch 1801, train_loss: 935.8777695972266, val_loss: 817.77847303183
Validation loss decreased (945.579479 --> 945.508518).  Saving model ...
Epoch 1802, train_loss: 936.4499089555167, val_loss: 817.2157530225205
Validation loss decreased (945.508518 --> 945.437324).  Saving model ...
Epoch 1803, train_loss: 936.1684179742367, val_loss: 802.8449107860638
Validation loss decreased (945.437324 --> 945.358237).  Saving model ...
Epoch 1804, train_loss: 937.5888101613684, val_loss: 824.3989301760771
Validation loss decreased (945.358237 --> 945.291187).  Saving model ...
Epoch 1805, train_loss: 931.8268194921259, val_loss: 826.9215549794394
Validation loss decreased (945.291187 --> 945.225608).  Saving model ...
Epoch 1806, train_loss: 940.1257093193383, val_loss: 819.9380624389869
Validation loss decreased (945.225608 --> 945.156235).  Saving model ...
Epoch 1807, train_loss: 936.6406099931459, val_loss: 823.023133616624
Validation loss decreased (945.156235 --> 945.088646).  Saving model ...
Epoch 1808, train_loss: 935.361841962658, val_loss: 829.9453073573335
Validation loss decreased (945.088646 --> 945.024961).  Saving model ...
Epoch 1809, train_loss: 937.214922221858, val_loss: 809.8599604663583
Validation loss decreased (945.024961 --> 944.950243).  Saving model ...
Epoch 1810, train_loss: 935.8974090497464, val_loss: 816.2110071091961
Validation loss decreased (944.950243 --> 944.879116).  Saving model ...
Epoch 1811, train_loss: 939.5268622478618, val_loss: 817.1151379376648
Validation loss decreased (944.879116 --> 944.808567).  Saving model ...
Epoch 1812, train_loss: 937.7618925654544, val_loss: 811.231755524962
Validation loss decreased (944.808567 --> 944.734849).  Saving model ...
Epoch 1813, train_loss: 935.4111148651157, val_loss: 818.0049605421447
Validation loss decreased (944.734849 --> 944.664949).  Saving model ...
Epoch 1814, train_loss: 929.7824407203719, val_loss: 811.6186588833067
Validation loss decreased (944.664949 --> 944.591604).  Saving model ...
Epoch 1815, train_loss: 933.766625104439, val_loss: 795.0251224909667
Validation loss decreased (944.591604 --> 944.509199).  Saving model ...
Epoch 1816, train_loss: 920.0916720199041, val_loss: 830.4081820191058
Validation loss decreased (944.509199 --> 944.446368).  Saving model ...
Epoch 1817, train_loss: 937.1680747921088, val_loss: 830.7134372169222
Validation loss decreased (944.446368 --> 944.383774).  Saving model ...
Epoch 1818, train_loss: 946.691346623, val_loss: 823.6486226177658
Validation loss decreased (944.383774 --> 944.317363).  Saving model ...
Epoch 1819, train_loss: 934.3761265276144, val_loss: 821.2889808606219
Validation loss decreased (944.317363 --> 944.249728).  Saving model ...
Epoch 1820, train_loss: 932.0029779979408, val_loss: 822.63464606369
Validation loss decreased (944.249728 --> 944.182906).  Saving model ...
Epoch 1821, train_loss: 928.7747261082338, val_loss: 821.5027362843134
Validation loss decreased (944.182906 --> 944.115537).  Saving model ...
Epoch 1822, train_loss: 938.6280653341106, val_loss: 816.0242695376829
Validation loss decreased (944.115537 --> 944.045234).  Saving model ...
Epoch 1823, train_loss: 933.5149654157276, val_loss: 830.8593837172676
Validation loss decreased (944.045234 --> 943.983146).  Saving model ...
Epoch 1824, train_loss: 935.6743676617776, val_loss: 816.3641189814276
Validation loss decreased (943.983146 --> 943.913180).  Saving model ...
Epoch 1825, train_loss: 930.1247515094192, val_loss: 820.8494150889804
Validation loss decreased (943.913180 --> 943.845748).  Saving model ...
Epoch 1826, train_loss: 936.5630051945349, val_loss: 815.9940951599677
Validation loss decreased (943.845748 --> 943.775730).  Saving model ...
Epoch 1827, train_loss: 929.5388950364048, val_loss: 815.8165295845935
Validation loss decreased (943.775730 --> 943.705692).  Saving model ...
Epoch 1828, train_loss: 934.0328413425193, val_loss: 823.0881415275293
Validation loss decreased (943.705692 --> 943.639709).  Saving model ...
Epoch 1829, train_loss: 931.1154491510434, val_loss: 814.2619787815544
Validation loss decreased (943.639709 --> 943.568972).  Saving model ...
Epoch 1830, train_loss: 928.3434733825201, val_loss: 828.3951916252022
Validation loss decreased (943.568972 --> 943.506036).  Saving model ...
Epoch 1831, train_loss: 936.8479277481363, val_loss: 826.4725706815501
Validation loss decreased (943.506036 --> 943.442118).  Saving model ...
Epoch 1832, train_loss: 929.5698652917982, val_loss: 813.6265329958113
Validation loss decreased (943.442118 --> 943.371258).  Saving model ...
Epoch 1833, train_loss: 928.7838893784949, val_loss: 829.4428667316615
Validation loss decreased (943.371258 --> 943.309104).  Saving model ...
Epoch 1834, train_loss: 928.9158026986128, val_loss: 816.8766029973384
Validation loss decreased (943.309104 --> 943.240166).  Saving model ...
Epoch 1835, train_loss: 936.7974448131682, val_loss: 809.0567067863102
Validation loss decreased (943.240166 --> 943.167041).  Saving model ...
Epoch 1836, train_loss: 928.9715820515236, val_loss: 825.9838115369613
Validation loss decreased (943.167041 --> 943.103216).  Saving model ...
Epoch 1837, train_loss: 939.2383466374101, val_loss: 814.790545539878
Validation loss decreased (943.103216 --> 943.033367).  Saving model ...
Epoch 1838, train_loss: 930.6561901191719, val_loss: 796.8562170223175
Validation loss decreased (943.033367 --> 942.953836).  Saving model ...
Epoch 1839, train_loss: 924.1361292765865, val_loss: 819.5662817960757
Validation loss decreased (942.953836 --> 942.886741).  Saving model ...
Epoch 1840, train_loss: 938.4277523926577, val_loss: 807.009522331622
Validation loss decreased (942.886741 --> 942.812895).  Saving model ...
Epoch 1841, train_loss: 929.3956885681731, val_loss: 808.939214815034
Validation loss decreased (942.812895 --> 942.740177).  Saving model ...
Epoch 1842, train_loss: 932.327784015115, val_loss: 825.877139823746
Validation loss decreased (942.740177 --> 942.676734).  Saving model ...
Epoch 1843, train_loss: 935.6580949100211, val_loss: 819.4990554267166
Validation loss decreased (942.676734 --> 942.609898).  Saving model ...
Epoch 1844, train_loss: 930.1411435913199, val_loss: 802.099947792071
Validation loss decreased (942.609898 --> 942.533700).  Saving model ...
Epoch 1845, train_loss: 932.1515374515969, val_loss: 784.0619501871755
Validation loss decreased (942.533700 --> 942.447807).  Saving model ...
Epoch 1846, train_loss: 918.3476477383865, val_loss: 822.291070587326
Validation loss decreased (942.447807 --> 942.382717).  Saving model ...
Epoch 1847, train_loss: 930.120611522576, val_loss: 815.4683094021567
Validation loss decreased (942.382717 --> 942.314003).  Saving model ...
Epoch 1848, train_loss: 924.6153438580923, val_loss: 819.2563458339815
Validation loss decreased (942.314003 --> 942.247413).  Saving model ...
Epoch 1849, train_loss: 932.2776685344446, val_loss: 820.692386763405
Validation loss decreased (942.247413 --> 942.181672).  Saving model ...
Epoch 1850, train_loss: 929.38036197948, val_loss: 816.6406106392324
Validation loss decreased (942.181672 --> 942.113812).  Saving model ...
Epoch 1851, train_loss: 927.8089142477759, val_loss: 814.7667133769723
Validation loss decreased (942.113812 --> 942.045013).  Saving model ...
Epoch 1852, train_loss: 930.4968498388115, val_loss: 818.5230486409754
Validation loss decreased (942.045013 --> 941.978317).  Saving model ...
Epoch 1853, train_loss: 926.9134879108473, val_loss: 815.9559307259323
Validation loss decreased (941.978317 --> 941.910307).  Saving model ...
Epoch 1854, train_loss: 920.7779501251489, val_loss: 825.6045155060511
Validation loss decreased (941.910307 --> 941.847575).  Saving model ...
Epoch 1855, train_loss: 937.570523626216, val_loss: 809.3918847196411
Validation loss decreased (941.847575 --> 941.776170).  Saving model ...
Epoch 1856, train_loss: 930.809986801821, val_loss: 812.6007188751302
Validation loss decreased (941.776170 --> 941.706571).  Saving model ...
Epoch 1857, train_loss: 920.3641402667636, val_loss: 828.056573776073
Validation loss decreased (941.706571 --> 941.645370).  Saving model ...
Epoch 1858, train_loss: 936.12439940039, val_loss: 822.1612316983498
Validation loss decreased (941.645370 --> 941.581062).  Saving model ...
Epoch 1859, train_loss: 930.2586521235924, val_loss: 814.2774749575059
Validation loss decreased (941.581062 --> 941.512583).  Saving model ...
Epoch 1860, train_loss: 921.5322901805515, val_loss: 813.693191843673
Validation loss decreased (941.512583 --> 941.443862).  Saving model ...
Epoch 1861, train_loss: 925.4362649858834, val_loss: 823.9598599126825
Validation loss decreased (941.443862 --> 941.380733).  Saving model ...
Epoch 1862, train_loss: 929.7750899934059, val_loss: 811.1610895692861
Validation loss decreased (941.380733 --> 941.310798).  Saving model ...
Epoch 1863, train_loss: 930.8299153436662, val_loss: 815.9369276588271
Validation loss decreased (941.310798 --> 941.243501).  Saving model ...
Epoch 1864, train_loss: 924.0033769011986, val_loss: 816.8213493209415
Validation loss decreased (941.243501 --> 941.176751).  Saving model ...
Epoch 1865, train_loss: 927.2178403247098, val_loss: 826.8744957381709
Validation loss decreased (941.176751 --> 941.115463).  Saving model ...
Epoch 1866, train_loss: 928.6670809675176, val_loss: 812.957184146422
Validation loss decreased (941.115463 --> 941.046782).  Saving model ...
Epoch 1867, train_loss: 924.5137371945033, val_loss: 799.3318230730075
Validation loss decreased (941.046782 --> 940.970877).  Saving model ...
Epoch 1868, train_loss: 924.3458315563599, val_loss: 793.3286754137499
Validation loss decreased (940.970877 --> 940.891839).  Saving model ...
Epoch 1869, train_loss: 926.5774073646368, val_loss: 818.8042267905342
Validation loss decreased (940.891839 --> 940.826517).  Saving model ...
Epoch 1870, train_loss: 923.9408775644728, val_loss: 820.5180747751396
Validation loss decreased (940.826517 --> 940.762181).  Saving model ...
Epoch 1871, train_loss: 932.6480542689344, val_loss: 805.7983215637119
Validation loss decreased (940.762181 --> 940.690046).  Saving model ...
Epoch 1872, train_loss: 917.4083219061221, val_loss: 821.7985288453323
Validation loss decreased (940.690046 --> 940.626536).  Saving model ...
Epoch 1873, train_loss: 924.6649407395098, val_loss: 820.0477871319762
Validation loss decreased (940.626536 --> 940.562158).  Saving model ...
Epoch 1874, train_loss: 924.1960209977251, val_loss: 790.8566584026374
Validation loss decreased (940.562158 --> 940.482273).  Saving model ...
Epoch 1875, train_loss: 923.3827720786884, val_loss: 827.3373272566884
Validation loss decreased (940.482273 --> 940.421929).  Saving model ...
Epoch 1876, train_loss: 931.1735099048337, val_loss: 811.7937374303739
Validation loss decreased (940.421929 --> 940.353364).  Saving model ...
Epoch 1877, train_loss: 920.362020839489, val_loss: 805.7179490590316
Validation loss decreased (940.353364 --> 940.281635).  Saving model ...
Epoch 1878, train_loss: 927.8094760842565, val_loss: 817.5554694894289
Validation loss decreased (940.281635 --> 940.216285).  Saving model ...
Epoch 1879, train_loss: 922.0516504249842, val_loss: 804.342321634116
Validation loss decreased (940.216285 --> 940.143973).  Saving model ...
Epoch 1880, train_loss: 921.9721103108493, val_loss: 797.7335142392803
Validation loss decreased (940.143973 --> 940.068223).  Saving model ...
Epoch 1881, train_loss: 926.3553304210682, val_loss: 801.9009125315702
Validation loss decreased (940.068223 --> 939.994769).  Saving model ...
Epoch 1882, train_loss: 926.4280933336452, val_loss: 808.84731311127
Validation loss decreased (939.994769 --> 939.925084).  Saving model ...
Epoch 1883, train_loss: 924.3779056845999, val_loss: 810.6510705539694
Validation loss decreased (939.925084 --> 939.856431).  Saving model ...
Epoch 1884, train_loss: 922.0572990055429, val_loss: 820.4493242276818
Validation loss decreased (939.856431 --> 939.793051).  Saving model ...
Epoch 1885, train_loss: 929.6352979862157, val_loss: 812.2609838313747
Validation loss decreased (939.793051 --> 939.725395).  Saving model ...
Epoch 1886, train_loss: 920.8176078842545, val_loss: 812.2755960796718
Validation loss decreased (939.725395 --> 939.657818).  Saving model ...
Epoch 1887, train_loss: 930.4482263653607, val_loss: 788.2194045336823
Validation loss decreased (939.657818 --> 939.577564).  Saving model ...
Epoch 1888, train_loss: 922.7398592903729, val_loss: 802.7603270326722
Validation loss decreased (939.577564 --> 939.505098).  Saving model ...
Epoch 1889, train_loss: 922.8857131344267, val_loss: 792.7530740670364
Validation loss decreased (939.505098 --> 939.427410).  Saving model ...
Epoch 1890, train_loss: 917.195474747272, val_loss: 804.3013794986628
Validation loss decreased (939.427410 --> 939.355915).  Saving model ...
Epoch 1891, train_loss: 922.322471631949, val_loss: 806.067647840513
Validation loss decreased (939.355915 --> 939.285429).  Saving model ...
Epoch 1892, train_loss: 918.3989186985615, val_loss: 806.1335202654424
Validation loss decreased (939.285429 --> 939.215053).  Saving model ...
Epoch 1893, train_loss: 926.3882375185152, val_loss: 796.1637605344807
Validation loss decreased (939.215053 --> 939.139484).  Saving model ...
Epoch 1894, train_loss: 921.087978222809, val_loss: 809.9490145467166
Validation loss decreased (939.139484 --> 939.071274).  Saving model ...
Epoch 1895, train_loss: 930.5033288339461, val_loss: 803.7018884475806
Validation loss decreased (939.071274 --> 938.999839).  Saving model ...
Epoch 1896, train_loss: 926.6025008518652, val_loss: 815.3075056955771
Validation loss decreased (938.999839 --> 938.934600).  Saving model ...
Epoch 1897, train_loss: 920.5631645918049, val_loss: 815.7638278223629
Validation loss decreased (938.934600 --> 938.869671).  Saving model ...
Epoch 1898, train_loss: 918.953383524659, val_loss: 795.2919046757178
Validation loss decreased (938.869671 --> 938.794024).  Saving model ...
Epoch 1899, train_loss: 921.328084308722, val_loss: 796.7191509404669
Validation loss decreased (938.794024 --> 938.719209).  Saving model ...
Epoch 1900, train_loss: 915.8045975397932, val_loss: 798.2122818358076
Validation loss decreased (938.719209 --> 938.645258).  Saving model ...
Epoch 1901, train_loss: 920.4137774482476, val_loss: 805.5017840022289
Validation loss decreased (938.645258 --> 938.575219).  Saving model ...
Epoch 1902, train_loss: 912.682088086378, val_loss: 812.2644603799008
Validation loss decreased (938.575219 --> 938.508809).  Saving model ...
Epoch 1903, train_loss: 919.1143527627291, val_loss: 811.488822717159
Validation loss decreased (938.508809 --> 938.442062).  Saving model ...
Epoch 1904, train_loss: 921.3299586873309, val_loss: 807.3508682195787
Validation loss decreased (938.442062 --> 938.373212).  Saving model ...
Epoch 1905, train_loss: 916.1793225192233, val_loss: 811.1669944271775
Validation loss decreased (938.373212 --> 938.306437).  Saving model ...
Epoch 1906, train_loss: 913.3218281383189, val_loss: 807.1057005295047
Validation loss decreased (938.306437 --> 938.237601).  Saving model ...
Epoch 1907, train_loss: 920.6882876722844, val_loss: 793.0551852570421
Validation loss decreased (938.237601 --> 938.161470).  Saving model ...
Epoch 1908, train_loss: 920.1778645259249, val_loss: 799.2288777412531
Validation loss decreased (938.161470 --> 938.088654).  Saving model ...
Epoch 1909, train_loss: 918.4596971423707, val_loss: 794.2659705358302
Validation loss decreased (938.088654 --> 938.013315).  Saving model ...
Epoch 1910, train_loss: 912.4385357266013, val_loss: 797.4624793218683
Validation loss decreased (938.013315 --> 937.939728).  Saving model ...
Epoch 1911, train_loss: 918.0485550720322, val_loss: 810.2473249461032
Validation loss decreased (937.939728 --> 937.872908).  Saving model ...
Epoch 1912, train_loss: 923.4855054225538, val_loss: 789.6512163072825
Validation loss decreased (937.872908 --> 937.795387).  Saving model ...
Epoch 1913, train_loss: 915.6917449532893, val_loss: 809.1879214160972
Validation loss decreased (937.795387 --> 937.728158).  Saving model ...
Epoch 1914, train_loss: 917.0346179475692, val_loss: 814.1416836160421
Validation loss decreased (937.728158 --> 937.663589).  Saving model ...
Epoch 1915, train_loss: 921.1114972471548, val_loss: 793.3218327692042
Validation loss decreased (937.663589 --> 937.588214).  Saving model ...
Epoch 1916, train_loss: 918.7820137757059, val_loss: 806.529097093079
Validation loss decreased (937.588214 --> 937.519812).  Saving model ...
Epoch 1917, train_loss: 921.145992886088, val_loss: 793.5685562395169
Validation loss decreased (937.519812 --> 937.444720).  Saving model ...
Epoch 1918, train_loss: 917.1798195300377, val_loss: 808.3185992374905
Validation loss decreased (937.444720 --> 937.377397).  Saving model ...
Epoch 1919, train_loss: 916.7615691954222, val_loss: 799.2190447738436
Validation loss decreased (937.377397 --> 937.305402).  Saving model ...
Epoch 1920, train_loss: 912.916227047046, val_loss: 790.4300834123516
Validation loss decreased (937.305402 --> 937.228904).  Saving model ...
Epoch 1921, train_loss: 910.0201282750111, val_loss: 815.2892853573736
Validation loss decreased (937.228904 --> 937.165427).  Saving model ...
Epoch 1922, train_loss: 912.5514324228989, val_loss: 813.1295988674516
Validation loss decreased (937.165427 --> 937.100892).  Saving model ...
Epoch 1923, train_loss: 922.029966839149, val_loss: 799.4254914050854
Validation loss decreased (937.100892 --> 937.029298).  Saving model ...
Epoch 1924, train_loss: 909.3780111755134, val_loss: 806.366513987603
Validation loss decreased (937.029298 --> 936.961386).  Saving model ...
Epoch 1925, train_loss: 913.4157395773857, val_loss: 795.9048760134202
Validation loss decreased (936.961386 --> 936.888110).  Saving model ...
Epoch 1926, train_loss: 913.6716883611126, val_loss: 806.1255695740824
Validation loss decreased (936.888110 --> 936.820217).  Saving model ...
Epoch 1927, train_loss: 919.2684907029815, val_loss: 782.790311836446
Validation loss decreased (936.820217 --> 936.740284).  Saving model ...
Epoch 1928, train_loss: 910.5023409090635, val_loss: 804.2651353357237
Validation loss decreased (936.740284 --> 936.671573).  Saving model ...
Epoch 1929, train_loss: 917.682916642301, val_loss: 800.3594170216498
Validation loss decreased (936.671573 --> 936.600908).  Saving model ...
Epoch 1930, train_loss: 914.4576908987431, val_loss: 805.3766442507946
Validation loss decreased (936.600908 --> 936.532916).  Saving model ...
Epoch 1931, train_loss: 914.5858432949124, val_loss: 795.7871574961036
Validation loss decreased (936.532916 --> 936.460029).  Saving model ...
Epoch 1932, train_loss: 907.3012098194904, val_loss: 797.893356056081
Validation loss decreased (936.460029 --> 936.388307).  Saving model ...
Epoch 1933, train_loss: 914.2417736381287, val_loss: 797.3097228118226
Validation loss decreased (936.388307 --> 936.316357).  Saving model ...
Epoch 1934, train_loss: 915.6415067487295, val_loss: 819.3103313297253
Validation loss decreased (936.316357 --> 936.255858).  Saving model ...
Epoch 1935, train_loss: 919.7943736695955, val_loss: 801.7837880691555
Validation loss decreased (936.255858 --> 936.186363).  Saving model ...
Epoch 1936, train_loss: 914.017078140764, val_loss: 804.3408978062866
Validation loss decreased (936.186363 --> 936.118261).  Saving model ...
Epoch 1937, train_loss: 919.2781603101287, val_loss: 798.6210159676162
Validation loss decreased (936.118261 --> 936.047277).  Saving model ...
Epoch 1938, train_loss: 919.4046147657449, val_loss: 783.6319637862622
Validation loss decreased (936.047277 --> 935.968631).  Saving model ...
Epoch 1939, train_loss: 912.2256649479339, val_loss: 777.5045985805327
Validation loss decreased (935.968631 --> 935.886906).  Saving model ...
Epoch 1940, train_loss: 908.1840775310017, val_loss: 797.182785951451
Validation loss decreased (935.886906 --> 935.815409).  Saving model ...
Epoch 1941, train_loss: 912.4746573094827, val_loss: 794.7409799350634
Validation loss decreased (935.815409 --> 935.742728).  Saving model ...
Epoch 1942, train_loss: 900.9056312501991, val_loss: 789.3899293070372
Validation loss decreased (935.742728 --> 935.667366).  Saving model ...
Epoch 1943, train_loss: 908.2761245143947, val_loss: 797.6898167040393
Validation loss decreased (935.667366 --> 935.596354).  Saving model ...
Epoch 1944, train_loss: 906.5891117042609, val_loss: 805.586210158357
Validation loss decreased (935.596354 --> 935.529476).  Saving model ...
Epoch 1945, train_loss: 922.905007514057, val_loss: 801.4183728153839
Validation loss decreased (935.529476 --> 935.460524).  Saving model ...
Epoch 1946, train_loss: 908.7018058461936, val_loss: 788.2383141654954
Validation loss decreased (935.460524 --> 935.384871).  Saving model ...
Epoch 1947, train_loss: 908.9254480987399, val_loss: 798.1761642515216
Validation loss decreased (935.384871 --> 935.314399).  Saving model ...
Epoch 1948, train_loss: 910.847264020724, val_loss: 792.3596979363982
Validation loss decreased (935.314399 --> 935.241013).  Saving model ...
Epoch 1949, train_loss: 913.9447257833577, val_loss: 796.8620232699977
Validation loss decreased (935.241013 --> 935.170013).  Saving model ...
Epoch 1950, train_loss: 905.2712491208664, val_loss: 801.3393569883152
Validation loss decreased (935.170013 --> 935.101382).  Saving model ...
Epoch 1951, train_loss: 913.988624244542, val_loss: 802.3323507377395
Validation loss decreased (935.101382 --> 935.033330).  Saving model ...
Epoch 1952, train_loss: 906.9103993104912, val_loss: 805.9851296356431
Validation loss decreased (935.033330 --> 934.967220).  Saving model ...
Epoch 1953, train_loss: 915.5344500752934, val_loss: 801.423287327952
Validation loss decreased (934.967220 --> 934.898841).  Saving model ...
Epoch 1954, train_loss: 915.7960445550555, val_loss: 799.5530647897941
Validation loss decreased (934.898841 --> 934.829575).  Saving model ...
Epoch 1955, train_loss: 912.5706172342973, val_loss: 782.1284755690232
Validation loss decreased (934.829575 --> 934.751467).  Saving model ...
Epoch 1956, train_loss: 909.473235311851, val_loss: 796.5617138365684
Validation loss decreased (934.751467 --> 934.680818).  Saving model ...
Epoch 1957, train_loss: 907.5170925502359, val_loss: 796.0886183585502
Validation loss decreased (934.680818 --> 934.609999).  Saving model ...
Epoch 1958, train_loss: 909.9725047440371, val_loss: 800.1935056827024
Validation loss decreased (934.609999 --> 934.541349).  Saving model ...
Epoch 1959, train_loss: 908.3777828111245, val_loss: 796.320329174554
Validation loss decreased (934.541349 --> 934.470792).  Saving model ...
Epoch 1960, train_loss: 905.3820701097796, val_loss: 798.0369984989476
Validation loss decreased (934.470792 --> 934.401183).  Saving model ...
Epoch 1961, train_loss: 905.3373277441424, val_loss: 803.1777457800839
Validation loss decreased (934.401183 --> 934.334266).  Saving model ...
Epoch 1962, train_loss: 903.3360424152845, val_loss: 802.8650835463517
Validation loss decreased (934.334266 --> 934.267259).  Saving model ...
Epoch 1963, train_loss: 910.905472718504, val_loss: 765.7857090821975
Validation loss decreased (934.267259 --> 934.181430).  Saving model ...
Epoch 1964, train_loss: 895.8423823846824, val_loss: 794.8815935987897
Validation loss decreased (934.181430 --> 934.110503).  Saving model ...
Epoch 1965, train_loss: 903.2679841243652, val_loss: 796.0352764208006
Validation loss decreased (934.110503 --> 934.040236).  Saving model ...
Epoch 1966, train_loss: 906.9357567989036, val_loss: 791.5127509376958
Validation loss decreased (934.040236 --> 933.967740).  Saving model ...
Epoch 1967, train_loss: 897.8479233894434, val_loss: 803.0811405792723
Validation loss decreased (933.967740 --> 933.901199).  Saving model ...
Epoch 1968, train_loss: 910.9896179883883, val_loss: 800.0063160692763
Validation loss decreased (933.901199 --> 933.833163).  Saving model ...
Epoch 1969, train_loss: 901.9215508549935, val_loss: 792.447108340109
Validation loss decreased (933.833163 --> 933.761357).  Saving model ...
Epoch 1970, train_loss: 906.4340408390475, val_loss: 785.6730050150994
Validation loss decreased (933.761357 --> 933.686185).  Saving model ...
Epoch 1971, train_loss: 911.8234230825894, val_loss: 808.5707041860288
Validation loss decreased (933.686185 --> 933.622707).  Saving model ...
Epoch 1972, train_loss: 903.4379237312693, val_loss: 790.9942454774072
Validation loss decreased (933.622707 --> 933.550380).  Saving model ...
Epoch 1973, train_loss: 898.843674513449, val_loss: 802.9478881864856
Validation loss decreased (933.550380 --> 933.484185).  Saving model ...
Epoch 1974, train_loss: 907.3520727756447, val_loss: 802.0429476254295
Validation loss decreased (933.484185 --> 933.417599).  Saving model ...
Epoch 1975, train_loss: 899.6539202447276, val_loss: 786.9555296456815
Validation loss decreased (933.417599 --> 933.343441).  Saving model ...
Epoch 1976, train_loss: 899.4616451846224, val_loss: 803.5179989699523
Validation loss decreased (933.343441 --> 933.277740).  Saving model ...
Epoch 1977, train_loss: 911.1672494039883, val_loss: 797.160361486563
Validation loss decreased (933.277740 --> 933.208889).  Saving model ...
Epoch 1978, train_loss: 905.0620917680687, val_loss: 799.7728731383218
Validation loss decreased (933.208889 --> 933.141429).  Saving model ...
Epoch 1979, train_loss: 908.0318607368309, val_loss: 778.7436545782622
Validation loss decreased (933.141429 --> 933.063411).  Saving model ...
Epoch 1980, train_loss: 900.8883343603582, val_loss: 795.235849369014
Validation loss decreased (933.063411 --> 932.993801).  Saving model ...
Epoch 1981, train_loss: 896.7003101258946, val_loss: 789.149941539897
Validation loss decreased (932.993801 --> 932.921190).  Saving model ...
Epoch 1982, train_loss: 902.6681033135822, val_loss: 794.0790131893424
Validation loss decreased (932.921190 --> 932.851138).  Saving model ...
Epoch 1983, train_loss: 897.4784253286152, val_loss: 791.0162946900836
Validation loss decreased (932.851138 --> 932.779613).  Saving model ...
Epoch 1984, train_loss: 901.6299515165148, val_loss: 800.1889981426353
Validation loss decreased (932.779613 --> 932.712783).  Saving model ...
Epoch 1985, train_loss: 898.514068153775, val_loss: 801.5918146316872
Validation loss decreased (932.712783 --> 932.646727).  Saving model ...
Epoch 1986, train_loss: 900.9323430489854, val_loss: 794.7912140087507
Validation loss decreased (932.646727 --> 932.577313).  Saving model ...
Epoch 1987, train_loss: 908.228829640545, val_loss: 796.4787495217943
Validation loss decreased (932.577313 --> 932.508819).  Saving model ...
Epoch 1988, train_loss: 903.6961046346192, val_loss: 773.3070327557019
Validation loss decreased (932.508819 --> 932.428737).  Saving model ...
Epoch 1989, train_loss: 903.4099418796453, val_loss: 789.2484109047608
Validation loss decreased (932.428737 --> 932.356751).  Saving model ...
Epoch 1990, train_loss: 897.1205748476974, val_loss: 786.520352569973
Validation loss decreased (932.356751 --> 932.283466).  Saving model ...
Epoch 1991, train_loss: 902.1990732706059, val_loss: 791.0957872979067
Validation loss decreased (932.283466 --> 932.212554).  Saving model ...
Epoch 1992, train_loss: 904.8460708231644, val_loss: 788.1758525273314
Validation loss decreased (932.212554 --> 932.140246).  Saving model ...
Epoch 1993, train_loss: 902.2778765652098, val_loss: 792.3832286260525
Validation loss decreased (932.140246 --> 932.070122).  Saving model ...
Epoch 1994, train_loss: 906.3642125958057, val_loss: 798.1887070088475
Validation loss decreased (932.070122 --> 932.002980).  Saving model ...
Epoch 1995, train_loss: 894.6920520054858, val_loss: 774.4366816117148
Validation loss decreased (932.002980 --> 931.923999).  Saving model ...
Epoch 1996, train_loss: 896.7463695821943, val_loss: 793.8299493592095
Validation loss decreased (931.923999 --> 931.854814).  Saving model ...
Epoch 1997, train_loss: 899.8189144948303, val_loss: 798.241217372837
Validation loss decreased (931.854814 --> 931.787907).  Saving model ...
Epoch 1998, train_loss: 894.315676481245, val_loss: 792.5697428178568
Validation loss decreased (931.787907 --> 931.718228).  Saving model ...
Epoch 1999, train_loss: 897.9582593099441, val_loss: 794.6077164868515
Validation loss decreased (931.718228 --> 931.649638).  Saving model ...
Epoch 2000, train_loss: 897.6741239849865, val_loss: 796.8145153481432
Validation loss decreased (931.649638 --> 931.582221).  Saving model ...
Epoch 2001, train_loss: 896.8298452042773, val_loss: 802.6609396536924
Validation loss decreased (931.582221 --> 931.517792).  Saving model ...
Epoch 2002, train_loss: 896.8111658160498, val_loss: 786.8144896067955
Validation loss decreased (931.517792 --> 931.445513).  Saving model ...
Epoch 2003, train_loss: 898.8200688233957, val_loss: 802.4781897862531
Validation loss decreased (931.445513 --> 931.381126).  Saving model ...
Epoch 2004, train_loss: 897.6386837673164, val_loss: 800.0078811127609
Validation loss decreased (931.381126 --> 931.315570).  Saving model ...
Epoch 2005, train_loss: 897.2063340320136, val_loss: 788.1957023130964
Validation loss decreased (931.315570 --> 931.244189).  Saving model ...
Epoch 2006, train_loss: 899.3530234798951, val_loss: 783.2274160001012
Validation loss decreased (931.244189 --> 931.170402).  Saving model ...
Epoch 2007, train_loss: 895.0655849548436, val_loss: 787.6893668243177
Validation loss decreased (931.170402 --> 931.098912).  Saving model ...
Epoch 2008, train_loss: 903.0000146281592, val_loss: 780.9206782267271
Validation loss decreased (931.098912 --> 931.024122).  Saving model ...
Epoch 2009, train_loss: 892.382823011025, val_loss: 777.702367001706
Validation loss decreased (931.024122 --> 930.947804).  Saving model ...
Epoch 2010, train_loss: 893.3578029084673, val_loss: 792.0562713794357
Validation loss decreased (930.947804 --> 930.878704).  Saving model ...
Epoch 2011, train_loss: 901.8936187095852, val_loss: 786.6565375998285
Validation loss decreased (930.878704 --> 930.806987).  Saving model ...
Epoch 2012, train_loss: 895.01395158231, val_loss: 788.753095997594
Validation loss decreased (930.806987 --> 930.736384).  Saving model ...
Epoch 2013, train_loss: 890.8148781948977, val_loss: 790.0029995348499
Validation loss decreased (930.736384 --> 930.666472).  Saving model ...
Epoch 2014, train_loss: 895.0403935335905, val_loss: 794.9401690014865
Validation loss decreased (930.666472 --> 930.599080).  Saving model ...
Epoch 2015, train_loss: 904.7462707440972, val_loss: 784.4579671673423
Validation loss decreased (930.599080 --> 930.526554).  Saving model ...
Epoch 2016, train_loss: 893.6519720751756, val_loss: 780.4657877479659
Validation loss decreased (930.526554 --> 930.452119).  Saving model ...
Epoch 2017, train_loss: 895.8911258562615, val_loss: 773.7477433441085
Validation loss decreased (930.452119 --> 930.374427).  Saving model ...
Epoch 2018, train_loss: 890.786061492436, val_loss: 788.2326808208669
Validation loss decreased (930.374427 --> 930.303990).  Saving model ...
Epoch 2019, train_loss: 893.5223267620368, val_loss: 785.1690094269646
Validation loss decreased (930.303990 --> 930.232106).  Saving model ...
Epoch 2020, train_loss: 895.3832733098664, val_loss: 782.5866935190669
Validation loss decreased (930.232106 --> 930.159014).  Saving model ...
Epoch 2021, train_loss: 895.5255359183017, val_loss: 784.4363701693436
Validation loss decreased (930.159014 --> 930.086909).  Saving model ...
Epoch 2022, train_loss: 898.7312393344507, val_loss: 783.2277951655342
Validation loss decreased (930.086909 --> 930.014279).  Saving model ...
Epoch 2023, train_loss: 889.9845264838938, val_loss: 799.3567405759846
Validation loss decreased (930.014279 --> 929.949693).  Saving model ...
Epoch 2024, train_loss: 901.1854249362361, val_loss: 789.8585157975003
Validation loss decreased (929.949693 --> 929.880478).  Saving model ...
Epoch 2025, train_loss: 894.5318156332479, val_loss: 791.8730176174862
Validation loss decreased (929.880478 --> 929.812326).  Saving model ...
Epoch 2026, train_loss: 886.8222870630851, val_loss: 784.8598202936737
Validation loss decreased (929.812326 --> 929.740780).  Saving model ...
Epoch 2027, train_loss: 892.4340151841998, val_loss: 794.1958519920377
Validation loss decreased (929.740780 --> 929.673910).  Saving model ...
Epoch 2028, train_loss: 890.1828886735228, val_loss: 778.3185623396768
Validation loss decreased (929.673910 --> 929.599277).  Saving model ...
Epoch 2029, train_loss: 888.975753972589, val_loss: 773.3100691768196
Validation loss decreased (929.599277 --> 929.522250).  Saving model ...
Epoch 2030, train_loss: 890.992350844305, val_loss: 787.7563162673845
Validation loss decreased (929.522250 --> 929.452414).  Saving model ...
Epoch 2031, train_loss: 894.6402643643754, val_loss: 785.806028238513
Validation loss decreased (929.452414 --> 929.381687).  Saving model ...
Epoch 2032, train_loss: 893.303855362049, val_loss: 788.9140022068774
Validation loss decreased (929.381687 --> 929.312559).  Saving model ...
Epoch 2033, train_loss: 886.2192597766644, val_loss: 792.7812418309408
Validation loss decreased (929.312559 --> 929.245402).  Saving model ...
Epoch 2034, train_loss: 890.7216046483401, val_loss: 783.4989029921868
Validation loss decreased (929.245402 --> 929.173747).  Saving model ...
Epoch 2035, train_loss: 892.2663916371255, val_loss: 785.7824960147672
Validation loss decreased (929.173747 --> 929.103284).  Saving model ...
Epoch 2036, train_loss: 884.8624425268874, val_loss: 789.4819656189725
Validation loss decreased (929.103284 --> 929.034708).  Saving model ...
Epoch 2037, train_loss: 894.3902099723656, val_loss: 776.1270164987778
Validation loss decreased (929.034708 --> 928.959643).  Saving model ...
Epoch 2038, train_loss: 894.7102559421037, val_loss: 771.6605295944879
Validation loss decreased (928.959643 --> 928.882460).  Saving model ...
Epoch 2039, train_loss: 890.1266029796664, val_loss: 787.342853785687
Validation loss decreased (928.882460 --> 928.813044).  Saving model ...
Epoch 2040, train_loss: 888.0131796171192, val_loss: 779.9066433766155
Validation loss decreased (928.813044 --> 928.740050).  Saving model ...
Epoch 2041, train_loss: 882.2235382842465, val_loss: 798.1661028360436
Validation loss decreased (928.740050 --> 928.676075).  Saving model ...
Epoch 2042, train_loss: 891.151417049129, val_loss: 783.4825664547197
Validation loss decreased (928.676075 --> 928.604971).  Saving model ...
Epoch 2043, train_loss: 895.6512537173212, val_loss: 782.8166101558563
Validation loss decreased (928.604971 --> 928.533611).  Saving model ...
Epoch 2044, train_loss: 884.6548920423114, val_loss: 779.3012493656634
Validation loss decreased (928.533611 --> 928.460601).  Saving model ...
Epoch 2045, train_loss: 888.9467114132475, val_loss: 761.4080571461499
Validation loss decreased (928.460601 --> 928.378913).  Saving model ...
Epoch 2046, train_loss: 885.9437011604122, val_loss: 758.9737781528635
Validation loss decreased (928.378913 --> 928.296115).  Saving model ...
Epoch 2047, train_loss: 884.9848090557327, val_loss: 780.5847542787702
Validation loss decreased (928.296115 --> 928.223955).  Saving model ...
Epoch 2048, train_loss: 889.6573448629559, val_loss: 778.3697719428716
Validation loss decreased (928.223955 --> 928.150784).  Saving model ...
Epoch 2049, train_loss: 887.8152104124871, val_loss: 768.1630268663611
Validation loss decreased (928.150784 --> 928.072703).  Saving model ...
Epoch 2050, train_loss: 880.9506851580309, val_loss: 784.4515461610866
Validation loss decreased (928.072703 --> 928.002644).  Saving model ...
Epoch 2051, train_loss: 886.4130325494885, val_loss: 790.5388761412436
Validation loss decreased (928.002644 --> 927.935621).  Saving model ...
Epoch 2052, train_loss: 887.4877866887751, val_loss: 776.437009691795
Validation loss decreased (927.935621 --> 927.861791).  Saving model ...
Epoch 2053, train_loss: 882.7472959195595, val_loss: 785.8770572817106
Validation loss decreased (927.861791 --> 927.792632).  Saving model ...
Epoch 2054, train_loss: 888.4616548177737, val_loss: 770.22687057568
Validation loss decreased (927.792632 --> 927.715920).  Saving model ...
Epoch 2055, train_loss: 889.6404592536355, val_loss: 778.5524260248079
Validation loss decreased (927.715920 --> 927.643334).  Saving model ...
Epoch 2056, train_loss: 886.0981490281273, val_loss: 783.4263999633214
Validation loss decreased (927.643334 --> 927.573190).  Saving model ...
Epoch 2057, train_loss: 879.9766558921928, val_loss: 789.3575031774573
Validation loss decreased (927.573190 --> 927.505997).  Saving model ...
Epoch 2058, train_loss: 889.587444008011, val_loss: 776.8835421878099
Validation loss decreased (927.505997 --> 927.432808).  Saving model ...
Epoch 2059, train_loss: 881.5459090389988, val_loss: 787.5318685219686
Validation loss decreased (927.432808 --> 927.364862).  Saving model ...
Epoch 2060, train_loss: 881.8517693844295, val_loss: 780.0900283498232
Validation loss decreased (927.364862 --> 927.293370).  Saving model ...
Epoch 2061, train_loss: 890.1209041404481, val_loss: 784.091839434107
Validation loss decreased (927.293370 --> 927.223888).  Saving model ...
Epoch 2062, train_loss: 884.1874954373403, val_loss: 781.2481782873914
Validation loss decreased (927.223888 --> 927.153095).  Saving model ...
Epoch 2063, train_loss: 881.9849599722278, val_loss: 773.9836987440896
Validation loss decreased (927.153095 --> 927.078849).  Saving model ...
Epoch 2064, train_loss: 883.508963127308, val_loss: 775.7021891445805
Validation loss decreased (927.078849 --> 927.005507).  Saving model ...
Epoch 2065, train_loss: 882.2169610556308, val_loss: 782.4919377005102
Validation loss decreased (927.005507 --> 926.935525).  Saving model ...
Epoch 2066, train_loss: 883.9555387634675, val_loss: 786.9196987001322
Validation loss decreased (926.935525 --> 926.867754).  Saving model ...
Epoch 2067, train_loss: 886.093596015842, val_loss: 764.914729499464
Validation loss decreased (926.867754 --> 926.789402).  Saving model ...
Epoch 2068, train_loss: 882.9694655622204, val_loss: 765.6914855288136
Validation loss decreased (926.789402 --> 926.711502).  Saving model ...
Epoch 2069, train_loss: 884.1314256144976, val_loss: 760.9941080823432
Validation loss decreased (926.711502 --> 926.631406).  Saving model ...
Epoch 2070, train_loss: 887.8106960519078, val_loss: 765.7737200274955
Validation loss decreased (926.631406 --> 926.553697).  Saving model ...
Epoch 2071, train_loss: 884.1457883525342, val_loss: 757.708828665482
Validation loss decreased (926.553697 --> 926.472169).  Saving model ...
Epoch 2072, train_loss: 878.3833421996821, val_loss: 783.5246325774325
Validation loss decreased (926.472169 --> 926.403179).  Saving model ...
Epoch 2073, train_loss: 880.2714146181603, val_loss: 772.65356022667
Validation loss decreased (926.403179 --> 926.329011).  Saving model ...
Epoch 2074, train_loss: 880.8555569826015, val_loss: 782.3618772662791
Validation loss decreased (926.329011 --> 926.259596).  Saving model ...
Epoch 2075, train_loss: 884.7682642878968, val_loss: 768.9264908626566
Validation loss decreased (926.259596 --> 926.183773).  Saving model ...
Epoch 2076, train_loss: 888.2321791533202, val_loss: 770.3643796111037
Validation loss decreased (926.183773 --> 926.108715).  Saving model ...
Epoch 2077, train_loss: 882.384947344886, val_loss: 777.5458734559352
Validation loss decreased (926.108715 --> 926.037188).  Saving model ...
Epoch 2078, train_loss: 886.3179606308486, val_loss: 758.8253929551223
Validation loss decreased (926.037188 --> 925.956720).  Saving model ...
Epoch 2079, train_loss: 884.1039630598588, val_loss: 778.8660421829754
Validation loss decreased (925.956720 --> 925.885969).  Saving model ...
Epoch 2080, train_loss: 879.9432575040892, val_loss: 780.0534095177387
Validation loss decreased (925.885969 --> 925.815857).  Saving model ...
Epoch 2081, train_loss: 884.438906740359, val_loss: 766.6815820916275
Validation loss decreased (925.815857 --> 925.739387).  Saving model ...
Epoch 2082, train_loss: 882.2596611404741, val_loss: 759.7840829160037
Validation loss decreased (925.739387 --> 925.659678).  Saving model ...
Epoch 2083, train_loss: 880.3470202008488, val_loss: 762.6218254960468
Validation loss decreased (925.659678 --> 925.581407).  Saving model ...
Epoch 2084, train_loss: 877.3518189691148, val_loss: 763.646701889833
Validation loss decreased (925.581407 --> 925.503703).  Saving model ...
Epoch 2085, train_loss: 872.8701311574797, val_loss: 779.9211380514392
Validation loss decreased (925.503703 --> 925.433880).  Saving model ...
Epoch 2086, train_loss: 887.9677697757412, val_loss: 775.335731077404
Validation loss decreased (925.433880 --> 925.361925).  Saving model ...
Epoch 2087, train_loss: 882.5912231400489, val_loss: 777.8860716011349
Validation loss decreased (925.361925 --> 925.291261).  Saving model ...
Epoch 2088, train_loss: 883.9874885125338, val_loss: 772.533199967433
Validation loss decreased (925.291261 --> 925.218101).  Saving model ...
Epoch 2089, train_loss: 884.2290872524147, val_loss: 766.7299633091026
Validation loss decreased (925.218101 --> 925.142233).  Saving model ...
Epoch 2090, train_loss: 879.7376315421258, val_loss: 775.5523258463544
Validation loss decreased (925.142233 --> 925.070658).  Saving model ...
Epoch 2091, train_loss: 876.106454800771, val_loss: 775.7573117215326
Validation loss decreased (925.070658 --> 924.999251).  Saving model ...
Epoch 2092, train_loss: 879.5949181086174, val_loss: 762.5773011363548
Validation loss decreased (924.999251 --> 924.921611).  Saving model ...
Epoch 2093, train_loss: 877.0823469646483, val_loss: 772.1846693962813
Validation loss decreased (924.921611 --> 924.848636).  Saving model ...
Epoch 2094, train_loss: 882.557764583558, val_loss: 763.0387757826405
Validation loss decreased (924.848636 --> 924.771363).  Saving model ...
Epoch 2095, train_loss: 880.6746868491291, val_loss: 764.6744871606871
Validation loss decreased (924.771363 --> 924.694945).  Saving model ...
Epoch 2096, train_loss: 878.4566567405153, val_loss: 770.6360454379629
Validation loss decreased (924.694945 --> 924.621443).  Saving model ...
Epoch 2097, train_loss: 889.5506722021456, val_loss: 760.0762301418076
Validation loss decreased (924.621443 --> 924.542976).  Saving model ...
Epoch 2098, train_loss: 876.6583701386091, val_loss: 764.3040934140373
Validation loss decreased (924.542976 --> 924.466599).  Saving model ...
Epoch 2099, train_loss: 873.7104024333568, val_loss: 773.4073034720954
Validation loss decreased (924.466599 --> 924.394632).  Saving model ...
Epoch 2100, train_loss: 877.0068853103086, val_loss: 771.2901441940335
Validation loss decreased (924.394632 --> 924.321725).  Saving model ...
Epoch 2101, train_loss: 888.2373855162684, val_loss: 759.1942928014861
Validation loss decreased (924.321725 --> 924.243130).  Saving model ...
Epoch 2102, train_loss: 873.6577578742325, val_loss: 769.243249938466
Validation loss decreased (924.243130 --> 924.169391).  Saving model ...
Epoch 2103, train_loss: 876.755352224419, val_loss: 766.6664208253115
Validation loss decreased (924.169391 --> 924.094497).  Saving model ...
Epoch 2104, train_loss: 868.9946675116473, val_loss: 768.0362858339153
Validation loss decreased (924.094497 --> 924.020325).  Saving model ...
Epoch 2105, train_loss: 875.5371607256882, val_loss: 761.066154518856
Validation loss decreased (924.020325 --> 923.942912).  Saving model ...
Epoch 2106, train_loss: 879.1276436539466, val_loss: 752.1111365785204
Validation loss decreased (923.942912 --> 923.861320).  Saving model ...
Epoch 2107, train_loss: 874.8353248952322, val_loss: 757.3897050869246
Validation loss decreased (923.861320 --> 923.782311).  Saving model ...
Epoch 2108, train_loss: 876.6904786013154, val_loss: 769.8873258592024
Validation loss decreased (923.782311 --> 923.709306).  Saving model ...
Epoch 2109, train_loss: 876.1684651482191, val_loss: 775.6920340246847
Validation loss decreased (923.709306 --> 923.639122).  Saving model ...
Epoch 2110, train_loss: 878.1864307138059, val_loss: 780.0234782507024
Validation loss decreased (923.639122 --> 923.571058).  Saving model ...
Epoch 2111, train_loss: 872.4777495384069, val_loss: 768.8923523629155
Validation loss decreased (923.571058 --> 923.497785).  Saving model ...
Epoch 2112, train_loss: 878.7331366555893, val_loss: 767.0040008385316
Validation loss decreased (923.497785 --> 923.423688).  Saving model ...
Epoch 2113, train_loss: 872.692699368865, val_loss: 746.7035716214226
Validation loss decreased (923.423688 --> 923.340053).  Saving model ...
Epoch 2114, train_loss: 873.9738579315837, val_loss: 749.8074993137631
Validation loss decreased (923.340053 --> 923.257966).  Saving model ...
Epoch 2115, train_loss: 873.5219574593733, val_loss: 755.0619272210421
Validation loss decreased (923.257966 --> 923.178441).  Saving model ...
Epoch 2116, train_loss: 874.6223168533346, val_loss: 766.9543065940011
Validation loss decreased (923.178441 --> 923.104611).  Saving model ...
Epoch 2117, train_loss: 872.8596933513141, val_loss: 770.0452321282363
Validation loss decreased (923.104611 --> 923.032311).  Saving model ...
Epoch 2118, train_loss: 874.5737911554081, val_loss: 776.4645544732058
Validation loss decreased (923.032311 --> 922.963110).  Saving model ...
Epoch 2119, train_loss: 866.1823811964945, val_loss: 782.8163120955892
Validation loss decreased (922.963110 --> 922.896971).  Saving model ...
Epoch 2120, train_loss: 879.8813464948053, val_loss: 770.1435258678597
Validation loss decreased (922.896971 --> 922.824918).  Saving model ...
Epoch 2121, train_loss: 873.0746930338797, val_loss: 751.9794073387981
Validation loss decreased (922.824918 --> 922.744368).  Saving model ...
Epoch 2122, train_loss: 878.676294956286, val_loss: 753.1147336904208
Validation loss decreased (922.744368 --> 922.664430).  Saving model ...
Epoch 2123, train_loss: 872.9752419003681, val_loss: 755.7627123198575
Validation loss decreased (922.664430 --> 922.585814).  Saving model ...
Epoch 2124, train_loss: 867.6582648637889, val_loss: 752.6212284799639
Validation loss decreased (922.585814 --> 922.505793).  Saving model ...
Epoch 2125, train_loss: 869.5526620539556, val_loss: 757.227836849811
Validation loss decreased (922.505793 --> 922.428015).  Saving model ...
Epoch 2126, train_loss: 873.1443044504796, val_loss: 769.1972525566156
Validation loss decreased (922.428015 --> 922.355940).  Saving model ...
Epoch 2127, train_loss: 873.1726609193449, val_loss: 752.3617451180354
Validation loss decreased (922.355940 --> 922.276018).  Saving model ...
Epoch 2128, train_loss: 873.50066933405, val_loss: 759.1503889638849
Validation loss decreased (922.276018 --> 922.199361).  Saving model ...
Epoch 2129, train_loss: 871.6189703899475, val_loss: 754.1341243303044
Validation loss decreased (922.199361 --> 922.120421).  Saving model ...
Epoch 2130, train_loss: 874.0260420105807, val_loss: 756.3641908906567
Validation loss decreased (922.120421 --> 922.042601).  Saving model ...
Epoch 2131, train_loss: 874.9690375831605, val_loss: 753.7729669767067
Validation loss decreased (922.042601 --> 921.963638).  Saving model ...
Epoch 2132, train_loss: 867.2090441503996, val_loss: 767.7152895845751
Validation loss decreased (921.963638 --> 921.891289).  Saving model ...
Epoch 2133, train_loss: 869.4882516524148, val_loss: 765.9142526073148
Validation loss decreased (921.891289 --> 921.818163).  Saving model ...
Epoch 2134, train_loss: 875.6508760952858, val_loss: 750.5880111969514
Validation loss decreased (921.818163 --> 921.737924).  Saving model ...
Epoch 2135, train_loss: 859.7865008145361, val_loss: 752.5367040439228
Validation loss decreased (921.737924 --> 921.658673).  Saving model ...
Epoch 2136, train_loss: 871.1758388636869, val_loss: 770.1965790530489
Validation loss decreased (921.658673 --> 921.587764).  Saving model ...
Epoch 2137, train_loss: 876.6329993295168, val_loss: 763.5116576357241
Validation loss decreased (921.587764 --> 921.513793).  Saving model ...
Epoch 2138, train_loss: 875.3783475993566, val_loss: 752.605192394621
Validation loss decreased (921.513793 --> 921.434790).  Saving model ...
Epoch 2139, train_loss: 870.5500326966034, val_loss: 766.3946465902418
Validation loss decreased (921.434790 --> 921.362307).  Saving model ...
Epoch 2140, train_loss: 871.5978553028732, val_loss: 751.7221123076259
Validation loss decreased (921.362307 --> 921.283036).  Saving model ...
Epoch 2141, train_loss: 866.7938908784316, val_loss: 757.8242130415639
Validation loss decreased (921.283036 --> 921.206689).  Saving model ...
Epoch 2142, train_loss: 870.823770421154, val_loss: 757.9046774161084
Validation loss decreased (921.206689 --> 921.130451).  Saving model ...
Epoch 2143, train_loss: 868.7244961363111, val_loss: 766.7912545728464
Validation loss decreased (921.130451 --> 921.058431).  Saving model ...
Epoch 2144, train_loss: 874.4358155604504, val_loss: 748.6727858081903
Validation loss decreased (921.058431 --> 920.978027).  Saving model ...
Epoch 2145, train_loss: 867.9524400001166, val_loss: 758.162379712639
Validation loss decreased (920.978027 --> 920.902122).  Saving model ...
Epoch 2146, train_loss: 867.7989952162619, val_loss: 756.1062953661327
Validation loss decreased (920.902122 --> 920.825330).  Saving model ...
Epoch 2147, train_loss: 870.3854990136837, val_loss: 763.4004560227748
Validation loss decreased (920.825330 --> 920.752007).  Saving model ...
Epoch 2148, train_loss: 867.3316739210746, val_loss: 756.1073823794392
Validation loss decreased (920.752007 --> 920.675357).  Saving model ...
Epoch 2149, train_loss: 874.8683157627111, val_loss: 741.0832225488956
Validation loss decreased (920.675357 --> 920.591787).  Saving model ...
Epoch 2150, train_loss: 863.0581101527403, val_loss: 751.2153498006422
Validation loss decreased (920.591787 --> 920.513007).  Saving model ...
Epoch 2151, train_loss: 866.160121491437, val_loss: 757.8249656260456
Validation loss decreased (920.513007 --> 920.437373).  Saving model ...
Epoch 2152, train_loss: 869.5051879057947, val_loss: 753.1522745816687
Validation loss decreased (920.437373 --> 920.359639).  Saving model ...
Epoch 2153, train_loss: 862.0438100469893, val_loss: 755.9803740532752
Validation loss decreased (920.359639 --> 920.283290).  Saving model ...
Epoch 2154, train_loss: 869.814175932391, val_loss: 750.6615807826212
Validation loss decreased (920.283290 --> 920.204542).  Saving model ...
Epoch 2155, train_loss: 866.3930189310413, val_loss: 749.9843322688124
Validation loss decreased (920.204542 --> 920.125554).  Saving model ...
Epoch 2156, train_loss: 865.265717829059, val_loss: 764.5771545483445
Validation loss decreased (920.125554 --> 920.053407).  Saving model ...
Epoch 2157, train_loss: 866.0721343636748, val_loss: 748.7854595916803
Validation loss decreased (920.053407 --> 919.974006).  Saving model ...
Epoch 2158, train_loss: 873.7257815436727, val_loss: 749.723176416799
Validation loss decreased (919.974006 --> 919.895113).  Saving model ...
Epoch 2159, train_loss: 868.1639484438404, val_loss: 761.8328451024604
Validation loss decreased (919.895113 --> 919.821902).  Saving model ...
Epoch 2160, train_loss: 874.7233461351428, val_loss: 749.3180359022155
Validation loss decreased (919.821902 --> 919.742965).  Saving model ...
Epoch 2161, train_loss: 872.1373135667392, val_loss: 747.5398593543747
Validation loss decreased (919.742965 --> 919.663279).  Saving model ...
Epoch 2162, train_loss: 871.0144243425101, val_loss: 750.2066262481171
Validation loss decreased (919.663279 --> 919.584899).  Saving model ...
Epoch 2163, train_loss: 866.7617317424326, val_loss: 743.3180763797628
Validation loss decreased (919.584899 --> 919.503407).  Saving model ...
Epoch 2164, train_loss: 865.7186675927562, val_loss: 760.2390711164917
Validation loss decreased (919.503407 --> 919.429810).  Saving model ...
Epoch 2165, train_loss: 868.651935111542, val_loss: 738.6088466889549
Validation loss decreased (919.429810 --> 919.346290).  Saving model ...
Epoch 2166, train_loss: 870.7668776365352, val_loss: 742.0585905936031
Validation loss decreased (919.346290 --> 919.264440).  Saving model ...
Epoch 2167, train_loss: 859.8737304791468, val_loss: 740.3902383837986
Validation loss decreased (919.264440 --> 919.181895).  Saving model ...
Epoch 2168, train_loss: 860.2935566472341, val_loss: 750.4194670130038
Validation loss decreased (919.181895 --> 919.104053).  Saving model ...
Epoch 2169, train_loss: 859.6423332005569, val_loss: 745.414944338876
Validation loss decreased (919.104053 --> 919.023975).  Saving model ...
Epoch 2170, train_loss: 866.1246020619756, val_loss: 745.6963584258601
Validation loss decreased (919.023975 --> 918.944100).  Saving model ...
Epoch 2171, train_loss: 867.5262574376965, val_loss: 756.8731191906332
Validation loss decreased (918.944100 --> 918.869447).  Saving model ...
Epoch 2172, train_loss: 869.1162955926659, val_loss: 741.828739848435
Validation loss decreased (918.869447 --> 918.787937).  Saving model ...
Epoch 2173, train_loss: 868.4962723704267, val_loss: 749.6630046585756
Validation loss decreased (918.787937 --> 918.710107).  Saving model ...
Epoch 2174, train_loss: 860.2403338363382, val_loss: 746.5775482508983
Validation loss decreased (918.710107 --> 918.630929).  Saving model ...
Epoch 2175, train_loss: 865.985966773549, val_loss: 742.279435822158
Validation loss decreased (918.630929 --> 918.549848).  Saving model ...
Epoch 2176, train_loss: 863.4594086977571, val_loss: 740.7171520997421
Validation loss decreased (918.549848 --> 918.468123).  Saving model ...
Epoch 2177, train_loss: 867.0743194447217, val_loss: 738.3767145190858
Validation loss decreased (918.468123 --> 918.385399).  Saving model ...
Epoch 2178, train_loss: 861.0411405989223, val_loss: 743.4963226569804
Validation loss decreased (918.385399 --> 918.305101).  Saving model ...
Epoch 2179, train_loss: 857.3277571950006, val_loss: 743.7489908944236
Validation loss decreased (918.305101 --> 918.224992).  Saving model ...
Epoch 2180, train_loss: 865.4176041836208, val_loss: 745.4697750712658
Validation loss decreased (918.224992 --> 918.145747).  Saving model ...
Epoch 2181, train_loss: 865.0452736322293, val_loss: 746.7529141714398
Validation loss decreased (918.145747 --> 918.067162).  Saving model ...
Epoch 2182, train_loss: 860.3314707808448, val_loss: 760.8378734767657
Validation loss decreased (918.067162 --> 917.995105).  Saving model ...
Epoch 2183, train_loss: 870.6461913798063, val_loss: 743.1738461490914
Validation loss decreased (917.995105 --> 917.915022).  Saving model ...
Epoch 2184, train_loss: 864.3865354779281, val_loss: 753.6068906854038
Validation loss decreased (917.915022 --> 917.839789).  Saving model ...
Epoch 2185, train_loss: 869.1328866865468, val_loss: 740.4314557831045
Validation loss decreased (917.839789 --> 917.758595).  Saving model ...
Epoch 2186, train_loss: 862.9683561868798, val_loss: 745.1226014584857
Validation loss decreased (917.758595 --> 917.679622).  Saving model ...
Epoch 2187, train_loss: 861.9251467485866, val_loss: 736.5507088305994
Validation loss decreased (917.679622 --> 917.596801).  Saving model ...
Epoch 2188, train_loss: 869.3150048565122, val_loss: 733.531139063184
Validation loss decreased (917.596801 --> 917.512676).  Saving model ...
Epoch 2189, train_loss: 854.4975161379771, val_loss: 750.645576088351
Validation loss decreased (917.512676 --> 917.436446).  Saving model ...
Epoch 2190, train_loss: 869.4128678350307, val_loss: 745.975995900024
Validation loss decreased (917.436446 --> 917.358154).  Saving model ...
Epoch 2191, train_loss: 864.2898840736824, val_loss: 742.9549468701529
Validation loss decreased (917.358154 --> 917.278554).  Saving model ...
Epoch 2192, train_loss: 865.1993706581179, val_loss: 734.0887903465165
Validation loss decreased (917.278554 --> 917.194982).  Saving model ...
Epoch 2193, train_loss: 861.6396248620596, val_loss: 752.7925219895329
Validation loss decreased (917.194982 --> 917.120015).  Saving model ...
Epoch 2194, train_loss: 865.1738966388692, val_loss: 736.9760492277477
Validation loss decreased (917.120015 --> 917.037908).  Saving model ...
Epoch 2195, train_loss: 863.8146337983829, val_loss: 739.1327850476791
Validation loss decreased (917.037908 --> 916.956857).  Saving model ...
Epoch 2196, train_loss: 864.3077345114303, val_loss: 730.0317249211668
Validation loss decreased (916.956857 --> 916.871737).  Saving model ...
Epoch 2197, train_loss: 868.1371451409752, val_loss: 741.8804019407653
Validation loss decreased (916.871737 --> 916.792087).  Saving model ...
Epoch 2198, train_loss: 856.2678180942547, val_loss: 745.3326501259429
Validation loss decreased (916.792087 --> 916.714080).  Saving model ...
Epoch 2199, train_loss: 858.9912233061428, val_loss: 741.8031065327041
Validation loss decreased (916.714080 --> 916.634538).  Saving model ...
Epoch 2200, train_loss: 863.1548544694808, val_loss: 731.5117464480687
Validation loss decreased (916.634538 --> 916.550392).  Saving model ...
Epoch 2201, train_loss: 863.0815359839014, val_loss: 733.1272995921969
Validation loss decreased (916.550392 --> 916.467055).  Saving model ...
Epoch 2202, train_loss: 864.4461888222439, val_loss: 743.2779131957008
Validation loss decreased (916.467055 --> 916.388405).  Saving model ...
Epoch 2203, train_loss: 866.7139160208419, val_loss: 744.0122710609658
Validation loss decreased (916.388405 --> 916.310159).  Saving model ...
Epoch 2204, train_loss: 858.519934838915, val_loss: 746.1761092159815
Validation loss decreased (916.310159 --> 916.232965).  Saving model ...
Epoch 2205, train_loss: 860.3882814388489, val_loss: 733.1041769453992
Validation loss decreased (916.232965 --> 916.149914).  Saving model ...
Epoch 2206, train_loss: 859.9610747068116, val_loss: 731.2472190847662
Validation loss decreased (916.149914 --> 916.066096).  Saving model ...
Epoch 2207, train_loss: 864.0481842948918, val_loss: 731.6481673118251
Validation loss decreased (916.066096 --> 915.982535).  Saving model ...
Epoch 2208, train_loss: 855.7766926746382, val_loss: 731.1554017337716
Validation loss decreased (915.982535 --> 915.898827).  Saving model ...
Epoch 2209, train_loss: 858.1674055243236, val_loss: 736.6338779705984
Validation loss decreased (915.898827 --> 915.817675).  Saving model ...
Epoch 2210, train_loss: 856.4051190189756, val_loss: 727.9464709925433
Validation loss decreased (915.817675 --> 915.732665).  Saving model ...
Epoch 2211, train_loss: 857.8059919445968, val_loss: 730.2820414071392
Validation loss decreased (915.732665 --> 915.648789).  Saving model ...
Epoch 2212, train_loss: 859.6217810588414, val_loss: 730.009451630248
Validation loss decreased (915.648789 --> 915.564865).  Saving model ...
Epoch 2213, train_loss: 857.5776002714057, val_loss: 737.838786719342
Validation loss decreased (915.564865 --> 915.484555).  Saving model ...
Epoch 2214, train_loss: 859.9731826965887, val_loss: 732.9294489043068
Validation loss decreased (915.484555 --> 915.402100).  Saving model ...
Epoch 2215, train_loss: 861.9433349871133, val_loss: 735.4838003291687
Validation loss decreased (915.402100 --> 915.320873).  Saving model ...
Epoch 2216, train_loss: 857.7534753707405, val_loss: 732.908006601709
Validation loss decreased (915.320873 --> 915.238557).  Saving model ...
Epoch 2217, train_loss: 864.3153412539403, val_loss: 736.7914471387312
Validation loss decreased (915.238557 --> 915.158067).  Saving model ...
Epoch 2218, train_loss: 862.4976572071988, val_loss: 732.0863886134604
Validation loss decreased (915.158067 --> 915.075528).  Saving model ...
Epoch 2219, train_loss: 856.0813386235586, val_loss: 730.5424330838632
Validation loss decreased (915.075528 --> 914.992367).  Saving model ...
Epoch 2220, train_loss: 854.0518682515448, val_loss: 730.3872561828407
Validation loss decreased (914.992367 --> 914.909212).  Saving model ...
Epoch 2221, train_loss: 857.3434052110094, val_loss: 743.7956506113654
Validation loss decreased (914.909212 --> 914.832168).  Saving model ...
Epoch 2222, train_loss: 856.9123555926474, val_loss: 716.8758607654772
Validation loss decreased (914.832168 --> 914.743079).  Saving model ...
Epoch 2223, train_loss: 857.0318895394505, val_loss: 735.3801223063579
Validation loss decreased (914.743079 --> 914.662394).  Saving model ...
Epoch 2224, train_loss: 863.4197942261866, val_loss: 726.7355515846278
Validation loss decreased (914.662394 --> 914.577894).  Saving model ...
Epoch 2225, train_loss: 851.0806722089458, val_loss: 725.3279806637433
Validation loss decreased (914.577894 --> 914.492838).  Saving model ...
Epoch 2226, train_loss: 846.5974024907881, val_loss: 745.3430308723229
Validation loss decreased (914.492838 --> 914.416850).  Saving model ...
Epoch 2227, train_loss: 862.0311499511012, val_loss: 732.0655349296884
Validation loss decreased (914.416850 --> 914.334968).  Saving model ...
Epoch 2228, train_loss: 853.8626426515948, val_loss: 732.5840916588351
Validation loss decreased (914.334968 --> 914.253392).  Saving model ...
Epoch 2229, train_loss: 868.7704540786998, val_loss: 737.9672583884222
Validation loss decreased (914.253392 --> 914.174305).  Saving model ...
Epoch 2230, train_loss: 857.8321653841568, val_loss: 745.6305771461351
Validation loss decreased (914.174305 --> 914.098724).  Saving model ...
Epoch 2231, train_loss: 859.0538640776088, val_loss: 734.8307490319676
Validation loss decreased (914.098724 --> 914.018371).  Saving model ...
Epoch 2232, train_loss: 851.7224650162646, val_loss: 726.0989581301919
Validation loss decreased (914.018371 --> 913.934178).  Saving model ...
Epoch 2233, train_loss: 852.7151033504628, val_loss: 729.2461471651881
Validation loss decreased (913.934178 --> 913.851469).  Saving model ...
Epoch 2234, train_loss: 853.4576293734681, val_loss: 725.9458374416719
Validation loss decreased (913.851469 --> 913.767358).  Saving model ...
Epoch 2235, train_loss: 853.4624462309954, val_loss: 721.9346215253407
Validation loss decreased (913.767358 --> 913.681526).  Saving model ...
Epoch 2236, train_loss: 849.2128153426875, val_loss: 766.1808628329082
Validation loss decreased (913.681526 --> 913.615560).  Saving model ...
Epoch 2237, train_loss: 855.7630182864202, val_loss: 722.7714661306364
Validation loss decreased (913.615560 --> 913.530248).  Saving model ...
Epoch 2238, train_loss: 849.8449317801451, val_loss: 736.2008045273357
Validation loss decreased (913.530248 --> 913.451012).  Saving model ...
Epoch 2239, train_loss: 858.5056188508175, val_loss: 723.2722242374443
Validation loss decreased (913.451012 --> 913.366073).  Saving model ...
Epoch 2240, train_loss: 852.0298856202895, val_loss: 750.0338685553605
Validation loss decreased (913.366073 --> 913.293157).  Saving model ...
Epoch 2241, train_loss: 855.8317845824243, val_loss: 746.1687047998112
Validation loss decreased (913.293157 --> 913.218581).  Saving model ...
Epoch 2242, train_loss: 856.5045265728938, val_loss: 734.8999618524093
Validation loss decreased (913.218581 --> 913.139045).  Saving model ...
Epoch 2243, train_loss: 857.8106218533924, val_loss: 721.8522095557055
Validation loss decreased (913.139045 --> 913.053764).  Saving model ...
Epoch 2244, train_loss: 855.385633290299, val_loss: 733.7893938559292
Validation loss decreased (913.053764 --> 912.973878).  Saving model ...
Epoch 2245, train_loss: 857.198710756108, val_loss: 716.553055259133
Validation loss decreased (912.973878 --> 912.886385).  Saving model ...
Epoch 2246, train_loss: 856.7700463789295, val_loss: 719.7791732702763
Validation loss decreased (912.886385 --> 912.800407).  Saving model ...
Epoch 2247, train_loss: 848.0070804152841, val_loss: 729.3324668949623
Validation loss decreased (912.800407 --> 912.718757).  Saving model ...
Epoch 2248, train_loss: 855.5971910454612, val_loss: 748.0534572597456
Validation loss decreased (912.718757 --> 912.645507).  Saving model ...
Epoch 2249, train_loss: 856.4682927774008, val_loss: 709.5045166683198
Validation loss decreased (912.645507 --> 912.555182).  Saving model ...
Epoch 2250, train_loss: 846.7171120873371, val_loss: 741.1270446968962
Validation loss decreased (912.555182 --> 912.478992).  Saving model ...
Epoch 2251, train_loss: 846.0639823628461, val_loss: 723.7254211729323
Validation loss decreased (912.478992 --> 912.395138).  Saving model ...
Epoch 2252, train_loss: 855.5410093833526, val_loss: 720.5887960842473
Validation loss decreased (912.395138 --> 912.309967).  Saving model ...
Epoch 2253, train_loss: 849.3775371796144, val_loss: 726.8958723365489
Validation loss decreased (912.309967 --> 912.227670).  Saving model ...
Epoch 2254, train_loss: 857.9422621476225, val_loss: 719.33021424171
Validation loss decreased (912.227670 --> 912.142090).  Saving model ...
Epoch 2255, train_loss: 857.0762317839029, val_loss: 720.7127603404169
Validation loss decreased (912.142090 --> 912.057199).  Saving model ...
Epoch 2256, train_loss: 844.4889371497617, val_loss: 746.6104223075512
Validation loss decreased (912.057199 --> 911.983863).  Saving model ...
Epoch 2257, train_loss: 854.3570679851484, val_loss: 718.1253754703425
Validation loss decreased (911.983863 --> 911.897971).  Saving model ...
Epoch 2258, train_loss: 850.9959223666405, val_loss: 717.6552501750325
Validation loss decreased (911.897971 --> 911.811946).  Saving model ...
Epoch 2259, train_loss: 843.2273016718858, val_loss: 736.3403344776124
Validation loss decreased (911.811946 --> 911.734270).  Saving model ...
Epoch 2260, train_loss: 853.653285989068, val_loss: 707.781647226634
Validation loss decreased (911.734270 --> 911.644025).  Saving model ...
Epoch 2261, train_loss: 849.7722430846424, val_loss: 727.7983788431465
Validation loss decreased (911.644025 --> 911.562714).  Saving model ...
Epoch 2262, train_loss: 849.389751029158, val_loss: 713.1173731008283
Validation loss decreased (911.562714 --> 911.474984).  Saving model ...
Epoch 2263, train_loss: 852.6498747216958, val_loss: 720.5440317402614
Validation loss decreased (911.474984 --> 911.390613).  Saving model ...
Epoch 2264, train_loss: 849.8817890279397, val_loss: 711.3439700074218
Validation loss decreased (911.390613 --> 911.302253).  Saving model ...
Epoch 2265, train_loss: 847.3188817030566, val_loss: 724.7500927058527
Validation loss decreased (911.302253 --> 911.219890).  Saving model ...
Epoch 2266, train_loss: 842.8018965494603, val_loss: 719.9118987903884
Validation loss decreased (911.219890 --> 911.135465).  Saving model ...
Epoch 2267, train_loss: 847.3117888477652, val_loss: 724.2202949458251
Validation loss decreased (911.135465 --> 911.053014).  Saving model ...
Epoch 2268, train_loss: 852.8642961482399, val_loss: 716.9966941762744
Validation loss decreased (911.053014 --> 910.967451).  Saving model ...
Epoch 2269, train_loss: 845.4596997094412, val_loss: 717.7345317370251
Validation loss decreased (910.967451 --> 910.882289).  Saving model ...
Epoch 2270, train_loss: 846.2966494244247, val_loss: 727.0458102442711
Validation loss decreased (910.882289 --> 910.801304).  Saving model ...
Epoch 2271, train_loss: 851.4616191176119, val_loss: 715.0201419358453
Validation loss decreased (910.801304 --> 910.715095).  Saving model ...
Epoch 2272, train_loss: 854.4487739383657, val_loss: 713.0445708411934
Validation loss decreased (910.715095 --> 910.628092).  Saving model ...
Epoch 2273, train_loss: 846.4215336235062, val_loss: 723.3953998923963
Validation loss decreased (910.628092 --> 910.545719).  Saving model ...
Epoch 2274, train_loss: 856.6074381658949, val_loss: 727.4523475565184
Validation loss decreased (910.545719 --> 910.465203).  Saving model ...
Epoch 2275, train_loss: 850.717904692514, val_loss: 726.1128368319187
Validation loss decreased (910.465203 --> 910.384169).  Saving model ...
Epoch 2276, train_loss: 856.6254241076011, val_loss: 715.684876811648
Validation loss decreased (910.384169 --> 910.298625).  Saving model ...
Epoch 2277, train_loss: 840.5743935514723, val_loss: 740.5624107875648
Validation loss decreased (910.298625 --> 910.224081).  Saving model ...
Epoch 2278, train_loss: 849.792592876042, val_loss: 716.371787750445
Validation loss decreased (910.224081 --> 910.138984).  Saving model ...
Epoch 2279, train_loss: 846.6559933597126, val_loss: 736.2863826846195
Validation loss decreased (910.138984 --> 910.062699).  Saving model ...
Epoch 2280, train_loss: 853.2336949555596, val_loss: 716.8206406297508
Validation loss decreased (910.062699 --> 909.977944).  Saving model ...
Epoch 2281, train_loss: 853.8165525417054, val_loss: 710.7288881312369
Validation loss decreased (909.977944 --> 909.890592).  Saving model ...
Epoch 2282, train_loss: 836.0264034920272, val_loss: 734.8526623054235
Validation loss decreased (909.890592 --> 909.813888).  Saving model ...
Epoch 2283, train_loss: 850.7770266771064, val_loss: 712.8786515770797
Validation loss decreased (909.813888 --> 909.727627).  Saving model ...
Epoch 2284, train_loss: 850.3134235400294, val_loss: 726.8342462692881
Validation loss decreased (909.727627 --> 909.647551).  Saving model ...
Epoch 2285, train_loss: 845.7903490572735, val_loss: 720.120165879318
Validation loss decreased (909.647551 --> 909.564607).  Saving model ...
Epoch 2286, train_loss: 857.4262410664602, val_loss: 719.8614501532912
Validation loss decreased (909.564607 --> 909.481622).  Saving model ...
Epoch 2287, train_loss: 847.3430193242805, val_loss: 713.3328216252283
Validation loss decreased (909.481622 --> 909.395855).  Saving model ...
Epoch 2288, train_loss: 848.0687188733926, val_loss: 720.1457504687268
Validation loss decreased (909.395855 --> 909.313141).  Saving model ...
Epoch 2289, train_loss: 844.0304693158281, val_loss: 730.1888770525876
Validation loss decreased (909.313141 --> 909.234886).  Saving model ...
Epoch 2290, train_loss: 845.1318458919819, val_loss: 726.7092227648145
Validation loss decreased (909.234886 --> 909.155181).  Saving model ...
Epoch 2291, train_loss: 850.9082017762194, val_loss: 723.4148725247604
Validation loss decreased (909.155181 --> 909.074107).  Saving model ...
Epoch 2292, train_loss: 845.1421120284097, val_loss: 718.7858791507064
Validation loss decreased (909.074107 --> 908.991084).  Saving model ...
Epoch 2293, train_loss: 847.8623096819291, val_loss: 710.0109564885056
Validation loss decreased (908.991084 --> 908.904307).  Saving model ...
Epoch 2294, train_loss: 846.0852277265132, val_loss: 711.6924669544345
Validation loss decreased (908.904307 --> 908.818338).  Saving model ...
Epoch 2295, train_loss: 842.8199549319141, val_loss: 727.7576269205742
Validation loss decreased (908.818338 --> 908.739445).  Saving model ...
Epoch 2296, train_loss: 843.8925095957187, val_loss: 724.6586560136963
Validation loss decreased (908.739445 --> 908.659270).  Saving model ...
Epoch 2297, train_loss: 842.1274068660681, val_loss: 720.3318523972786
Validation loss decreased (908.659270 --> 908.577282).  Saving model ...
Epoch 2298, train_loss: 847.308915458546, val_loss: 720.0841629527014
Validation loss decreased (908.577282 --> 908.495257).  Saving model ...
Epoch 2299, train_loss: 848.7276455642965, val_loss: 724.6441872004339
Validation loss decreased (908.495257 --> 908.415287).  Saving model ...
Epoch 2300, train_loss: 845.2905158225291, val_loss: 722.5508441913129
Validation loss decreased (908.415287 --> 908.334476).  Saving model ...
Epoch 2301, train_loss: 849.0657604045973, val_loss: 711.9301645954121
Validation loss decreased (908.334476 --> 908.249120).  Saving model ...
Epoch 2302, train_loss: 840.4225294042008, val_loss: 729.0044726712728
Validation loss decreased (908.249120 --> 908.171256).  Saving model ...
Epoch 2303, train_loss: 850.7688058030626, val_loss: 714.0847632824824
Validation loss decreased (908.171256 --> 908.086980).  Saving model ...
Epoch 2304, train_loss: 840.2369431680647, val_loss: 723.4659689669919
Validation loss decreased (908.086980 --> 908.006849).  Saving model ...
Epoch 2305, train_loss: 840.4058881694593, val_loss: 712.0932009580843
Validation loss decreased (908.006849 --> 907.921854).  Saving model ...
Epoch 2306, train_loss: 847.0665226362595, val_loss: 706.7520338708053
Validation loss decreased (907.921854 --> 907.834617).  Saving model ...
Epoch 2307, train_loss: 840.7391367524157, val_loss: 715.9172295705699
Validation loss decreased (907.834617 --> 907.751428).  Saving model ...
Epoch 2308, train_loss: 846.6607507794972, val_loss: 718.7046048027609
Validation loss decreased (907.751428 --> 907.669518).  Saving model ...
Epoch 2309, train_loss: 846.1323095487909, val_loss: 713.1787474055203
Validation loss decreased (907.669518 --> 907.585287).  Saving model ...
Epoch 2310, train_loss: 840.5180348786947, val_loss: 717.3799675189566
Validation loss decreased (907.585287 --> 907.502947).  Saving model ...
Epoch 2311, train_loss: 847.4231395147169, val_loss: 717.8435932791675
Validation loss decreased (907.502947 --> 907.420879).  Saving model ...
Epoch 2312, train_loss: 844.5535330020738, val_loss: 733.8543583470583
Validation loss decreased (907.420879 --> 907.345807).  Saving model ...
Epoch 2313, train_loss: 842.0338345503616, val_loss: 717.2390112171682
Validation loss decreased (907.345807 --> 907.263616).  Saving model ...
Epoch 2314, train_loss: 849.8111297066382, val_loss: 711.4366881828618
Validation loss decreased (907.263616 --> 907.178989).  Saving model ...
Epoch 2315, train_loss: 847.5711290694852, val_loss: 726.2268501184166
Validation loss decreased (907.178989 --> 907.100824).  Saving model ...
Epoch 2316, train_loss: 851.811701071352, val_loss: 693.0795564777433
Validation loss decreased (907.100824 --> 907.008414).  Saving model ...
Epoch 2317, train_loss: 844.765703210469, val_loss: 711.7809722623451
Validation loss decreased (907.008414 --> 906.924155).  Saving model ...
Epoch 2318, train_loss: 844.5962093704535, val_loss: 709.8409503062677
Validation loss decreased (906.924155 --> 906.839132).  Saving model ...
Epoch 2319, train_loss: 842.5725368130419, val_loss: 713.2411307502676
Validation loss decreased (906.839132 --> 906.755649).  Saving model ...
Epoch 2320, train_loss: 835.5585079188548, val_loss: 721.3980616280656
Validation loss decreased (906.755649 --> 906.675753).  Saving model ...
Epoch 2321, train_loss: 852.5843896408368, val_loss: 717.8383343439742
Validation loss decreased (906.675753 --> 906.594393).  Saving model ...
Epoch 2322, train_loss: 846.8813676615666, val_loss: 708.4626216390178
Validation loss decreased (906.594393 --> 906.509065).  Saving model ...
Epoch 2323, train_loss: 847.7597768792241, val_loss: 707.68667699624
Validation loss decreased (906.509065 --> 906.423476).  Saving model ...
Epoch 2324, train_loss: 842.8692419270153, val_loss: 707.4277632745438
Validation loss decreased (906.423476 --> 906.337850).  Saving model ...
Epoch 2325, train_loss: 840.1026857284752, val_loss: 713.1521370564237
Validation loss decreased (906.337850 --> 906.254759).  Saving model ...
Epoch 2326, train_loss: 841.3630550093332, val_loss: 725.5000771445369
Validation loss decreased (906.254759 --> 906.177049).  Saving model ...
Epoch 2327, train_loss: 846.3039986909471, val_loss: 731.4724712462117
Validation loss decreased (906.177049 --> 906.101972).  Saving model ...
Epoch 2328, train_loss: 844.5692092124098, val_loss: 709.9714873717339
Validation loss decreased (906.101972 --> 906.017723).  Saving model ...
Epoch 2329, train_loss: 844.460838960903, val_loss: 710.7118109942697
Validation loss decreased (906.017723 --> 905.933865).  Saving model ...
Epoch 2330, train_loss: 847.4392295047215, val_loss: 715.1877126737105
Validation loss decreased (905.933865 --> 905.852000).  Saving model ...
Epoch 2331, train_loss: 841.3050971500317, val_loss: 711.7554958181249
Validation loss decreased (905.852000 --> 905.768732).  Saving model ...
Epoch 2332, train_loss: 846.8976845287832, val_loss: 703.4842736134484
Validation loss decreased (905.768732 --> 905.681989).  Saving model ...
Epoch 2333, train_loss: 841.0595795975689, val_loss: 704.6879511626452
Validation loss decreased (905.681989 --> 905.595837).  Saving model ...
Epoch 2334, train_loss: 844.1958086558323, val_loss: 691.6818876871798
Validation loss decreased (905.595837 --> 905.504185).  Saving model ...
Epoch 2335, train_loss: 837.1845110695689, val_loss: 728.4069736761188
Validation loss decreased (905.504185 --> 905.428341).  Saving model ...
Epoch 2336, train_loss: 844.4579432690706, val_loss: 714.9636267023948
Validation loss decreased (905.428341 --> 905.346806).  Saving model ...
Epoch 2337, train_loss: 850.8322960533154, val_loss: 717.424144242969
Validation loss decreased (905.346806 --> 905.266394).  Saving model ...
Epoch 2338, train_loss: 845.468611626887, val_loss: 714.706661217599
Validation loss decreased (905.266394 --> 905.184889).  Saving model ...
Epoch 2339, train_loss: 844.8777642078505, val_loss: 696.4254179658602
Validation loss decreased (905.184889 --> 905.095637).  Saving model ...
Epoch 2340, train_loss: 839.8625492823381, val_loss: 717.5302860167402
Validation loss decreased (905.095637 --> 905.015481).  Saving model ...
Epoch 2341, train_loss: 849.665662994929, val_loss: 712.7547971837279
Validation loss decreased (905.015481 --> 904.933354).  Saving model ...
Epoch 2342, train_loss: 842.6397513557002, val_loss: 705.6229995822465
Validation loss decreased (904.933354 --> 904.848251).  Saving model ...
Epoch 2343, train_loss: 842.0495027267289, val_loss: 704.2901571568186
Validation loss decreased (904.848251 --> 904.762652).  Saving model ...
Epoch 2344, train_loss: 843.2906444890702, val_loss: 709.2422452823984
Validation loss decreased (904.762652 --> 904.679239).  Saving model ...
Epoch 2345, train_loss: 841.3795769530888, val_loss: 715.6471796620666
Validation loss decreased (904.679239 --> 904.598628).  Saving model ...
Epoch 2346, train_loss: 844.7296104667574, val_loss: 709.546348375358
Validation loss decreased (904.598628 --> 904.515486).  Saving model ...
Epoch 2347, train_loss: 845.3862794950834, val_loss: 709.5064426016806
Validation loss decreased (904.515486 --> 904.432397).  Saving model ...
Epoch 2348, train_loss: 847.4537144831493, val_loss: 710.843644296262
Validation loss decreased (904.432397 --> 904.349949).  Saving model ...
Epoch 2349, train_loss: 837.0712367954499, val_loss: 718.340763033187
Validation loss decreased (904.349949 --> 904.270762).  Saving model ...
Epoch 2350, train_loss: 836.801707296018, val_loss: 715.5387104370749
Validation loss decreased (904.270762 --> 904.190451).  Saving model ...
Epoch 2351, train_loss: 840.8891727133924, val_loss: 718.7163652222025
Validation loss decreased (904.190451 --> 904.111559).  Saving model ...
Epoch 2352, train_loss: 841.6467517916266, val_loss: 719.1910032416495
Validation loss decreased (904.111559 --> 904.032936).  Saving model ...
Epoch 2353, train_loss: 841.2797161532154, val_loss: 715.1692784529151
Validation loss decreased (904.032936 --> 903.952671).  Saving model ...
Epoch 2354, train_loss: 843.2178178021261, val_loss: 705.3621962538804
Validation loss decreased (903.952671 --> 903.868308).  Saving model ...
Epoch 2355, train_loss: 839.1256371558113, val_loss: 716.747788335692
Validation loss decreased (903.868308 --> 903.788852).  Saving model ...
Epoch 2356, train_loss: 844.2028700809932, val_loss: 699.7805355163308
Validation loss decreased (903.788852 --> 903.702261).  Saving model ...
Epoch 2357, train_loss: 836.5007639985539, val_loss: 709.3527389808165
Validation loss decreased (903.702261 --> 903.619804).  Saving model ...
Epoch 2358, train_loss: 839.9801016328663, val_loss: 717.64100699672
Validation loss decreased (903.619804 --> 903.540933).  Saving model ...
Epoch 2359, train_loss: 837.7991953130446, val_loss: 708.1472733032264
Validation loss decreased (903.540933 --> 903.458104).  Saving model ...
Epoch 2360, train_loss: 842.057185025792, val_loss: 722.0828676521336
Validation loss decreased (903.458104 --> 903.381250).  Saving model ...
Epoch 2361, train_loss: 840.8529782536026, val_loss: 699.1089963373984
Validation loss decreased (903.381250 --> 903.294731).  Saving model ...
Epoch 2362, train_loss: 838.1191069386254, val_loss: 727.203990010244
Validation loss decreased (903.294731 --> 903.220179).  Saving model ...
Epoch 2363, train_loss: 837.7484314454214, val_loss: 705.1857107931268
Validation loss decreased (903.220179 --> 903.136373).  Saving model ...
Epoch 2364, train_loss: 840.4466571536066, val_loss: 706.242242449522
Validation loss decreased (903.136373 --> 903.053084).  Saving model ...
Epoch 2365, train_loss: 843.8836845620419, val_loss: 701.8900984975809
Validation loss decreased (903.053084 --> 902.968026).  Saving model ...
Epoch 2366, train_loss: 835.7061938056842, val_loss: 725.4658253324474
Validation loss decreased (902.968026 --> 902.893004).  Saving model ...
Epoch 2367, train_loss: 840.9520430497589, val_loss: 723.1760938544186
Validation loss decreased (902.893004 --> 902.817078).  Saving model ...
Epoch 2368, train_loss: 841.8335497941971, val_loss: 716.4546571512134
Validation loss decreased (902.817078 --> 902.738377).  Saving model ...
Epoch 2369, train_loss: 832.4819711407872, val_loss: 718.2678845805593
Validation loss decreased (902.738377 --> 902.660509).  Saving model ...
Epoch 2370, train_loss: 840.0944696269522, val_loss: 701.331693866849
Validation loss decreased (902.660509 --> 902.575560).  Saving model ...
Epoch 2371, train_loss: 836.716238213974, val_loss: 734.189624775615
Validation loss decreased (902.575560 --> 902.504541).  Saving model ...
Epoch 2372, train_loss: 838.3271950076833, val_loss: 719.0519326095891
Validation loss decreased (902.504541 --> 902.427200).  Saving model ...
Epoch 2373, train_loss: 840.1572383750943, val_loss: 713.5560114507211
Validation loss decreased (902.427200 --> 902.347609).  Saving model ...
Epoch 2374, train_loss: 843.9239412876162, val_loss: 694.3120051030097
Validation loss decreased (902.347609 --> 902.259978).  Saving model ...
Epoch 2375, train_loss: 831.2264093931118, val_loss: 715.6055069764346
Validation loss decreased (902.259978 --> 902.181386).  Saving model ...
Epoch 2376, train_loss: 833.2826618526235, val_loss: 712.6673902755093
Validation loss decreased (902.181386 --> 902.101625).  Saving model ...
Epoch 2377, train_loss: 841.8327760659616, val_loss: 705.3706477616121
Validation loss decreased (902.101625 --> 902.018860).  Saving model ...
Epoch 2378, train_loss: 840.3303465268707, val_loss: 723.9232700742285
Validation loss decreased (902.018860 --> 901.943967).  Saving model ...
Epoch 2379, train_loss: 845.3576211214191, val_loss: 696.984474378438
Validation loss decreased (901.943967 --> 901.857813).  Saving model ...
Epoch 2380, train_loss: 844.7048092786736, val_loss: 700.4037988897497
Validation loss decreased (901.857813 --> 901.773169).  Saving model ...
Epoch 2381, train_loss: 839.8325963045344, val_loss: 702.6598796766112
Validation loss decreased (901.773169 --> 901.689543).  Saving model ...
Epoch 2382, train_loss: 840.4742459534344, val_loss: 700.4859587900838
Validation loss decreased (901.689543 --> 901.605075).  Saving model ...
Epoch 2383, train_loss: 835.6424975066165, val_loss: 720.1496327400649
Validation loss decreased (901.605075 --> 901.528929).  Saving model ...
Epoch 2384, train_loss: 841.0388241664634, val_loss: 717.4211477590821
Validation loss decreased (901.528929 --> 901.451702).  Saving model ...
Epoch 2385, train_loss: 838.4366815257238, val_loss: 714.8202380745389
Validation loss decreased (901.451702 --> 901.373450).  Saving model ...
Epoch 2386, train_loss: 838.3805301362743, val_loss: 722.1453844720787
Validation loss decreased (901.373450 --> 901.298334).  Saving model ...
Epoch 2387, train_loss: 839.1494833112778, val_loss: 705.8646381915169
Validation loss decreased (901.298334 --> 901.216460).  Saving model ...
Epoch 2388, train_loss: 834.0819674472359, val_loss: 711.3341096753985
Validation loss decreased (901.216460 --> 901.136944).  Saving model ...
Epoch 2389, train_loss: 834.8046150322461, val_loss: 715.2234228223562
Validation loss decreased (901.136944 --> 901.059124).  Saving model ...
Epoch 2390, train_loss: 832.8035861929606, val_loss: 714.6656082046806
Validation loss decreased (901.059124 --> 900.981135).  Saving model ...
Epoch 2391, train_loss: 836.8127643636459, val_loss: 698.5004891554846
Validation loss decreased (900.981135 --> 900.896450).  Saving model ...
Epoch 2392, train_loss: 829.213282977744, val_loss: 718.0213753568023
Validation loss decreased (900.896450 --> 900.819997).  Saving model ...
Epoch 2393, train_loss: 832.1116362597184, val_loss: 708.1254292202548
Validation loss decreased (900.819997 --> 900.739473).  Saving model ...
Epoch 2394, train_loss: 835.7292434215385, val_loss: 713.8034659448708
Validation loss decreased (900.739473 --> 900.661388).  Saving model ...
Epoch 2395, train_loss: 838.9656746107213, val_loss: 718.8367514463047
Validation loss decreased (900.661388 --> 900.585470).  Saving model ...
Epoch 2396, train_loss: 833.5875011448403, val_loss: 709.0360213155769
Validation loss decreased (900.585470 --> 900.505524).  Saving model ...
Epoch 2397, train_loss: 841.1118237295485, val_loss: 695.5453242018378
Validation loss decreased (900.505524 --> 900.420017).  Saving model ...
Epoch 2398, train_loss: 832.9884054984241, val_loss: 721.5131198433925
Validation loss decreased (900.420017 --> 900.345410).  Saving model ...
Epoch 2399, train_loss: 840.4815145568209, val_loss: 732.1835688643323
Validation loss decreased (900.345410 --> 900.275314).  Saving model ...
Epoch 2400, train_loss: 837.6716662315552, val_loss: 687.776722025496
Validation loss decreased (900.275314 --> 900.186773).  Saving model ...
Epoch 2401, train_loss: 829.2832832078751, val_loss: 726.5047990177737
Validation loss decreased (900.186773 --> 900.114435).  Saving model ...
Epoch 2402, train_loss: 835.1395478426133, val_loss: 724.3682517120683
Validation loss decreased (900.114435 --> 900.041269).  Saving model ...
Epoch 2403, train_loss: 834.4216145965803, val_loss: 700.5447892541578
Validation loss decreased (900.041269 --> 899.958249).  Saving model ...
Epoch 2404, train_loss: 836.8948080309963, val_loss: 708.8023252113109
Validation loss decreased (899.958249 --> 899.878733).  Saving model ...
Epoch 2405, train_loss: 834.6738762564577, val_loss: 710.2956455330386
Validation loss decreased (899.878733 --> 899.799904).  Saving model ...
Epoch 2406, train_loss: 838.0607009145252, val_loss: 704.362351026226
Validation loss decreased (899.799904 --> 899.718675).  Saving model ...
Epoch 2407, train_loss: 839.7648882839165, val_loss: 715.243329336566
Validation loss decreased (899.718675 --> 899.642034).  Saving model ...
Epoch 2408, train_loss: 830.653360610165, val_loss: 705.1954432684073
Validation loss decreased (899.642034 --> 899.561284).  Saving model ...
Epoch 2409, train_loss: 830.7843954121514, val_loss: 729.588609294792
Validation loss decreased (899.561284 --> 899.490726).  Saving model ...
Epoch 2410, train_loss: 841.8958998431432, val_loss: 699.4189390450165
Validation loss decreased (899.490726 --> 899.407709).  Saving model ...
Epoch 2411, train_loss: 826.8851239474873, val_loss: 719.7188773123754
Validation loss decreased (899.407709 --> 899.333180).  Saving model ...
Epoch 2412, train_loss: 843.8503480099353, val_loss: 698.2555270283532
Validation loss decreased (899.333180 --> 899.249815).  Saving model ...
Epoch 2413, train_loss: 832.2047498354619, val_loss: 711.5950185900484
Validation loss decreased (899.249815 --> 899.172047).  Saving model ...
Epoch 2414, train_loss: 833.6015642372071, val_loss: 708.8455886164307
Validation loss decreased (899.172047 --> 899.093204).  Saving model ...
Epoch 2415, train_loss: 831.7237146726151, val_loss: 696.9562493400331
Validation loss decreased (899.093204 --> 899.009503).  Saving model ...
Epoch 2416, train_loss: 825.3459767940128, val_loss: 732.7380919587281
Validation loss decreased (899.009503 --> 898.940682).  Saving model ...
Epoch 2417, train_loss: 830.7828717552976, val_loss: 703.9278919341829
Validation loss decreased (898.940682 --> 898.859998).  Saving model ...
Epoch 2418, train_loss: 835.7103486021658, val_loss: 705.453576936446
Validation loss decreased (898.859998 --> 898.780012).  Saving model ...
Epoch 2419, train_loss: 831.3322885459768, val_loss: 717.2734969351359
Validation loss decreased (898.780012 --> 898.704979).  Saving model ...
Epoch 2420, train_loss: 839.2188457869304, val_loss: 699.3815762232631
Validation loss decreased (898.704979 --> 898.622614).  Saving model ...
Epoch 2421, train_loss: 832.9644600055186, val_loss: 723.8814583257945
Validation loss decreased (898.622614 --> 898.550436).  Saving model ...
Epoch 2422, train_loss: 834.0123808767354, val_loss: 699.8779210581824
Validation loss decreased (898.550436 --> 898.468408).  Saving model ...
Epoch 2423, train_loss: 828.3964453971408, val_loss: 712.0836992202754
Validation loss decreased (898.468408 --> 898.391485).  Saving model ...
Epoch 2424, train_loss: 840.6238356533714, val_loss: 702.1325192086896
Validation loss decreased (898.391485 --> 898.310520).  Saving model ...
Epoch 2425, train_loss: 832.8804192169003, val_loss: 707.2425696363715
Validation loss decreased (898.310520 --> 898.231729).  Saving model ...
Epoch 2426, train_loss: 830.8696921082053, val_loss: 731.3068284998117
Validation loss decreased (898.231729 --> 898.162922).  Saving model ...
Epoch 2427, train_loss: 837.2416044079519, val_loss: 725.7254839954885
Validation loss decreased (898.162922 --> 898.091873).  Saving model ...
Epoch 2428, train_loss: 829.9447765392968, val_loss: 725.3801373616856
Validation loss decreased (898.091873 --> 898.020739).  Saving model ...
Epoch 2429, train_loss: 835.7194095678641, val_loss: 725.0605808543828
Validation loss decreased (898.020739 --> 897.949533).  Saving model ...
Epoch 2430, train_loss: 829.6542043759185, val_loss: 721.6913917027027
Validation loss decreased (897.949533 --> 897.876999).  Saving model ...
Epoch 2431, train_loss: 833.2504053288342, val_loss: 719.8228906132889
Validation loss decreased (897.876999 --> 897.803756).  Saving model ...
Epoch 2432, train_loss: 829.7375729902658, val_loss: 713.7169185059821
Validation loss decreased (897.803756 --> 897.728062).  Saving model ...
Epoch 2433, train_loss: 828.0636578653488, val_loss: 695.7675743473238
Validation loss decreased (897.728062 --> 897.645053).  Saving model ...
Epoch 2434, train_loss: 827.8562115614471, val_loss: 710.3847834790855
Validation loss decreased (897.645053 --> 897.568118).  Saving model ...
Epoch 2435, train_loss: 837.9094840224128, val_loss: 716.798800702371
Validation loss decreased (897.568118 --> 897.493880).  Saving model ...
Epoch 2436, train_loss: 835.8926076385915, val_loss: 711.1670443725807
Validation loss decreased (897.493880 --> 897.417391).  Saving model ...
Epoch 2437, train_loss: 833.3867447842349, val_loss: 711.5049960803434
Validation loss decreased (897.417391 --> 897.341104).  Saving model ...
Epoch 2438, train_loss: 832.4377096415086, val_loss: 699.2422674734726
Validation loss decreased (897.341104 --> 897.259849).  Saving model ...
Epoch 2439, train_loss: 834.1408730042504, val_loss: 715.0674482970106
Validation loss decreased (897.259849 --> 897.185150).  Saving model ...
Epoch 2440, train_loss: 838.580151137753, val_loss: 683.3483405062999
Validation loss decreased (897.185150 --> 897.097512).  Saving model ...
Epoch 2441, train_loss: 833.4469474810096, val_loss: 717.7767253204187
Validation loss decreased (897.097512 --> 897.024050).  Saving model ...
Epoch 2442, train_loss: 831.5011586007993, val_loss: 701.1183408116632
Validation loss decreased (897.024050 --> 896.943826).  Saving model ...
Epoch 2443, train_loss: 828.3014156865975, val_loss: 703.3157306828543
Validation loss decreased (896.943826 --> 896.864568).  Saving model ...
Epoch 2444, train_loss: 836.6353485821306, val_loss: 696.977075947192
Validation loss decreased (896.864568 --> 896.782781).  Saving model ...
Epoch 2445, train_loss: 832.3090286228525, val_loss: 706.7226259523078
Validation loss decreased (896.782781 --> 896.705047).  Saving model ...
Epoch 2446, train_loss: 831.3884754637832, val_loss: 715.5034290318578
Validation loss decreased (896.705047 --> 896.630966).  Saving model ...
Epoch 2447, train_loss: 832.5423839519582, val_loss: 718.0569344745521
Validation loss decreased (896.630966 --> 896.557989).  Saving model ...
Epoch 2448, train_loss: 828.42840883874, val_loss: 727.0705202092618
Validation loss decreased (896.557989 --> 896.488754).  Saving model ...
Epoch 2449, train_loss: 835.8257176218507, val_loss: 707.618298567655
Validation loss decreased (896.488754 --> 896.411633).  Saving model ...
Epoch 2450, train_loss: 835.9467487706224, val_loss: 703.4892340366929
Validation loss decreased (896.411633 --> 896.332889).  Saving model ...
Epoch 2451, train_loss: 829.7330953816714, val_loss: 707.7786481768554
Validation loss decreased (896.332889 --> 896.255959).  Saving model ...
Epoch 2452, train_loss: 829.3615524851659, val_loss: 709.5669168735103
Validation loss decreased (896.255959 --> 896.179822).  Saving model ...
Epoch 2453, train_loss: 829.4499096512092, val_loss: 707.89644139068
Validation loss decreased (896.179822 --> 896.103065).  Saving model ...
Epoch 2454, train_loss: 831.2165423893496, val_loss: 691.4181566198778
Validation loss decreased (896.103065 --> 896.019657).  Saving model ...
Epoch 2455, train_loss: 826.5365721099314, val_loss: 705.2438837764661
Validation loss decreased (896.019657 --> 895.941948).  Saving model ...
Epoch 2456, train_loss: 831.3280827479681, val_loss: 715.9460297824056
Validation loss decreased (895.941948 --> 895.868659).  Saving model ...
Epoch 2457, train_loss: 830.1062968758058, val_loss: 722.3609608253615
Validation loss decreased (895.868659 --> 895.798042).  Saving model ...
Epoch 2458, train_loss: 825.8005564223247, val_loss: 692.923958511496
Validation loss decreased (895.798042 --> 895.715505).  Saving model ...
Epoch 2459, train_loss: 832.067559669878, val_loss: 728.3239178850145
Validation loss decreased (895.715505 --> 895.647432).  Saving model ...
Epoch 2460, train_loss: 833.3271583083782, val_loss: 704.8506705670885
Validation loss decreased (895.647432 --> 895.569873).  Saving model ...
Epoch 2461, train_loss: 826.2099911138322, val_loss: 709.9192728673751
Validation loss decreased (895.569873 --> 895.494436).  Saving model ...
Epoch 2462, train_loss: 829.7204140954943, val_loss: 694.5773272605849
Validation loss decreased (895.494436 --> 895.412828).  Saving model ...
Epoch 2463, train_loss: 826.9702562659292, val_loss: 696.6537674104948
Validation loss decreased (895.412828 --> 895.332130).  Saving model ...
Epoch 2464, train_loss: 832.2285106628299, val_loss: 692.1652045492333
Validation loss decreased (895.332130 --> 895.249676).  Saving model ...
Epoch 2465, train_loss: 830.7593157164955, val_loss: 708.2762250442638
Validation loss decreased (895.249676 --> 895.173825).  Saving model ...
Epoch 2466, train_loss: 830.5349382379054, val_loss: 709.8269740344971
Validation loss decreased (895.173825 --> 895.098664).  Saving model ...
Epoch 2467, train_loss: 833.7541221223177, val_loss: 699.039556262714
Validation loss decreased (895.098664 --> 895.019191).  Saving model ...
Epoch 2468, train_loss: 823.7794338912344, val_loss: 725.2521441089998
Validation loss decreased (895.019191 --> 894.950404).  Saving model ...
Epoch 2469, train_loss: 832.6566426161155, val_loss: 709.6095355409935
Validation loss decreased (894.950404 --> 894.875337).  Saving model ...
Epoch 2470, train_loss: 829.2091951030983, val_loss: 722.4206043633267
Validation loss decreased (894.875337 --> 894.805517).  Saving model ...
Epoch 2471, train_loss: 826.8400328481877, val_loss: 715.1166857070284
Validation loss decreased (894.805517 --> 894.732798).  Saving model ...
Epoch 2472, train_loss: 831.2199500454072, val_loss: 686.8473869146243
Validation loss decreased (894.732798 --> 894.648702).  Saving model ...
Epoch 2473, train_loss: 830.3706812449149, val_loss: 715.1111641334054
Validation loss decreased (894.648702 --> 894.576103).  Saving model ...
Epoch 2474, train_loss: 828.68129523882, val_loss: 708.2417758212376
Validation loss decreased (894.576103 --> 894.500786).  Saving model ...
Epoch 2475, train_loss: 828.9534966623594, val_loss: 701.8733770218493
Validation loss decreased (894.500786 --> 894.422957).  Saving model ...
Epoch 2476, train_loss: 827.9693554210374, val_loss: 698.5500494413906
Validation loss decreased (894.422957 --> 894.343848).  Saving model ...
Epoch 2477, train_loss: 827.5017048464069, val_loss: 710.1041137145183
Validation loss decreased (894.343848 --> 894.269468).  Saving model ...
Epoch 2478, train_loss: 838.9312695282309, val_loss: 694.7701360099517
Validation loss decreased (894.269468 --> 894.188960).  Saving model ...
Epoch 2479, train_loss: 831.9534769507545, val_loss: 702.0734053424994
Validation loss decreased (894.188960 --> 894.111463).  Saving model ...
Epoch 2480, train_loss: 819.7149799605562, val_loss: 706.625854230137
Validation loss decreased (894.111463 --> 894.035863).  Saving model ...
Epoch 2481, train_loss: 822.4845387159303, val_loss: 713.9900336760503
Validation loss decreased (894.035863 --> 893.963294).  Saving model ...
Epoch 2482, train_loss: 829.9336661824624, val_loss: 703.5423294539474
Validation loss decreased (893.963294 --> 893.886573).  Saving model ...
Epoch 2483, train_loss: 828.9801375836462, val_loss: 698.2283907087423
Validation loss decreased (893.886573 --> 893.807774).  Saving model ...
Epoch 2484, train_loss: 832.352760817257, val_loss: 711.3493737211271
Validation loss decreased (893.807774 --> 893.734320).  Saving model ...
Epoch 2485, train_loss: 820.0675428393988, val_loss: 700.3309162483724
Validation loss decreased (893.734320 --> 893.656492).  Saving model ...
Epoch 2486, train_loss: 829.4246181755822, val_loss: 718.1014363656221
Validation loss decreased (893.656492 --> 893.585874).  Saving model ...
Epoch 2487, train_loss: 828.3956506188418, val_loss: 713.6179897971839
Validation loss decreased (893.585874 --> 893.513511).  Saving model ...
Epoch 2488, train_loss: 827.543676594619, val_loss: 715.6961293073828
Validation loss decreased (893.513511 --> 893.442041).  Saving model ...
Epoch 2489, train_loss: 829.5036778101843, val_loss: 734.864298512152
Validation loss decreased (893.442041 --> 893.378330).  Saving model ...
Epoch 2490, train_loss: 837.7894308676179, val_loss: 694.0917717358802
Validation loss decreased (893.378330 --> 893.298295).  Saving model ...
Epoch 2491, train_loss: 826.2154964257252, val_loss: 704.1250360313057
Validation loss decreased (893.298295 --> 893.222352).  Saving model ...
Epoch 2492, train_loss: 831.5604734642544, val_loss: 710.6571555333999
Validation loss decreased (893.222352 --> 893.149092).  Saving model ...
Epoch 2493, train_loss: 826.1505029329721, val_loss: 712.0264204632573
Validation loss decreased (893.149092 --> 893.076439).  Saving model ...
Epoch 2494, train_loss: 823.0323468408693, val_loss: 708.3804826238089
Validation loss decreased (893.076439 --> 893.002383).  Saving model ...
Epoch 2495, train_loss: 822.6409757372232, val_loss: 685.9258471018519
Validation loss decreased (893.002383 --> 892.919386).  Saving model ...
Epoch 2496, train_loss: 829.748590859314, val_loss: 703.8996794900298
Validation loss decreased (892.919386 --> 892.843657).  Saving model ...
Epoch 2497, train_loss: 823.2632347078782, val_loss: 707.2052603300966
Validation loss decreased (892.843657 --> 892.769313).  Saving model ...
Epoch 2498, train_loss: 827.2832995290725, val_loss: 713.5471777093852
Validation loss decreased (892.769313 --> 892.697567).  Saving model ...
Epoch 2499, train_loss: 826.2086576131995, val_loss: 712.7764894643315
Validation loss decreased (892.697567 --> 892.625569).  Saving model ...
Epoch 2500, train_loss: 827.5348803226387, val_loss: 703.0067733917634
Validation loss decreased (892.625569 --> 892.549722).  Saving model ...
Epoch 2501, train_loss: 824.3245140311836, val_loss: 692.572037166909
Validation loss decreased (892.549722 --> 892.469763).  Saving model ...
Epoch 2502, train_loss: 824.1086568873068, val_loss: 696.1648101803661
Validation loss decreased (892.469763 --> 892.391303).  Saving model ...
Epoch 2503, train_loss: 824.3434114632486, val_loss: 698.9462734826848
Validation loss decreased (892.391303 --> 892.314018).  Saving model ...
Epoch 2504, train_loss: 820.1263616821776, val_loss: 715.3213081418917
Validation loss decreased (892.314018 --> 892.243334).  Saving model ...
Epoch 2505, train_loss: 831.3827848594904, val_loss: 685.1888713462376
Validation loss decreased (892.243334 --> 892.160678).  Saving model ...
Epoch 2506, train_loss: 821.5059949123421, val_loss: 683.2379289387776
Validation loss decreased (892.160678 --> 892.077309).  Saving model ...
Epoch 2507, train_loss: 821.4774699451898, val_loss: 716.550738055695
Validation loss decreased (892.077309 --> 892.007294).  Saving model ...
Epoch 2508, train_loss: 824.3573480377266, val_loss: 698.0967992616362
Validation loss decreased (892.007294 --> 891.929977).  Saving model ...
Epoch 2509, train_loss: 831.5037913035832, val_loss: 695.1825725112911
Validation loss decreased (891.929977 --> 891.851561).  Saving model ...
Epoch 2510, train_loss: 829.1065156051083, val_loss: 708.873343642619
Validation loss decreased (891.851561 --> 891.778661).  Saving model ...
Epoch 2511, train_loss: 818.9268094785305, val_loss: 719.5294776727425
Validation loss decreased (891.778661 --> 891.710063).  Saving model ...
Epoch 2512, train_loss: 823.3102918191535, val_loss: 709.4914776042434
Validation loss decreased (891.710063 --> 891.637524).  Saving model ...
Epoch 2513, train_loss: 818.2724763219386, val_loss: 696.9438362413093
Validation loss decreased (891.637524 --> 891.560049).  Saving model ...
Epoch 2514, train_loss: 818.5748234849399, val_loss: 710.426007260923
Validation loss decreased (891.560049 --> 891.487999).  Saving model ...
Epoch 2515, train_loss: 827.2706261776588, val_loss: 696.6207065772238
Validation loss decreased (891.487999 --> 891.410517).  Saving model ...
Epoch 2516, train_loss: 820.6922367450026, val_loss: 708.1553059789868
Validation loss decreased (891.410517 --> 891.337681).  Saving model ...
Epoch 2517, train_loss: 827.3862659882807, val_loss: 714.811453669016
Validation loss decreased (891.337681 --> 891.267548).  Saving model ...
Epoch 2518, train_loss: 825.447096030897, val_loss: 715.2003348004376
Validation loss decreased (891.267548 --> 891.197624).  Saving model ...
Epoch 2519, train_loss: 823.9155573673643, val_loss: 691.0566699288511
Validation loss decreased (891.197624 --> 891.118172).  Saving model ...
Epoch 2520, train_loss: 825.5199605093185, val_loss: 711.7835061938234
Validation loss decreased (891.118172 --> 891.047007).  Saving model ...
Epoch 2521, train_loss: 830.365161263997, val_loss: 681.3954710149986
Validation loss decreased (891.047007 --> 890.963845).  Saving model ...
Epoch 2522, train_loss: 824.6874400427429, val_loss: 698.0649470040313
Validation loss decreased (890.963845 --> 890.887359).  Saving model ...
Epoch 2523, train_loss: 817.6148178529877, val_loss: 705.8589186700297
Validation loss decreased (890.887359 --> 890.814022).  Saving model ...
Epoch 2524, train_loss: 820.5655370572441, val_loss: 708.4543523131916
Validation loss decreased (890.814022 --> 890.741772).  Saving model ...
Epoch 2525, train_loss: 823.5350990829038, val_loss: 708.5126648302543
Validation loss decreased (890.741772 --> 890.669602).  Saving model ...
Epoch 2526, train_loss: 816.2906929518906, val_loss: 701.8467002920532
Validation loss decreased (890.669602 --> 890.594850).  Saving model ...
Epoch 2527, train_loss: 829.4893184927087, val_loss: 714.4456230077368
Validation loss decreased (890.594850 --> 890.525143).  Saving model ...
Epoch 2528, train_loss: 825.6361278531265, val_loss: 719.2604531202163
Validation loss decreased (890.525143 --> 890.457396).  Saving model ...
Epoch 2529, train_loss: 823.4262410030645, val_loss: 710.330529580624
Validation loss decreased (890.457396 --> 890.386171).  Saving model ...
Epoch 2530, train_loss: 825.3905301511315, val_loss: 704.4794019429111
Validation loss decreased (890.386171 --> 890.312690).  Saving model ...
Epoch 2531, train_loss: 820.3710803294435, val_loss: 701.3290601631447
Validation loss decreased (890.312690 --> 890.238023).  Saving model ...
Epoch 2532, train_loss: 818.6577935887199, val_loss: 718.4924488447219
Validation loss decreased (890.238023 --> 890.170193).  Saving model ...
Epoch 2533, train_loss: 827.6846244554279, val_loss: 716.2416411101707
Validation loss decreased (890.170193 --> 890.101528).  Saving model ...
Epoch 2534, train_loss: 827.6146546609203, val_loss: 710.6789402570327
Validation loss decreased (890.101528 --> 890.030722).  Saving model ...
Epoch 2535, train_loss: 821.9883534908741, val_loss: 717.3480308623116
Validation loss decreased (890.030722 --> 889.962602).  Saving model ...
Epoch 2536, train_loss: 822.7746677198738, val_loss: 680.6487733182423
Validation loss decreased (889.962602 --> 889.880065).  Saving model ...
Epoch 2537, train_loss: 819.284174962368, val_loss: 719.6713345767726
Validation loss decreased (889.880065 --> 889.812975).  Saving model ...
Epoch 2538, train_loss: 822.4810180014213, val_loss: 699.6904497322331
Validation loss decreased (889.812975 --> 889.738064).  Saving model ...
Epoch 2539, train_loss: 825.0953238144984, val_loss: 705.6183503087033
Validation loss decreased (889.738064 --> 889.665548).  Saving model ...
Epoch 2540, train_loss: 815.8684928800043, val_loss: 721.630894416317
Validation loss decreased (889.665548 --> 889.599392).  Saving model ...
Epoch 2541, train_loss: 822.3863881483383, val_loss: 700.729909602172
Validation loss decreased (889.599392 --> 889.525064).  Saving model ...
Epoch 2542, train_loss: 815.7594483223478, val_loss: 724.1913179288971
Validation loss decreased (889.525064 --> 889.460023).  Saving model ...
Epoch 2543, train_loss: 829.0138745137514, val_loss: 696.3487194916717
Validation loss decreased (889.460023 --> 889.384084).  Saving model ...
Epoch 2544, train_loss: 820.6719866622791, val_loss: 707.7128330142522
Validation loss decreased (889.384084 --> 889.312673).  Saving model ...
Epoch 2545, train_loss: 824.7618462004777, val_loss: 683.0359901965439
Validation loss decreased (889.312673 --> 889.231621).  Saving model ...
Epoch 2546, train_loss: 821.0403259860146, val_loss: 689.1346048750924
Validation loss decreased (889.231621 --> 889.153028).  Saving model ...
Epoch 2547, train_loss: 822.7499191170151, val_loss: 714.8456032960062
Validation loss decreased (889.153028 --> 889.084592).  Saving model ...
Epoch 2548, train_loss: 828.5502676909924, val_loss: 688.8963899169147
Validation loss decreased (889.084592 --> 889.006025).  Saving model ...
Epoch 2549, train_loss: 818.1463932105995, val_loss: 711.579904720982
Validation loss decreased (889.006025 --> 888.936419).  Saving model ...
Epoch 2550, train_loss: 815.6332711164183, val_loss: 704.8575888070023
Validation loss decreased (888.936419 --> 888.864231).  Saving model ...
Epoch 2551, train_loss: 825.6577322743967, val_loss: 714.2509403553273
Validation loss decreased (888.864231 --> 888.795782).  Saving model ...
Epoch 2552, train_loss: 822.0440863293703, val_loss: 699.5727435346115
Validation loss decreased (888.795782 --> 888.721635).  Saving model ...
Epoch 2553, train_loss: 827.0358127106582, val_loss: 693.9932375143526
Validation loss decreased (888.721635 --> 888.645361).  Saving model ...
Epoch 2554, train_loss: 821.6300546816956, val_loss: 694.1715220016795
Validation loss decreased (888.645361 --> 888.569216).  Saving model ...
Epoch 2555, train_loss: 822.9934471581752, val_loss: 694.9233972349322
Validation loss decreased (888.569216 --> 888.493425).  Saving model ...
Epoch 2556, train_loss: 823.77704705092, val_loss: 681.2830157410659
Validation loss decreased (888.493425 --> 888.412357).  Saving model ...
Epoch 2557, train_loss: 813.7228994143197, val_loss: 714.9015752732753
Validation loss decreased (888.412357 --> 888.344500).  Saving model ...
Epoch 2558, train_loss: 815.7313713990034, val_loss: 716.8199896235819
Validation loss decreased (888.344500 --> 888.277446).  Saving model ...
Epoch 2559, train_loss: 822.1185328865968, val_loss: 742.4494755907081
Validation loss decreased (888.277446 --> 888.220459).  Saving model ...
Epoch 2560, train_loss: 826.640072025486, val_loss: 713.9891350040392
Validation loss decreased (888.220459 --> 888.152400).  Saving model ...
Epoch 2561, train_loss: 823.5931076195029, val_loss: 707.8306981533766
Validation loss decreased (888.152400 --> 888.081990).  Saving model ...
Epoch 2562, train_loss: 821.1438870321994, val_loss: 714.5046760560739
Validation loss decreased (888.081990 --> 888.014239).  Saving model ...
Epoch 2563, train_loss: 822.5392265938624, val_loss: 707.145010581171
Validation loss decreased (888.014239 --> 887.943670).  Saving model ...
Epoch 2564, train_loss: 817.3547358862712, val_loss: 745.8373848022798
Validation loss decreased (887.943670 --> 887.888246).  Saving model ...
Epoch 2565, train_loss: 824.151541403978, val_loss: 709.4157627449985
Validation loss decreased (887.888246 --> 887.818666).  Saving model ...
Epoch 2566, train_loss: 816.4050188004777, val_loss: 746.1938811776704
Validation loss decreased (887.818666 --> 887.763473).  Saving model ...
Epoch 2567, train_loss: 830.0855895417853, val_loss: 691.479652808386
Validation loss decreased (887.763473 --> 887.687009).  Saving model ...
Epoch 2568, train_loss: 814.7910001544249, val_loss: 697.5351997983347
Validation loss decreased (887.687009 --> 887.612962).  Saving model ...
Epoch 2569, train_loss: 815.5553593318683, val_loss: 716.0882955936813
Validation loss decreased (887.612962 --> 887.546195).  Saving model ...
Epoch 2570, train_loss: 818.8599949663806, val_loss: 703.3927273095869
Validation loss decreased (887.546195 --> 887.474540).  Saving model ...
Epoch 2571, train_loss: 815.8316250373962, val_loss: 700.8126419897322
Validation loss decreased (887.474540 --> 887.401937).  Saving model ...
Epoch 2572, train_loss: 818.7641133575675, val_loss: 713.2713571707077
Validation loss decreased (887.401937 --> 887.334235).  Saving model ...
Epoch 2573, train_loss: 816.2746702053204, val_loss: 735.8983178049216
Validation loss decreased (887.334235 --> 887.275379).  Saving model ...
Epoch 2574, train_loss: 818.2568635484691, val_loss: 698.909481668616
Validation loss decreased (887.275379 --> 887.202199).  Saving model ...
Epoch 2575, train_loss: 816.7308262657431, val_loss: 698.4003659025498
Validation loss decreased (887.202199 --> 887.128878).  Saving model ...
Epoch 2576, train_loss: 813.3111913785913, val_loss: 718.6130324540867
Validation loss decreased (887.128878 --> 887.063460).  Saving model ...
Epoch 2577, train_loss: 814.5172831590562, val_loss: 718.9097060070768
Validation loss decreased (887.063460 --> 886.998208).  Saving model ...
Epoch 2578, train_loss: 819.9672155310174, val_loss: 700.144178389057
Validation loss decreased (886.998208 --> 886.925728).  Saving model ...
Epoch 2579, train_loss: 819.1302040642479, val_loss: 702.7463487063845
Validation loss decreased (886.925728 --> 886.854313).  Saving model ...
Epoch 2580, train_loss: 827.2654486170995, val_loss: 698.2225153668613
Validation loss decreased (886.854313 --> 886.781200).  Saving model ...
Epoch 2581, train_loss: 821.9789819980587, val_loss: 694.3454134769463
Validation loss decreased (886.781200 --> 886.706641).  Saving model ...
Epoch 2582, train_loss: 811.8520922378605, val_loss: 719.4187346581839
Validation loss decreased (886.706641 --> 886.641851).  Saving model ...
Epoch 2583, train_loss: 812.5849527238113, val_loss: 699.4732134838238
Validation loss decreased (886.641851 --> 886.569390).  Saving model ...
Epoch 2584, train_loss: 815.7598168965329, val_loss: 732.7622733930085
Validation loss decreased (886.569390 --> 886.509867).  Saving model ...
Epoch 2585, train_loss: 818.0720734086534, val_loss: 716.0463180675994
Validation loss decreased (886.509867 --> 886.443923).  Saving model ...
Epoch 2586, train_loss: 816.1184989831206, val_loss: 739.9911823577462
Validation loss decreased (886.443923 --> 886.387290).  Saving model ...
Epoch 2587, train_loss: 823.3976175927872, val_loss: 720.2757709085168
Validation loss decreased (886.387290 --> 886.323080).  Saving model ...
Epoch 2588, train_loss: 808.809393412719, val_loss: 729.5445174167334
Validation loss decreased (886.323080 --> 886.262501).  Saving model ...
Epoch 2589, train_loss: 819.7548994181291, val_loss: 699.8223940681419
Validation loss decreased (886.262501 --> 886.190489).  Saving model ...
Epoch 2590, train_loss: 820.2259771449386, val_loss: 700.6532939469704
Validation loss decreased (886.190489 --> 886.118853).  Saving model ...
Epoch 2591, train_loss: 809.6354210143024, val_loss: 704.2366523707797
Validation loss decreased (886.118853 --> 886.048655).  Saving model ...
Epoch 2592, train_loss: 815.0744322914827, val_loss: 694.7807134872455
Validation loss decreased (886.048655 --> 885.974864).  Saving model ...
Epoch 2593, train_loss: 816.3407559757404, val_loss: 707.0682958286781
Validation loss decreased (885.974864 --> 885.905868).  Saving model ...
Epoch 2594, train_loss: 820.3662696559679, val_loss: 689.6217815280735
Validation loss decreased (885.905868 --> 885.830199).  Saving model ...
Epoch 2595, train_loss: 816.5452537288163, val_loss: 724.519111066869
Validation loss decreased (885.830199 --> 885.768037).  Saving model ...
Epoch 2596, train_loss: 816.9674466008747, val_loss: 711.5013412195996
Validation loss decreased (885.768037 --> 885.700908).  Saving model ...
Epoch 2597, train_loss: 811.2261897190359, val_loss: 701.5400237229468
Validation loss decreased (885.700908 --> 885.629995).  Saving model ...
Epoch 2598, train_loss: 813.5755116077873, val_loss: 683.1786517378249
Validation loss decreased (885.629995 --> 885.552069).  Saving model ...
Epoch 2599, train_loss: 815.4590748079579, val_loss: 702.771779528459
Validation loss decreased (885.552069 --> 885.481742).  Saving model ...
Epoch 2600, train_loss: 812.9556441794095, val_loss: 686.4850262895008
Validation loss decreased (885.481742 --> 885.405205).  Saving model ...
Epoch 2601, train_loss: 817.8075369285419, val_loss: 711.0370783021716
Validation loss decreased (885.405205 --> 885.338166).  Saving model ...
Epoch 2602, train_loss: 816.4420220324463, val_loss: 687.8022429427286
Validation loss decreased (885.338166 --> 885.262249).  Saving model ...
Epoch 2603, train_loss: 817.7572715474925, val_loss: 708.4808557456844
Validation loss decreased (885.262249 --> 885.194334).  Saving model ...
Epoch 2604, train_loss: 819.0928845929642, val_loss: 697.0009834190431
Validation loss decreased (885.194334 --> 885.122064).  Saving model ...
Epoch 2605, train_loss: 808.3867696240894, val_loss: 724.493235615205
Validation loss decreased (885.122064 --> 885.060402).  Saving model ...
Epoch 2606, train_loss: 814.5169627173252, val_loss: 717.9536472159734
Validation loss decreased (885.060402 --> 884.996278).  Saving model ...
Epoch 2607, train_loss: 817.7971374991035, val_loss: 703.1626497940115
Validation loss decreased (884.996278 --> 884.926530).  Saving model ...
Epoch 2608, train_loss: 812.8345975166598, val_loss: 718.3387840464933
Validation loss decreased (884.926530 --> 884.862654).  Saving model ...
Epoch 2609, train_loss: 814.3543719852653, val_loss: 713.0112473856411
Validation loss decreased (884.862654 --> 884.796785).  Saving model ...
Epoch 2610, train_loss: 815.1669454922741, val_loss: 707.9264368216528
Validation loss decreased (884.796785 --> 884.729019).  Saving model ...
Epoch 2611, train_loss: 808.803208476068, val_loss: 720.5488075082832
Validation loss decreased (884.729019 --> 884.666139).  Saving model ...
Epoch 2612, train_loss: 821.2259341206998, val_loss: 706.9985818796249
Validation loss decreased (884.666139 --> 884.598119).  Saving model ...
Epoch 2613, train_loss: 812.4358835001125, val_loss: 724.7598177465908
Validation loss decreased (884.598119 --> 884.536949).  Saving model ...
Epoch 2614, train_loss: 818.8965803863694, val_loss: 709.467655603069
Validation loss decreased (884.536949 --> 884.469975).  Saving model ...
Epoch 2615, train_loss: 816.3493764595022, val_loss: 701.7983061226764
Validation loss decreased (884.469975 --> 884.400120).  Saving model ...
Epoch 2616, train_loss: 820.7408689834367, val_loss: 687.532518832717
Validation loss decreased (884.400120 --> 884.324864).  Saving model ...
Epoch 2617, train_loss: 807.4794705829396, val_loss: 694.9582840739799
Validation loss decreased (884.324864 --> 884.252504).  Saving model ...
Epoch 2618, train_loss: 814.6383634427474, val_loss: 688.6188821916229
Validation loss decreased (884.252504 --> 884.177778).  Saving model ...
Epoch 2619, train_loss: 810.0692611061291, val_loss: 691.3814535431512
Validation loss decreased (884.177778 --> 884.104163).  Saving model ...
Epoch 2620, train_loss: 809.490977702455, val_loss: 715.8987290419915
Validation loss decreased (884.104163 --> 884.039963).  Saving model ...
Epoch 2621, train_loss: 814.182430119942, val_loss: 709.7679871039921
Validation loss decreased (884.039963 --> 883.973472).  Saving model ...
Epoch 2622, train_loss: 813.8239501747676, val_loss: 691.9080812592529
Validation loss decreased (883.973472 --> 883.900221).  Saving model ...
Epoch 2623, train_loss: 816.0986584768192, val_loss: 716.5823338858951
Validation loss decreased (883.900221 --> 883.836432).  Saving model ...
Epoch 2624, train_loss: 820.377053077313, val_loss: 709.1660732634864
Validation loss decreased (883.836432 --> 883.769866).  Saving model ...
Epoch 2625, train_loss: 816.122810169101, val_loss: 711.6417203249204
Validation loss decreased (883.769866 --> 883.704293).  Saving model ...
Epoch 2626, train_loss: 812.2307526248167, val_loss: 707.129370526594
Validation loss decreased (883.704293 --> 883.637052).  Saving model ...
Epoch 2627, train_loss: 812.7987808466675, val_loss: 691.0975932341485
Validation loss decreased (883.637052 --> 883.563759).  Saving model ...
Epoch 2628, train_loss: 810.6888084938099, val_loss: 681.5864651367623
Validation loss decreased (883.563759 --> 883.486903).  Saving model ...
Epoch 2629, train_loss: 807.7360750014932, val_loss: 714.2841763052678
Validation loss decreased (883.486903 --> 883.422543).  Saving model ...
Epoch 2630, train_loss: 807.8629263695786, val_loss: 714.628068518683
Validation loss decreased (883.422543 --> 883.358363).  Saving model ...
Epoch 2631, train_loss: 813.0907556068069, val_loss: 714.6503755012267
Validation loss decreased (883.358363 --> 883.294240).  Saving model ...
Epoch 2632, train_loss: 817.3495525220553, val_loss: 695.5316563846337
Validation loss decreased (883.294240 --> 883.222901).  Saving model ...
Epoch 2633, train_loss: 814.1185014530492, val_loss: 684.5429970916225
Validation loss decreased (883.222901 --> 883.147444).  Saving model ...
Epoch 2634, train_loss: 811.4064836461739, val_loss: 693.6276607941146
Validation loss decreased (883.147444 --> 883.075493).  Saving model ...
Epoch 2635, train_loss: 810.0729330371032, val_loss: 720.8374188024469
Validation loss decreased (883.075493 --> 883.013922).  Saving model ...
Epoch 2636, train_loss: 816.3191618564218, val_loss: 696.4795609839207
Validation loss decreased (883.013922 --> 882.943158).  Saving model ...
Epoch 2637, train_loss: 809.5862818157029, val_loss: 701.4864555713426
Validation loss decreased (882.943158 --> 882.874346).  Saving model ...
Epoch 2638, train_loss: 817.612554981608, val_loss: 701.5270614787055
Validation loss decreased (882.874346 --> 882.805602).  Saving model ...
Epoch 2639, train_loss: 809.9355515881253, val_loss: 679.0639815323553
Validation loss decreased (882.805602 --> 882.728398).  Saving model ...
Epoch 2640, train_loss: 813.1666226552052, val_loss: 691.9252209345835
Validation loss decreased (882.728398 --> 882.656124).  Saving model ...
Epoch 2641, train_loss: 815.7988272645478, val_loss: 710.4994701853838
Validation loss decreased (882.656124 --> 882.590938).  Saving model ...
Epoch 2642, train_loss: 806.0671172084412, val_loss: 703.9939863490398
Validation loss decreased (882.590938 --> 882.523339).  Saving model ...
Epoch 2643, train_loss: 808.9213854220307, val_loss: 716.5618666597542
Validation loss decreased (882.523339 --> 882.460546).  Saving model ...
Epoch 2644, train_loss: 819.9525571515325, val_loss: 678.7837346631511
Validation loss decreased (882.460546 --> 882.383512).  Saving model ...
Epoch 2645, train_loss: 806.9629055310622, val_loss: 708.5518648886791
Validation loss decreased (882.383512 --> 882.317791).  Saving model ...
Epoch 2646, train_loss: 811.659619811411, val_loss: 692.2502578648154
Validation loss decreased (882.317791 --> 882.245959).  Saving model ...
Epoch 2647, train_loss: 809.036892634086, val_loss: 714.7617323333799
Validation loss decreased (882.245959 --> 882.182686).  Saving model ...
Epoch 2648, train_loss: 805.8294439554687, val_loss: 707.2152377231474
Validation loss decreased (882.182686 --> 882.116611).  Saving model ...
Epoch 2649, train_loss: 813.6992468494167, val_loss: 694.6387078206297
Validation loss decreased (882.116611 --> 882.045838).  Saving model ...
Epoch 2650, train_loss: 807.0217785041244, val_loss: 684.3061288307002
Validation loss decreased (882.045838 --> 881.971219).  Saving model ...
Epoch 2651, train_loss: 815.996005685868, val_loss: 686.8945241584053
Validation loss decreased (881.971219 --> 881.897633).  Saving model ...
Epoch 2652, train_loss: 808.9105356469196, val_loss: 705.9422921169247
Validation loss decreased (881.897633 --> 881.831285).  Saving model ...
Epoch 2653, train_loss: 810.8947802797762, val_loss: 717.1858345292235
Validation loss decreased (881.831285 --> 881.769224).  Saving model ...
Epoch 2654, train_loss: 807.6545769363048, val_loss: 694.268327955383
Validation loss decreased (881.769224 --> 881.698576).  Saving model ...
Epoch 2655, train_loss: 807.8203984875787, val_loss: 697.2973616513281
Validation loss decreased (881.698576 --> 881.629122).  Saving model ...
Epoch 2656, train_loss: 802.9661656416426, val_loss: 721.0966359103719
Validation loss decreased (881.629122 --> 881.568680).  Saving model ...
Epoch 2657, train_loss: 808.6312682138538, val_loss: 707.2353782368369
Validation loss decreased (881.568680 --> 881.503067).  Saving model ...
Epoch 2658, train_loss: 809.965710641029, val_loss: 706.5635701167694
Validation loss decreased (881.503067 --> 881.437251).  Saving model ...
Epoch 2659, train_loss: 811.587310209359, val_loss: 694.9512568765439
Validation loss decreased (881.437251 --> 881.367117).  Saving model ...
Epoch 2660, train_loss: 819.295243170621, val_loss: 705.8083334951049
Validation loss decreased (881.367117 --> 881.301118).  Saving model ...
Epoch 2661, train_loss: 817.3897929355069, val_loss: 717.5395102499814
Validation loss decreased (881.301118 --> 881.239576).  Saving model ...
Epoch 2662, train_loss: 807.3264034994069, val_loss: 713.0276352911084
Validation loss decreased (881.239576 --> 881.176386).  Saving model ...
Epoch 2663, train_loss: 809.701631384396, val_loss: 702.6957363286507
Validation loss decreased (881.176386 --> 881.109364).  Saving model ...
Epoch 2664, train_loss: 809.8393523285635, val_loss: 694.5213885162166
Validation loss decreased (881.109364 --> 881.039323).  Saving model ...
Epoch 2665, train_loss: 813.450028200395, val_loss: 691.8165428815065
Validation loss decreased (881.039323 --> 880.968321).  Saving model ...
Epoch 2666, train_loss: 803.4546961516378, val_loss: 703.9910268967351
Validation loss decreased (880.968321 --> 880.901937).  Saving model ...
Epoch 2667, train_loss: 807.8908372210983, val_loss: 697.0740867199391
Validation loss decreased (880.901937 --> 880.833011).  Saving model ...
Epoch 2668, train_loss: 813.814698836607, val_loss: 707.5718113670858
Validation loss decreased (880.833011 --> 880.768070).  Saving model ...
Epoch 2669, train_loss: 808.5096190124365, val_loss: 707.47838891302
Validation loss decreased (880.768070 --> 880.703143).  Saving model ...
Epoch 2670, train_loss: 809.252427648258, val_loss: 697.8642532922826
Validation loss decreased (880.703143 --> 880.634664).  Saving model ...
Epoch 2671, train_loss: 805.4136758091515, val_loss: 709.3586452023411
Validation loss decreased (880.634664 --> 880.570540).  Saving model ...
Epoch 2672, train_loss: 805.9376244257003, val_loss: 710.363322692679
Validation loss decreased (880.570540 --> 880.506840).  Saving model ...
Epoch 2673, train_loss: 807.9390481445711, val_loss: 690.1708361180293
Validation loss decreased (880.506840 --> 880.435633).  Saving model ...
Epoch 2674, train_loss: 808.6056619238449, val_loss: 695.9004743893721
Validation loss decreased (880.435633 --> 880.366622).  Saving model ...
Epoch 2675, train_loss: 809.9398837145527, val_loss: 720.7270963859228
Validation loss decreased (880.366622 --> 880.306944).  Saving model ...
Epoch 2676, train_loss: 802.4485610683014, val_loss: 685.9757917949008
Validation loss decreased (880.306944 --> 880.234324).  Saving model ...
Epoch 2677, train_loss: 806.8801591447344, val_loss: 699.4235691744201
Validation loss decreased (880.234324 --> 880.166781).  Saving model ...
Epoch 2678, train_loss: 806.3943677376018, val_loss: 695.6874771150727
Validation loss decreased (880.166781 --> 880.097894).  Saving model ...
Epoch 2679, train_loss: 805.9331682990793, val_loss: 713.6555142098555
Validation loss decreased (880.097894 --> 880.035766).  Saving model ...
Epoch 2680, train_loss: 806.8093673337963, val_loss: 701.6477013130433
Validation loss decreased (880.035766 --> 879.969203).  Saving model ...
Epoch 2681, train_loss: 812.619499568181, val_loss: 685.4930885138338
Validation loss decreased (879.969203 --> 879.896664).  Saving model ...
Epoch 2682, train_loss: 802.3081198347608, val_loss: 713.3495829584423
Validation loss decreased (879.896664 --> 879.834566).  Saving model ...
Epoch 2683, train_loss: 807.9545766432601, val_loss: 696.5174105463539
Validation loss decreased (879.834566 --> 879.766241).  Saving model ...
Epoch 2684, train_loss: 809.1152319006187, val_loss: 695.5790368468124
Validation loss decreased (879.766241 --> 879.697617).  Saving model ...
Epoch 2685, train_loss: 801.6170144913494, val_loss: 703.91140236423
Validation loss decreased (879.697617 --> 879.632147).  Saving model ...
Epoch 2686, train_loss: 822.304361534913, val_loss: 682.0925419264482
Validation loss decreased (879.632147 --> 879.558603).  Saving model ...
Epoch 2687, train_loss: 799.445480192733, val_loss: 677.5615569836235
Validation loss decreased (879.558603 --> 879.483427).  Saving model ...
Epoch 2688, train_loss: 795.3287661909941, val_loss: 714.269827217493
Validation loss decreased (879.483427 --> 879.421964).  Saving model ...
Epoch 2689, train_loss: 811.122651471992, val_loss: 704.8934644415755
Validation loss decreased (879.421964 --> 879.357059).  Saving model ...
Epoch 2690, train_loss: 807.0112587867909, val_loss: 703.4620709754694
Validation loss decreased (879.357059 --> 879.291671).  Saving model ...
Epoch 2691, train_loss: 810.9672145797774, val_loss: 691.954016487996
Validation loss decreased (879.291671 --> 879.222054).  Saving model ...
Epoch 2692, train_loss: 805.402081478448, val_loss: 701.4226064731238
Validation loss decreased (879.222054 --> 879.156007).  Saving model ...
Epoch 2693, train_loss: 812.2636616738089, val_loss: 688.8139317751705
Validation loss decreased (879.156007 --> 879.085327).  Saving model ...
Epoch 2694, train_loss: 810.8313862173161, val_loss: 678.9900482771908
Validation loss decreased (879.085327 --> 879.011052).  Saving model ...
Epoch 2695, train_loss: 804.167649580635, val_loss: 707.4460852309843
Validation loss decreased (879.011052 --> 878.947392).  Saving model ...
Epoch 2696, train_loss: 805.5046306243178, val_loss: 694.0860739007704
Validation loss decreased (878.947392 --> 878.878823).  Saving model ...
Epoch 2697, train_loss: 800.0627441647358, val_loss: 696.4782980023823
Validation loss decreased (878.878823 --> 878.811192).  Saving model ...
Epoch 2698, train_loss: 801.79581300593, val_loss: 691.1535541677366
Validation loss decreased (878.811192 --> 878.741638).  Saving model ...
Epoch 2699, train_loss: 804.1370245260351, val_loss: 690.9100414139475
Validation loss decreased (878.741638 --> 878.672045).  Saving model ...
Epoch 2700, train_loss: 801.730711600243, val_loss: 696.5169844227368
Validation loss decreased (878.672045 --> 878.604580).  Saving model ...
Epoch 2701, train_loss: 808.8812092020911, val_loss: 688.1242021763218
Validation loss decreased (878.604580 --> 878.534058).  Saving model ...
Epoch 2702, train_loss: 798.5050914350415, val_loss: 683.3585845123289
Validation loss decreased (878.534058 --> 878.461824).  Saving model ...
Epoch 2703, train_loss: 803.5928334592563, val_loss: 712.6738815420205
Validation loss decreased (878.461824 --> 878.400489).  Saving model ...
Epoch 2704, train_loss: 803.1935289894938, val_loss: 693.5696389189696
Validation loss decreased (878.400489 --> 878.332135).  Saving model ...
Epoch 2705, train_loss: 811.2620392965621, val_loss: 679.2322586023479
Validation loss decreased (878.332135 --> 878.258530).  Saving model ...
Epoch 2706, train_loss: 801.3423529341533, val_loss: 714.7748620678652
Validation loss decreased (878.258530 --> 878.198115).  Saving model ...
Epoch 2707, train_loss: 808.1334029602622, val_loss: 706.2310436954655
Validation loss decreased (878.198115 --> 878.134588).  Saving model ...
Epoch 2708, train_loss: 803.4214455008432, val_loss: 693.3640164793201
Validation loss decreased (878.134588 --> 878.066357).  Saving model ...
Epoch 2709, train_loss: 801.0016414626833, val_loss: 713.9678627253575
Validation loss decreased (878.066357 --> 878.005782).  Saving model ...
Epoch 2710, train_loss: 804.2546541232083, val_loss: 703.2800904592541
Validation loss decreased (878.005782 --> 877.941307).  Saving model ...
Epoch 2711, train_loss: 802.2923603720774, val_loss: 688.3686209671588
Validation loss decreased (877.941307 --> 877.871380).  Saving model ...
Epoch 2712, train_loss: 800.8860848012428, val_loss: 692.6338561000208
Validation loss decreased (877.871380 --> 877.803077).  Saving model ...
Epoch 2713, train_loss: 803.0061864703556, val_loss: 689.6948170858624
Validation loss decreased (877.803077 --> 877.733741).  Saving model ...
Epoch 2714, train_loss: 803.8937645670529, val_loss: 698.1211536572488
Validation loss decreased (877.733741 --> 877.667561).  Saving model ...
Epoch 2715, train_loss: 805.7776357607802, val_loss: 687.0399748706487
Validation loss decreased (877.667561 --> 877.597348).  Saving model ...
Epoch 2716, train_loss: 804.3024084877588, val_loss: 684.5035547082515
Validation loss decreased (877.597348 --> 877.526253).  Saving model ...
Epoch 2717, train_loss: 791.8035123494217, val_loss: 697.8429019207647
Validation loss decreased (877.526253 --> 877.460120).  Saving model ...
Epoch 2718, train_loss: 798.8308163484287, val_loss: 731.3497755817904
Validation loss decreased (877.460120 --> 877.406364).  Saving model ...
Epoch 2719, train_loss: 803.4139489689632, val_loss: 706.4679913872814
Validation loss decreased (877.406364 --> 877.343496).  Saving model ...
Epoch 2720, train_loss: 816.8946583340532, val_loss: 713.4807096867652
Validation loss decreased (877.343496 --> 877.283252).  Saving model ...
Epoch 2721, train_loss: 803.7203497362324, val_loss: 709.000239168483
Validation loss decreased (877.283252 --> 877.221406).  Saving model ...
Epoch 2722, train_loss: 799.9160412838366, val_loss: 695.2189700625563
Validation loss decreased (877.221406 --> 877.154543).  Saving model ...
Epoch 2723, train_loss: 801.6208767149957, val_loss: 694.6274863464415
Validation loss decreased (877.154543 --> 877.087511).  Saving model ...
Epoch 2724, train_loss: 799.9749197618381, val_loss: 697.2038740397937
Validation loss decreased (877.087511 --> 877.021474).  Saving model ...
Epoch 2725, train_loss: 804.4146553635285, val_loss: 699.1117005293901
Validation loss decreased (877.021474 --> 876.956186).  Saving model ...
Epoch 2726, train_loss: 800.7700041486811, val_loss: 707.7395423076222
Validation loss decreased (876.956186 --> 876.894111).  Saving model ...
Epoch 2727, train_loss: 793.475110054013, val_loss: 715.0586480392241
Validation loss decreased (876.894111 --> 876.834766).  Saving model ...
Epoch 2728, train_loss: 802.0830507704305, val_loss: 717.345328326424
Validation loss decreased (876.834766 --> 876.776302).  Saving model ...
Epoch 2729, train_loss: 796.5503042475455, val_loss: 727.5949106941622
Validation loss decreased (876.776302 --> 876.721637).  Saving model ...
Epoch 2730, train_loss: 802.2879867996063, val_loss: 700.1177228344594
Validation loss decreased (876.721637 --> 876.656947).  Saving model ...
Epoch 2731, train_loss: 798.6151011331324, val_loss: 687.2103123395314
Validation loss decreased (876.656947 --> 876.587578).  Saving model ...
Epoch 2732, train_loss: 798.4831205504281, val_loss: 719.3491989409484
Validation loss decreased (876.587578 --> 876.530023).  Saving model ...
Epoch 2733, train_loss: 800.38165095709, val_loss: 711.6362675371215
Validation loss decreased (876.530023 --> 876.469689).  Saving model ...
Epoch 2734, train_loss: 806.4884137456278, val_loss: 712.0905269627441
Validation loss decreased (876.469689 --> 876.409565).  Saving model ...
Epoch 2735, train_loss: 801.6120757885104, val_loss: 701.0500067842562
Validation loss decreased (876.409565 --> 876.345448).  Saving model ...
Epoch 2736, train_loss: 798.3173172521277, val_loss: 691.7778853181118
Validation loss decreased (876.345448 --> 876.277989).  Saving model ...
Epoch 2737, train_loss: 796.551405459093, val_loss: 699.2854635718577
Validation loss decreased (876.277989 --> 876.213323).  Saving model ...
Epoch 2738, train_loss: 802.6968420208822, val_loss: 708.3750946516462
Validation loss decreased (876.213323 --> 876.152023).  Saving model ...
Epoch 2739, train_loss: 796.9171792731107, val_loss: 704.3824544335075
Validation loss decreased (876.152023 --> 876.089310).  Saving model ...
Epoch 2740, train_loss: 806.7242994709333, val_loss: 705.5428218575981
Validation loss decreased (876.089310 --> 876.027067).  Saving model ...
Epoch 2741, train_loss: 795.7790126299714, val_loss: 711.9907342756459
Validation loss decreased (876.027067 --> 875.967222).  Saving model ...
Epoch 2742, train_loss: 802.5384551216881, val_loss: 688.6609409353691
Validation loss decreased (875.967222 --> 875.898912).  Saving model ...
Epoch 2743, train_loss: 797.0156365014558, val_loss: 703.9965196873527
Validation loss decreased (875.898912 --> 875.836242).  Saving model ...
Epoch 2744, train_loss: 801.7213996137413, val_loss: 693.6338224192573
Validation loss decreased (875.836242 --> 875.769842).  Saving model ...
Epoch 2745, train_loss: 801.0379967238057, val_loss: 701.6498468773788
Validation loss decreased (875.769842 --> 875.706410).  Saving model ...
Epoch 2746, train_loss: 798.9467994115842, val_loss: 709.6576052633371
Validation loss decreased (875.706410 --> 875.645941).  Saving model ...
Epoch 2747, train_loss: 806.61554465269, val_loss: 688.7228472231055
Validation loss decreased (875.645941 --> 875.577895).  Saving model ...
Epoch 2748, train_loss: 797.5445543912475, val_loss: 697.3527071856239
Validation loss decreased (875.577895 --> 875.513038).  Saving model ...
Epoch 2749, train_loss: 797.8726038222702, val_loss: 702.325190900509
Validation loss decreased (875.513038 --> 875.450038).  Saving model ...
Epoch 2750, train_loss: 800.4184387980956, val_loss: 688.7895581286044
Validation loss decreased (875.450038 --> 875.382161).  Saving model ...
Epoch 2751, train_loss: 795.989920470125, val_loss: 695.5254746589618
Validation loss decreased (875.382161 --> 875.316783).  Saving model ...
Epoch 2752, train_loss: 796.4037246741112, val_loss: 710.1803955659934
Validation loss decreased (875.316783 --> 875.256777).  Saving model ...
Epoch 2753, train_loss: 804.7373957507423, val_loss: 730.2278824103872
Validation loss decreased (875.256777 --> 875.204097).  Saving model ...
Epoch 2754, train_loss: 801.525824092562, val_loss: 717.8893571034406
Validation loss decreased (875.204097 --> 875.146974).  Saving model ...
Epoch 2755, train_loss: 806.026357502726, val_loss: 701.8814358078995
Validation loss decreased (875.146974 --> 875.084083).  Saving model ...
Epoch 2756, train_loss: 800.399913902577, val_loss: 690.4354178752615
Validation loss decreased (875.084083 --> 875.017084).  Saving model ...
Epoch 2757, train_loss: 789.1441680604573, val_loss: 702.4818310311329
Validation loss decreased (875.017084 --> 874.954503).  Saving model ...
Epoch 2758, train_loss: 802.8066756325795, val_loss: 693.2620223485542
Validation loss decreased (874.954503 --> 874.888625).  Saving model ...
Epoch 2759, train_loss: 795.5028786872365, val_loss: 702.7289013046692
Validation loss decreased (874.888625 --> 874.826226).  Saving model ...
Epoch 2760, train_loss: 792.6024894243477, val_loss: 739.3628126099817
Validation loss decreased (874.826226 --> 874.777145).  Saving model ...
Epoch 2761, train_loss: 804.7413579810352, val_loss: 703.3824901407738
Validation loss decreased (874.777145 --> 874.715068).  Saving model ...
Epoch 2762, train_loss: 801.4822374683972, val_loss: 677.4344019677686
Validation loss decreased (874.715068 --> 874.643641).  Saving model ...
Epoch 2763, train_loss: 799.5413945782128, val_loss: 718.2150417833418
Validation loss decreased (874.643641 --> 874.587025).  Saving model ...
Epoch 2764, train_loss: 802.4081236328464, val_loss: 695.6994277260261
Validation loss decreased (874.587025 --> 874.522305).  Saving model ...
Epoch 2765, train_loss: 799.9023320968683, val_loss: 697.0994871850148
Validation loss decreased (874.522305 --> 874.458138).  Saving model ...
Epoch 2766, train_loss: 798.1222843593913, val_loss: 714.1556759692124
Validation loss decreased (874.458138 --> 874.400183).  Saving model ...
Epoch 2767, train_loss: 796.8722533504653, val_loss: 709.4889906571974
Validation loss decreased (874.400183 --> 874.340584).  Saving model ...
Epoch 2768, train_loss: 802.6409822486004, val_loss: 695.1040277727448
Validation loss decreased (874.340584 --> 874.275831).  Saving model ...
Epoch 2769, train_loss: 796.6454827729021, val_loss: 704.8123954374263
Validation loss decreased (874.275831 --> 874.214630).  Saving model ...
Epoch 2770, train_loss: 803.009695300807, val_loss: 684.9839244236
Validation loss decreased (874.214630 --> 874.146316).  Saving model ...
Epoch 2771, train_loss: 794.3778431095087, val_loss: 701.6697810141137
Validation loss decreased (874.146316 --> 874.084073).  Saving model ...
Epoch 2772, train_loss: 794.8245805314855, val_loss: 683.5994575859995
Validation loss decreased (874.084073 --> 874.015355).  Saving model ...
Epoch 2773, train_loss: 796.0085637947842, val_loss: 697.3364441904649
Validation loss decreased (874.015355 --> 873.951641).  Saving model ...
Epoch 2774, train_loss: 795.4937549686825, val_loss: 707.7548329920683
Validation loss decreased (873.951641 --> 873.891729).  Saving model ...
Epoch 2775, train_loss: 804.6084760016381, val_loss: 710.1638323372825
Validation loss decreased (873.891729 --> 873.832728).  Saving model ...
Epoch 2776, train_loss: 796.7343729880465, val_loss: 708.5053679246486
Validation loss decreased (873.832728 --> 873.773172).  Saving model ...
Epoch 2777, train_loss: 792.77390342892, val_loss: 703.0372841965494
Validation loss decreased (873.773172 --> 873.711690).  Saving model ...
Epoch 2778, train_loss: 804.3763456517572, val_loss: 707.5958833391692
Validation loss decreased (873.711690 --> 873.651893).  Saving model ...
Epoch 2779, train_loss: 801.1759476286242, val_loss: 717.2205220112537
Validation loss decreased (873.651893 --> 873.595602).  Saving model ...
Epoch 2780, train_loss: 796.7532540336837, val_loss: 703.2921542524081
Validation loss decreased (873.595602 --> 873.534342).  Saving model ...
Epoch 2781, train_loss: 797.6866955193183, val_loss: 684.7659149022237
Validation loss decreased (873.534342 --> 873.466464).  Saving model ...
Epoch 2782, train_loss: 798.9950127113664, val_loss: 701.2839477629465
Validation loss decreased (873.466464 --> 873.404573).  Saving model ...
Epoch 2783, train_loss: 799.3484462784087, val_loss: 692.4481479101936
Validation loss decreased (873.404573 --> 873.339550).  Saving model ...
Epoch 2784, train_loss: 797.187574759326, val_loss: 701.8790592996944
Validation loss decreased (873.339550 --> 873.277963).  Saving model ...
Epoch 2785, train_loss: 797.4246174781938, val_loss: 702.9138250482748
Validation loss decreased (873.277963 --> 873.216791).  Saving model ...
Epoch 2786, train_loss: 800.1210400268192, val_loss: 683.8590443944935
Validation loss decreased (873.216791 --> 873.148823).  Saving model ...
Epoch 2787, train_loss: 792.2626621240942, val_loss: 707.605054175291
Validation loss decreased (873.148823 --> 873.089424).  Saving model ...
Epoch 2788, train_loss: 790.9071485584798, val_loss: 710.75893437773
Validation loss decreased (873.089424 --> 873.031200).  Saving model ...
Epoch 2789, train_loss: 795.5477595532149, val_loss: 701.0446907327574
Validation loss decreased (873.031200 --> 872.969534).  Saving model ...
Epoch 2790, train_loss: 789.1809890284721, val_loss: 696.2260268380247
Validation loss decreased (872.969534 --> 872.906185).  Saving model ...
Epoch 2791, train_loss: 799.1916021896959, val_loss: 709.6669522425755
Validation loss decreased (872.906185 --> 872.847697).  Saving model ...
Epoch 2792, train_loss: 795.2209009925303, val_loss: 708.7156467516005
Validation loss decreased (872.847697 --> 872.788910).  Saving model ...
Epoch 2793, train_loss: 799.3582638681072, val_loss: 701.0809068464683
Validation loss decreased (872.788910 --> 872.727433).  Saving model ...
Epoch 2794, train_loss: 798.5088704704359, val_loss: 697.0166278454666
Validation loss decreased (872.727433 --> 872.664544).  Saving model ...
Epoch 2795, train_loss: 797.035316668821, val_loss: 718.5375437964445
Validation loss decreased (872.664544 --> 872.609400).  Saving model ...
Epoch 2796, train_loss: 796.9792199504483, val_loss: 684.0775347038885
Validation loss decreased (872.609400 --> 872.541971).  Saving model ...
Epoch 2797, train_loss: 798.143638620036, val_loss: 697.0289879363999
Validation loss decreased (872.541971 --> 872.479220).  Saving model ...
Epoch 2798, train_loss: 797.0332497915455, val_loss: 702.0614526505274
Validation loss decreased (872.479220 --> 872.418313).  Saving model ...
Epoch 2799, train_loss: 794.703150697552, val_loss: 680.0399262409964
Validation loss decreased (872.418313 --> 872.349582).  Saving model ...
Epoch 2800, train_loss: 794.2091929992946, val_loss: 700.6695722440992
Validation loss decreased (872.349582 --> 872.288268).  Saving model ...
Epoch 2801, train_loss: 799.1516657199526, val_loss: 707.079590230739
Validation loss decreased (872.288268 --> 872.229286).  Saving model ...
Epoch 2802, train_loss: 795.4387425198838, val_loss: 723.2294507550754
Validation loss decreased (872.229286 --> 872.176110).  Saving model ...
Epoch 2803, train_loss: 791.9298082786529, val_loss: 690.3606997643469
Validation loss decreased (872.176110 --> 872.111245).  Saving model ...
Epoch 2804, train_loss: 793.5198891601074, val_loss: 704.313621208977
Validation loss decreased (872.111245 --> 872.051403).  Saving model ...
Epoch 2805, train_loss: 800.698144483861, val_loss: 716.363623636045
Validation loss decreased (872.051403 --> 871.995899).  Saving model ...
Epoch 2806, train_loss: 791.0045587616679, val_loss: 703.4143878629585
Validation loss decreased (871.995899 --> 871.935820).  Saving model ...
Epoch 2807, train_loss: 789.2553624954751, val_loss: 701.5577855343623
Validation loss decreased (871.935820 --> 871.875123).  Saving model ...
Epoch 2808, train_loss: 807.4599323744017, val_loss: 687.1008270655188
Validation loss decreased (871.875123 --> 871.809320).  Saving model ...
Epoch 2809, train_loss: 793.6915626537223, val_loss: 696.2379668610848
Validation loss decreased (871.809320 --> 871.746817).  Saving model ...
Epoch 2810, train_loss: 789.7658586538664, val_loss: 679.7395511471012
Validation loss decreased (871.746817 --> 871.678487).  Saving model ...
Epoch 2811, train_loss: 792.0122535748015, val_loss: 691.8047272970722
Validation loss decreased (871.678487 --> 871.614498).  Saving model ...
Epoch 2812, train_loss: 795.1459641550167, val_loss: 678.535963198863
Validation loss decreased (871.614498 --> 871.545835).  Saving model ...
Epoch 2813, train_loss: 790.7160013155727, val_loss: 682.2974034692405
Validation loss decreased (871.545835 --> 871.478559).  Saving model ...
Epoch 2814, train_loss: 792.4692422977424, val_loss: 688.5587661931031
Validation loss decreased (871.478559 --> 871.413555).  Saving model ...
Epoch 2815, train_loss: 794.5688206980816, val_loss: 693.2512277012182
Validation loss decreased (871.413555 --> 871.350265).  Saving model ...
Epoch 2816, train_loss: 794.3723662624773, val_loss: 711.2585849344622
Validation loss decreased (871.350265 --> 871.293414).  Saving model ...
Epoch 2817, train_loss: 792.0719965399965, val_loss: 712.1093509756084
Validation loss decreased (871.293414 --> 871.236906).  Saving model ...
Epoch 2818, train_loss: 801.0518014646707, val_loss: 709.208070755833
Validation loss decreased (871.236906 --> 871.179408).  Saving model ...
Epoch 2819, train_loss: 789.1358205297213, val_loss: 684.4851278583324
Validation loss decreased (871.179408 --> 871.113181).  Saving model ...
Epoch 2820, train_loss: 795.6544275301816, val_loss: 662.279089924285
Validation loss decreased (871.113181 --> 871.039126).  Saving model ...
Epoch 2821, train_loss: 793.3604100151873, val_loss: 705.5765403504065
Validation loss decreased (871.039126 --> 870.980473).  Saving model ...
Epoch 2822, train_loss: 792.9459801977612, val_loss: 723.0353674684412
Validation loss decreased (870.980473 --> 870.928047).  Saving model ...
Epoch 2823, train_loss: 797.1164875894258, val_loss: 719.7438338685148
Validation loss decreased (870.928047 --> 870.874492).  Saving model ...
Epoch 2824, train_loss: 790.7613383288061, val_loss: 699.1986904287672
Validation loss decreased (870.874492 --> 870.813701).  Saving model ...
Epoch 2825, train_loss: 793.5432085058608, val_loss: 678.2704379691352
Validation loss decreased (870.813701 --> 870.745544).  Saving model ...
Epoch 2826, train_loss: 796.409220904977, val_loss: 691.0668068118342
Validation loss decreased (870.745544 --> 870.681963).  Saving model ...
Epoch 2827, train_loss: 790.4690670713538, val_loss: 696.9459768319795
Validation loss decreased (870.681963 --> 870.620507).  Saving model ...
Epoch 2828, train_loss: 793.3089598652392, val_loss: 719.8177375462984
Validation loss decreased (870.620507 --> 870.567182).  Saving model ...
Epoch 2829, train_loss: 793.0986125480791, val_loss: 712.7720367327444
Validation loss decreased (870.567182 --> 870.511405).  Saving model ...
Epoch 2830, train_loss: 787.7949741125054, val_loss: 715.0102407232812
Validation loss decreased (870.511405 --> 870.456457).  Saving model ...
Epoch 2831, train_loss: 788.8774455871204, val_loss: 712.8473516055392
Validation loss decreased (870.456457 --> 870.400785).  Saving model ...
Epoch 2832, train_loss: 788.4624528734968, val_loss: 688.1579006145953
Validation loss decreased (870.400785 --> 870.336433).  Saving model ...
Epoch 2833, train_loss: 788.0350633835124, val_loss: 719.5520817258184
Validation loss decreased (870.336433 --> 870.283209).  Saving model ...
Epoch 2834, train_loss: 793.8589283191202, val_loss: 693.2044592542451
Validation loss decreased (870.283209 --> 870.220725).  Saving model ...
Epoch 2835, train_loss: 790.3407984162815, val_loss: 687.8712010754151
Validation loss decreased (870.220725 --> 870.156405).  Saving model ...
Epoch 2836, train_loss: 795.9977119925233, val_loss: 711.708305949911
Validation loss decreased (870.156405 --> 870.100534).  Saving model ...
Epoch 2837, train_loss: 800.4581605330937, val_loss: 685.2544438569084
Validation loss decreased (870.100534 --> 870.035379).  Saving model ...
Epoch 2838, train_loss: 791.1181541111592, val_loss: 713.3131944746002
Validation loss decreased (870.035379 --> 869.980156).  Saving model ...
Epoch 2839, train_loss: 792.7657886452787, val_loss: 701.6023474242625
Validation loss decreased (869.980156 --> 869.920847).  Saving model ...
Epoch 2840, train_loss: 796.2738345813179, val_loss: 707.536521522403
Validation loss decreased (869.920847 --> 869.863670).  Saving model ...
Epoch 2841, train_loss: 789.2418818049246, val_loss: 684.5861843522835
Validation loss decreased (869.863670 --> 869.798454).  Saving model ...
Epoch 2842, train_loss: 792.7636706933016, val_loss: 695.4677744596647
Validation loss decreased (869.798454 --> 869.737113).  Saving model ...
Epoch 2843, train_loss: 790.8867503267358, val_loss: 687.3481332947594
Validation loss decreased (869.737113 --> 869.672960).  Saving model ...
Epoch 2844, train_loss: 791.8968856974642, val_loss: 670.5391358293541
Validation loss decreased (869.672960 --> 869.602941).  Saving model ...
Epoch 2845, train_loss: 794.497986034592, val_loss: 678.6936545768161
Validation loss decreased (869.602941 --> 869.535837).  Saving model ...
Epoch 2846, train_loss: 787.1971513531741, val_loss: 720.2275184236524
Validation loss decreased (869.535837 --> 869.483375).  Saving model ...
Epoch 2847, train_loss: 788.3050884610178, val_loss: 714.2009102387232
Validation loss decreased (869.483375 --> 869.428832).  Saving model ...
Epoch 2848, train_loss: 795.8608356949305, val_loss: 695.2807420946715
Validation loss decreased (869.428832 --> 869.367685).  Saving model ...
Epoch 2849, train_loss: 787.8016182257635, val_loss: 692.4987381414244
Validation loss decreased (869.367685 --> 869.305604).  Saving model ...
Epoch 2850, train_loss: 786.2260881908895, val_loss: 711.1330294914382
Validation loss decreased (869.305604 --> 869.250104).  Saving model ...
Epoch 2851, train_loss: 797.4489975718371, val_loss: 691.2251910353813
Validation loss decreased (869.250104 --> 869.187662).  Saving model ...
Epoch 2852, train_loss: 784.3192598825146, val_loss: 682.4927639196098
Validation loss decreased (869.187662 --> 869.122200).  Saving model ...
Epoch 2853, train_loss: 787.6657587394684, val_loss: 706.2001511259323
Validation loss decreased (869.122200 --> 869.065095).  Saving model ...
Epoch 2854, train_loss: 788.6303377194319, val_loss: 701.8003103056773
Validation loss decreased (869.065095 --> 869.006488).  Saving model ...
Epoch 2855, train_loss: 787.0940803572754, val_loss: 692.3100843677921
Validation loss decreased (869.006488 --> 868.944598).  Saving model ...
Epoch 2856, train_loss: 789.9304925034033, val_loss: 656.2845808838366
Validation loss decreased (868.944598 --> 868.870137).  Saving model ...
Epoch 2857, train_loss: 790.6248902017129, val_loss: 710.0004852226376
Validation loss decreased (868.870137 --> 868.814530).  Saving model ...
Epoch 2858, train_loss: 800.2194212702015, val_loss: 695.3847795235783
Validation loss decreased (868.814530 --> 868.753847).  Saving model ...
Epoch 2859, train_loss: 790.384266285518, val_loss: 681.4211284875433
Validation loss decreased (868.753847 --> 868.688324).  Saving model ...
Epoch 2860, train_loss: 785.8520136444264, val_loss: 691.3575810895367
Validation loss decreased (868.688324 --> 868.626320).  Saving model ...
Epoch 2861, train_loss: 790.5861007026353, val_loss: 698.3787206102746
Validation loss decreased (868.626320 --> 868.566814).  Saving model ...
Epoch 2862, train_loss: 790.7195841531094, val_loss: 710.8384611122478
Validation loss decreased (868.566814 --> 868.511702).  Saving model ...
Epoch 2863, train_loss: 786.3590238664164, val_loss: 698.5413066925938
Validation loss decreased (868.511702 --> 868.452334).  Saving model ...
Epoch 2864, train_loss: 793.6586398053743, val_loss: 684.5578149458989
Validation loss decreased (868.452334 --> 868.388125).  Saving model ...
Epoch 2865, train_loss: 793.7435777171847, val_loss: 718.8183390503021
Validation loss decreased (868.388125 --> 868.335920).  Saving model ...
Epoch 2866, train_loss: 783.4535989567823, val_loss: 697.467611914443
Validation loss decreased (868.335920 --> 868.276300).  Saving model ...
Epoch 2867, train_loss: 786.813361398421, val_loss: 704.3266708799647
Validation loss decreased (868.276300 --> 868.219115).  Saving model ...
Epoch 2868, train_loss: 788.1345544453568, val_loss: 703.0742335813247
Validation loss decreased (868.219115 --> 868.161533).  Saving model ...
Epoch 2869, train_loss: 783.9189830488651, val_loss: 693.5787003906239
Validation loss decreased (868.161533 --> 868.100682).  Saving model ...
Epoch 2870, train_loss: 793.1643394554106, val_loss: 711.8195285478678
Validation loss decreased (868.100682 --> 868.046229).  Saving model ...
Epoch 2871, train_loss: 791.8139892569297, val_loss: 695.0414945397225
Validation loss decreased (868.046229 --> 867.985969).  Saving model ...
Epoch 2872, train_loss: 793.0454842709686, val_loss: 687.1234420116525
Validation loss decreased (867.985969 --> 867.922995).  Saving model ...
Epoch 2873, train_loss: 787.4335725227114, val_loss: 704.574777369941
Validation loss decreased (867.922995 --> 867.866139).  Saving model ...
Epoch 2874, train_loss: 791.726109085808, val_loss: 709.1114277222536
Validation loss decreased (867.866139 --> 867.810900).  Saving model ...
Epoch 2875, train_loss: 792.544345377865, val_loss: 667.1414041986181
Validation loss decreased (867.810900 --> 867.741102).  Saving model ...
Epoch 2876, train_loss: 791.0123145616242, val_loss: 700.4283667255664
Validation loss decreased (867.741102 --> 867.682927).  Saving model ...
Epoch 2877, train_loss: 783.8396731400345, val_loss: 712.3291219697729
Validation loss decreased (867.682927 --> 867.628928).  Saving model ...
Epoch 2878, train_loss: 791.2992238677178, val_loss: 701.3827199558419
Validation loss decreased (867.628928 --> 867.571164).  Saving model ...
Epoch 2879, train_loss: 782.3914526555957, val_loss: 684.20495480437
Validation loss decreased (867.571164 --> 867.507473).  Saving model ...
Epoch 2880, train_loss: 790.1844009673111, val_loss: 704.29398315018
Validation loss decreased (867.507473 --> 867.450801).  Saving model ...
Epoch 2881, train_loss: 791.0405560935584, val_loss: 680.6355666677492
Validation loss decreased (867.450801 --> 867.385957).  Saving model ...
Epoch 2882, train_loss: 787.6970002896842, val_loss: 702.0977824243796
Validation loss decreased (867.385957 --> 867.328606).  Saving model ...
Epoch 2883, train_loss: 784.6723350980168, val_loss: 705.3139294106985
Validation loss decreased (867.328606 --> 867.272409).  Saving model ...
Epoch 2884, train_loss: 790.0778009380413, val_loss: 693.3239471325061
Validation loss decreased (867.272409 --> 867.212094).  Saving model ...
Epoch 2885, train_loss: 789.878321592706, val_loss: 683.77833527437
Validation loss decreased (867.212094 --> 867.148512).  Saving model ...
Epoch 2886, train_loss: 799.5113039178625, val_loss: 670.3364247672649
Validation loss decreased (867.148512 --> 867.080317).  Saving model ...
Epoch 2887, train_loss: 782.0513085688979, val_loss: 704.872384511012
Validation loss decreased (867.080317 --> 867.024131).  Saving model ...
Epoch 2888, train_loss: 790.8103190223417, val_loss: 701.1025246750538
Validation loss decreased (867.024131 --> 866.966679).  Saving model ...
Epoch 2889, train_loss: 789.7174225676596, val_loss: 704.9856997486401
Validation loss decreased (866.966679 --> 866.910611).  Saving model ...
Epoch 2890, train_loss: 791.9897986773527, val_loss: 703.557541350844
Validation loss decreased (866.910611 --> 866.854087).  Saving model ...
Epoch 2891, train_loss: 786.1446647964033, val_loss: 684.6741005849954
Validation loss decreased (866.854087 --> 866.791071).  Saving model ...
Epoch 2892, train_loss: 789.0200497152965, val_loss: 695.010503772067
Validation loss decreased (866.791071 --> 866.731672).  Saving model ...
Epoch 2893, train_loss: 785.9045747896438, val_loss: 691.3599730005864
Validation loss decreased (866.731672 --> 866.671053).  Saving model ...
Epoch 2894, train_loss: 786.8144557357048, val_loss: 711.4815130530465
Validation loss decreased (866.671053 --> 866.617429).  Saving model ...
Epoch 2895, train_loss: 791.7364653190399, val_loss: 700.2337686827672
Validation loss decreased (866.617429 --> 866.559956).  Saving model ...
Epoch 2896, train_loss: 789.105092489324, val_loss: 680.8122349862814
Validation loss decreased (866.559956 --> 866.495816).  Saving model ...
Epoch 2897, train_loss: 787.720602628092, val_loss: 681.7884827158742
Validation loss decreased (866.495816 --> 866.432058).  Saving model ...
Epoch 2898, train_loss: 790.8382614026008, val_loss: 707.9903187252088
Validation loss decreased (866.432058 --> 866.377385).  Saving model ...
Epoch 2899, train_loss: 784.7470544445495, val_loss: 694.5501374802549
Validation loss decreased (866.377385 --> 866.318114).  Saving model ...
Epoch 2900, train_loss: 780.8718047630676, val_loss: 689.6351303977772
Validation loss decreased (866.318114 --> 866.257189).  Saving model ...
Epoch 2901, train_loss: 787.206532379294, val_loss: 672.2933618241442
Validation loss decreased (866.257189 --> 866.190328).  Saving model ...
Epoch 2902, train_loss: 787.7165970365228, val_loss: 689.8732457061723
Validation loss decreased (866.190328 --> 866.129571).  Saving model ...
Epoch 2903, train_loss: 788.383129065902, val_loss: 668.3906581470814
Validation loss decreased (866.129571 --> 866.061456).  Saving model ...
Epoch 2904, train_loss: 783.2130263323899, val_loss: 699.1045562717763
Validation loss decreased (866.061456 --> 866.003964).  Saving model ...
Epoch 2905, train_loss: 779.0397616962497, val_loss: 687.6581478579623
Validation loss decreased (866.003964 --> 865.942571).  Saving model ...
Epoch 2906, train_loss: 788.8051769960991, val_loss: 689.7031275208574
Validation loss decreased (865.942571 --> 865.881924).  Saving model ...
Epoch 2907, train_loss: 789.3653062916485, val_loss: 700.4399056478564
Validation loss decreased (865.881924 --> 865.825012).  Saving model ...
Epoch 2908, train_loss: 789.396466935028, val_loss: 679.9677693992746
Validation loss decreased (865.825012 --> 865.761100).  Saving model ...
Epoch 2909, train_loss: 787.2694865048094, val_loss: 702.0994135238069
Validation loss decreased (865.761100 --> 865.704840).  Saving model ...
Epoch 2910, train_loss: 789.3843591934292, val_loss: 699.4757705203474
Validation loss decreased (865.704840 --> 865.647716).  Saving model ...
Epoch 2911, train_loss: 784.5502425869829, val_loss: 712.3079218513659
Validation loss decreased (865.647716 --> 865.595040).  Saving model ...
Epoch 2912, train_loss: 790.5143637947185, val_loss: 704.7989550329139
Validation loss decreased (865.595040 --> 865.539822).  Saving model ...
Epoch 2913, train_loss: 785.8103061906602, val_loss: 696.3781298854618
Validation loss decreased (865.539822 --> 865.481750).  Saving model ...
Epoch 2914, train_loss: 781.5528923245898, val_loss: 692.8989141960059
Validation loss decreased (865.481750 --> 865.422525).  Saving model ...
Epoch 2915, train_loss: 789.9511896600941, val_loss: 692.5341791382212
Validation loss decreased (865.422525 --> 865.363215).  Saving model ...
Epoch 2916, train_loss: 783.4536094213581, val_loss: 711.9432586093967
Validation loss decreased (865.363215 --> 865.310602).  Saving model ...
Epoch 2917, train_loss: 787.7377930206495, val_loss: 704.5084955663043
Validation loss decreased (865.310602 --> 865.255476).  Saving model ...
Epoch 2918, train_loss: 784.7248779787425, val_loss: 688.8773890324989
Validation loss decreased (865.255476 --> 865.195031).  Saving model ...
Epoch 2919, train_loss: 783.8682674371821, val_loss: 711.929086067798
Validation loss decreased (865.195031 --> 865.142525).  Saving model ...
Epoch 2920, train_loss: 791.4577480868992, val_loss: 681.5522816760896
Validation loss decreased (865.142525 --> 865.079652).  Saving model ...
Epoch 2921, train_loss: 780.7738539804501, val_loss: 704.3728498674876
Validation loss decreased (865.079652 --> 865.024634).  Saving model ...
Epoch 2922, train_loss: 790.8708696412905, val_loss: 680.728822005292
Validation loss decreased (865.024634 --> 864.961562).  Saving model ...
Epoch 2923, train_loss: 782.2042206119993, val_loss: 694.6350654576668
Validation loss decreased (864.961562 --> 864.903291).  Saving model ...
Epoch 2924, train_loss: 778.3231535916993, val_loss: 682.548653834617
Validation loss decreased (864.903291 --> 864.840926).  Saving model ...
Epoch 2925, train_loss: 787.6088961819197, val_loss: 673.9991163467481
Validation loss decreased (864.840926 --> 864.775681).  Saving model ...
Epoch 2926, train_loss: 784.4246613803689, val_loss: 693.7900614228516
Validation loss decreased (864.775681 --> 864.717244).  Saving model ...
Epoch 2927, train_loss: 783.1050063901899, val_loss: 706.0206724188506
Validation loss decreased (864.717244 --> 864.663026).  Saving model ...
Epoch 2928, train_loss: 785.5010010371798, val_loss: 687.7881679257645
Validation loss decreased (864.663026 --> 864.602618).  Saving model ...
Epoch 2929, train_loss: 787.3715055333234, val_loss: 702.0487011890833
Validation loss decreased (864.602618 --> 864.547120).  Saving model ...
Epoch 2930, train_loss: 793.4038611710823, val_loss: 673.2000967006664
Validation loss decreased (864.547120 --> 864.481814).  Saving model ...
Epoch 2931, train_loss: 781.4502593391252, val_loss: 695.370880176955
Validation loss decreased (864.481814 --> 864.424117).  Saving model ...
Epoch 2932, train_loss: 785.3266511959783, val_loss: 698.4860325765945
Validation loss decreased (864.424117 --> 864.367521).  Saving model ...
Epoch 2933, train_loss: 786.5543154210666, val_loss: 674.5700942081327
Validation loss decreased (864.367521 --> 864.302810).  Saving model ...
Epoch 2934, train_loss: 778.3669689925127, val_loss: 700.3174169134326
Validation loss decreased (864.302810 --> 864.246919).  Saving model ...
Epoch 2935, train_loss: 789.4875506655245, val_loss: 692.8122097278416
Validation loss decreased (864.246919 --> 864.188508).  Saving model ...
Epoch 2936, train_loss: 781.1711068095375, val_loss: 705.2985485592045
Validation loss decreased (864.188508 --> 864.134390).  Saving model ...
Epoch 2937, train_loss: 788.61624246148, val_loss: 688.229633179241
Validation loss decreased (864.134390 --> 864.074498).  Saving model ...
Epoch 2938, train_loss: 777.2785739383343, val_loss: 698.1103960491445
Validation loss decreased (864.074498 --> 864.018009).  Saving model ...
Epoch 2939, train_loss: 780.9148422346412, val_loss: 709.3972552953496
Validation loss decreased (864.018009 --> 863.965399).  Saving model ...
Epoch 2940, train_loss: 787.97295695305, val_loss: 684.6682612933167
Validation loss decreased (863.965399 --> 863.904414).  Saving model ...
Epoch 2941, train_loss: 777.4743697433947, val_loss: 708.5210943730785
Validation loss decreased (863.904414 --> 863.851580).  Saving model ...
Epoch 2942, train_loss: 784.1029181684762, val_loss: 670.7726541597316
Validation loss decreased (863.851580 --> 863.785952).  Saving model ...
Epoch 2943, train_loss: 780.9343345302956, val_loss: 680.2109793928049
Validation loss decreased (863.785952 --> 863.723575).  Saving model ...
Epoch 2944, train_loss: 782.6504661684437, val_loss: 689.8370749705592
Validation loss decreased (863.723575 --> 863.664510).  Saving model ...
Epoch 2945, train_loss: 775.607936845691, val_loss: 694.1314537582247
Validation loss decreased (863.664510 --> 863.606944).  Saving model ...
Epoch 2946, train_loss: 789.6073535257832, val_loss: 681.4226853075296
Validation loss decreased (863.606944 --> 863.545102).  Saving model ...
Epoch 2947, train_loss: 783.5902112633581, val_loss: 696.1107946987289
Validation loss decreased (863.545102 --> 863.488287).  Saving model ...
Epoch 2948, train_loss: 784.2755965152986, val_loss: 678.7213582082481
Validation loss decreased (863.488287 --> 863.425612).  Saving model ...
Epoch 2949, train_loss: 781.807678672865, val_loss: 686.1944989464795
Validation loss decreased (863.425612 --> 863.365513).  Saving model ...
Epoch 2950, train_loss: 778.8333420971073, val_loss: 690.3365606436358
Validation loss decreased (863.365513 --> 863.306859).  Saving model ...
Epoch 2951, train_loss: 780.8858329638502, val_loss: 703.7151439904618
Validation loss decreased (863.306859 --> 863.252779).  Saving model ...
Epoch 2952, train_loss: 782.439615872696, val_loss: 688.0823754386664
Validation loss decreased (863.252779 --> 863.193439).  Saving model ...
Epoch 2953, train_loss: 782.7355435234743, val_loss: 687.5483016254949
Validation loss decreased (863.193439 --> 863.133959).  Saving model ...
Epoch 2954, train_loss: 787.8256962683142, val_loss: 686.7327793254127
Validation loss decreased (863.133959 --> 863.074243).  Saving model ...
Epoch 2955, train_loss: 782.0415350178898, val_loss: 684.2084892735662
Validation loss decreased (863.074243 --> 863.013713).  Saving model ...
Epoch 2956, train_loss: 780.743293592763, val_loss: 686.8475950115593
Validation loss decreased (863.013713 --> 862.954117).  Saving model ...
Epoch 2957, train_loss: 785.5708556922251, val_loss: 673.9542363939023
Validation loss decreased (862.954117 --> 862.890201).  Saving model ...
Epoch 2958, train_loss: 779.1018995681283, val_loss: 693.8354487077619
Validation loss decreased (862.890201 --> 862.833049).  Saving model ...
Epoch 2959, train_loss: 781.0585034709455, val_loss: 693.8219776302358
Validation loss decreased (862.833049 --> 862.775931).  Saving model ...
Epoch 2960, train_loss: 783.7427836281524, val_loss: 706.7110392726354
Validation loss decreased (862.775931 --> 862.723207).  Saving model ...
Epoch 2961, train_loss: 789.3849532443049, val_loss: 672.6782610516087
Validation loss decreased (862.723207 --> 862.659024).  Saving model ...
Epoch 2962, train_loss: 781.8554718098678, val_loss: 696.8866733084457
Validation loss decreased (862.659024 --> 862.603058).  Saving model ...
Epoch 2963, train_loss: 788.8347863261915, val_loss: 668.8834595851217
Validation loss decreased (862.603058 --> 862.537678).  Saving model ...
Epoch 2964, train_loss: 777.3289608296258, val_loss: 687.1701132637046
Validation loss decreased (862.537678 --> 862.478512).  Saving model ...
Epoch 2965, train_loss: 779.0898063190372, val_loss: 689.8916907958746
Validation loss decreased (862.478512 --> 862.420304).  Saving model ...
Epoch 2966, train_loss: 787.2280309088, val_loss: 670.4516348074214
Validation loss decreased (862.420304 --> 862.355581).  Saving model ...
Epoch 2967, train_loss: 787.0231877988457, val_loss: 682.4200704380763
Validation loss decreased (862.355581 --> 862.294936).  Saving model ...
Epoch 2968, train_loss: 785.1168495425203, val_loss: 715.3184033492099
Validation loss decreased (862.294936 --> 862.245415).  Saving model ...
Epoch 2969, train_loss: 783.4553023866669, val_loss: 682.7010468280982
Validation loss decreased (862.245415 --> 862.184942).  Saving model ...
Epoch 2970, train_loss: 781.720056524911, val_loss: 693.2725380005663
Validation loss decreased (862.184942 --> 862.128069).  Saving model ...
Epoch 2971, train_loss: 782.9354102151303, val_loss: 697.1603472236575
Validation loss decreased (862.128069 --> 862.072543).  Saving model ...
Epoch 2972, train_loss: 781.6163915775657, val_loss: 691.533608899448
Validation loss decreased (862.072543 --> 862.015162).  Saving model ...
Epoch 2973, train_loss: 777.4015314209189, val_loss: 663.9277517759032
Validation loss decreased (862.015162 --> 861.948533).  Saving model ...
Epoch 2974, train_loss: 781.5211886611517, val_loss: 695.4769427716074
Validation loss decreased (861.948533 --> 861.892557).  Saving model ...
Epoch 2975, train_loss: 781.1105192458509, val_loss: 668.3745974093679
Validation loss decreased (861.892557 --> 861.827509).  Saving model ...
Epoch 2976, train_loss: 777.7700373273567, val_loss: 677.3809993755268
Validation loss decreased (861.827509 --> 861.765531).  Saving model ...
Epoch 2977, train_loss: 782.06287006582, val_loss: 685.0640584127444
Validation loss decreased (861.765531 --> 861.706175).  Saving model ...
Epoch 2978, train_loss: 780.4485725639518, val_loss: 697.3828864446396
Validation loss decreased (861.706175 --> 861.650996).  Saving model ...
Epoch 2979, train_loss: 793.2957358514911, val_loss: 679.2688964648053
Validation loss decreased (861.650996 --> 861.589774).  Saving model ...
Epoch 2980, train_loss: 784.0125985535411, val_loss: 672.3689534818026
Validation loss decreased (861.589774 --> 861.526277).  Saving model ...
Epoch 2981, train_loss: 777.9156353970887, val_loss: 694.3963332795548
Validation loss decreased (861.526277 --> 861.470212).  Saving model ...
Epoch 2982, train_loss: 783.9000991441817, val_loss: 683.3767139656238
Validation loss decreased (861.470212 --> 861.410489).  Saving model ...
Epoch 2983, train_loss: 782.5190406562596, val_loss: 681.3136162856225
Validation loss decreased (861.410489 --> 861.350115).  Saving model ...
Epoch 2984, train_loss: 783.2215514991713, val_loss: 673.6556417718092
Validation loss decreased (861.350115 --> 861.287214).  Saving model ...
Epoch 2985, train_loss: 780.6355588544168, val_loss: 686.9594932939943
Validation loss decreased (861.287214 --> 861.228813).  Saving model ...
Epoch 2986, train_loss: 775.44790076683, val_loss: 691.5681076288998
Validation loss decreased (861.228813 --> 861.171994).  Saving model ...
Epoch 2987, train_loss: 787.0124577907626, val_loss: 679.1419635966645
Validation loss decreased (861.171994 --> 861.111054).  Saving model ...
Epoch 2988, train_loss: 781.313287930673, val_loss: 685.3009360226552
Validation loss decreased (861.111054 --> 861.052215).  Saving model ...
Epoch 2989, train_loss: 774.6278243595236, val_loss: 685.6225247642401
Validation loss decreased (861.052215 --> 860.993523).  Saving model ...
Epoch 2990, train_loss: 781.1863278506356, val_loss: 667.9098013030933
Validation loss decreased (860.993523 --> 860.928947).  Saving model ...
Epoch 2991, train_loss: 777.4105255550033, val_loss: 692.8281077869847
Validation loss decreased (860.928947 --> 860.872744).  Saving model ...
Epoch 2992, train_loss: 775.7589057877818, val_loss: 683.9580970434572
Validation loss decreased (860.872744 --> 860.813615).  Saving model ...
Epoch 2993, train_loss: 777.3396270524355, val_loss: 691.1391299533957
Validation loss decreased (860.813615 --> 860.756925).  Saving model ...
Epoch 2994, train_loss: 775.4630347258163, val_loss: 685.61667620479
Validation loss decreased (860.756925 --> 860.698428).  Saving model ...
Epoch 2995, train_loss: 774.3751465354086, val_loss: 687.9941583761466
Validation loss decreased (860.698428 --> 860.640763).  Saving model ...
Epoch 2996, train_loss: 784.2217303336181, val_loss: 670.7147112967906
Validation loss decreased (860.640763 --> 860.577370).  Saving model ...
Epoch 2997, train_loss: 776.2484168143534, val_loss: 689.8841289246639
Validation loss decreased (860.577370 --> 860.520416).  Saving model ...
Epoch 2998, train_loss: 782.3059251255147, val_loss: 687.3340540174758
Validation loss decreased (860.520416 --> 860.462648).  Saving model ...
Epoch 2999, train_loss: 780.159380324338, val_loss: 672.4110307864241
Validation loss decreased (860.462648 --> 860.399943).  Saving model ...
Epoch 3000, train_loss: 775.6030417959471, val_loss: 702.7638908400473
Validation loss decreased (860.399943 --> 860.347398).  Saving model ...
Epoch 3001, train_loss: 786.7921542320231, val_loss: 711.7795071503523
Validation loss decreased (860.347398 --> 860.297892).  Saving model ...
Epoch 3002, train_loss: 786.7192312143289, val_loss: 676.077153230597
Validation loss decreased (860.297892 --> 860.236526).  Saving model ...
Epoch 3003, train_loss: 778.2825187019067, val_loss: 677.4664663584921
Validation loss decreased (860.236526 --> 860.175663).  Saving model ...
Epoch 3004, train_loss: 778.3340801428313, val_loss: 685.518263736787
Validation loss decreased (860.175663 --> 860.117522).  Saving model ...
Epoch 3005, train_loss: 781.2877927915403, val_loss: 687.1756497551672
Validation loss decreased (860.117522 --> 860.059970).  Saving model ...
Epoch 3006, train_loss: 779.7367557517921, val_loss: 670.5634516732564
Validation loss decreased (860.059970 --> 859.996931).  Saving model ...
Epoch 3007, train_loss: 778.3967473159493, val_loss: 674.2949376832559
Validation loss decreased (859.996931 --> 859.935175).  Saving model ...
Epoch 3008, train_loss: 779.7437784165184, val_loss: 686.3173998425628
Validation loss decreased (859.935175 --> 859.877456).  Saving model ...
Epoch 3009, train_loss: 779.2926072937029, val_loss: 687.7369655780002
Validation loss decreased (859.877456 --> 859.820247).  Saving model ...
Epoch 3010, train_loss: 776.7489847039935, val_loss: 682.6825161667338
Validation loss decreased (859.820247 --> 859.761398).  Saving model ...
Epoch 3011, train_loss: 783.0371517190284, val_loss: 668.5761272870174
Validation loss decreased (859.761398 --> 859.697902).  Saving model ...
Epoch 3012, train_loss: 778.8968759431606, val_loss: 673.7033213515308
Validation loss decreased (859.697902 --> 859.636151).  Saving model ...
Epoch 3013, train_loss: 776.5902360894659, val_loss: 675.4055518492509
Validation loss decreased (859.636151 --> 859.575006).  Saving model ...
Epoch 3014, train_loss: 776.4744111281832, val_loss: 673.5858154536511
Validation loss decreased (859.575006 --> 859.513297).  Saving model ...
Epoch 3015, train_loss: 779.5338374019093, val_loss: 683.7812398935913
Validation loss decreased (859.513297 --> 859.455011).  Saving model ...
Epoch 3016, train_loss: 779.9000133589824, val_loss: 698.1177736396813
Validation loss decreased (859.455011 --> 859.401517).  Saving model ...
Epoch 3017, train_loss: 783.3848656408942, val_loss: 668.13791102384
Validation loss decreased (859.401517 --> 859.338122).  Saving model ...
Epoch 3018, train_loss: 771.7343757088718, val_loss: 694.1786255829646
Validation loss decreased (859.338122 --> 859.283397).  Saving model ...
Epoch 3019, train_loss: 775.9144974678844, val_loss: 704.876146187606
Validation loss decreased (859.283397 --> 859.232252).  Saving model ...
Epoch 3020, train_loss: 777.2571994601285, val_loss: 695.8262213977072
Validation loss decreased (859.232252 --> 859.178144).  Saving model ...
Epoch 3021, train_loss: 773.8671951200056, val_loss: 677.6464533437958
Validation loss decreased (859.178144 --> 859.118054).  Saving model ...
Epoch 3022, train_loss: 779.2595824016189, val_loss: 694.1619653179363
Validation loss decreased (859.118054 --> 859.063469).  Saving model ...
Epoch 3023, train_loss: 784.0148228946774, val_loss: 661.2852739615246
Validation loss decreased (859.063469 --> 858.998045).  Saving model ...
Epoch 3024, train_loss: 775.8585444034068, val_loss: 683.0681261597853
Validation loss decreased (858.998045 --> 858.939867).  Saving model ...
Epoch 3025, train_loss: 780.5941542328816, val_loss: 679.6891020452207
Validation loss decreased (858.939867 --> 858.880610).  Saving model ...
Epoch 3026, train_loss: 774.3031780799471, val_loss: 686.4312240777417
Validation loss decreased (858.880610 --> 858.823621).  Saving model ...
Epoch 3027, train_loss: 782.7458142593994, val_loss: 692.0380687221115
Validation loss decreased (858.823621 --> 858.768522).  Saving model ...
Epoch 3028, train_loss: 773.3175880695563, val_loss: 688.601389345505
Validation loss decreased (858.768522 --> 858.712324).  Saving model ...
Epoch 3029, train_loss: 774.0782240187976, val_loss: 694.1079214821042
Validation loss decreased (858.712324 --> 858.657981).  Saving model ...
Epoch 3030, train_loss: 775.789620225056, val_loss: 698.3871187227968
Validation loss decreased (858.657981 --> 858.605086).  Saving model ...
Epoch 3031, train_loss: 773.0011079998449, val_loss: 687.6351298556068
Validation loss decreased (858.605086 --> 858.548679).  Saving model ...
Epoch 3032, train_loss: 775.1818213944706, val_loss: 694.5687915067655
Validation loss decreased (858.548679 --> 858.494596).  Saving model ...
Epoch 3033, train_loss: 777.1130167283349, val_loss: 672.8554742477783
Validation loss decreased (858.494596 --> 858.433390).  Saving model ...
Epoch 3034, train_loss: 775.5176197866098, val_loss: 676.7076276992872
Validation loss decreased (858.433390 --> 858.373493).  Saving model ...
Epoch 3035, train_loss: 774.4917776002386, val_loss: 683.8932378084796
Validation loss decreased (858.373493 --> 858.316004).  Saving model ...
Epoch 3036, train_loss: 775.5938466906513, val_loss: 685.5519483238573
Validation loss decreased (858.316004 --> 858.259099).  Saving model ...
Epoch 3037, train_loss: 779.2934095397695, val_loss: 668.3224720249908
Validation loss decreased (858.259099 --> 858.196558).  Saving model ...
Epoch 3038, train_loss: 779.7831835437419, val_loss: 682.7303102365913
Validation loss decreased (858.196558 --> 858.138801).  Saving model ...
Epoch 3039, train_loss: 776.3715178087028, val_loss: 699.2428534588662
Validation loss decreased (858.138801 --> 858.086515).  Saving model ...
Epoch 3040, train_loss: 776.5477890962763, val_loss: 690.4118208896124
Validation loss decreased (858.086515 --> 858.031359).  Saving model ...
Epoch 3041, train_loss: 782.3108041678673, val_loss: 690.5249558461378
Validation loss decreased (858.031359 --> 857.976276).  Saving model ...
Epoch 3042, train_loss: 775.605125467555, val_loss: 682.2716483455238
Validation loss decreased (857.976276 --> 857.918517).  Saving model ...
Epoch 3043, train_loss: 779.0932162577288, val_loss: 696.3038933907728
Validation loss decreased (857.918517 --> 857.865407).  Saving model ...
Epoch 3044, train_loss: 782.3251167209208, val_loss: 691.0884155709437
Validation loss decreased (857.865407 --> 857.810618).  Saving model ...
Epoch 3045, train_loss: 775.1235837714725, val_loss: 683.4732091352789
Validation loss decreased (857.810618 --> 857.753364).  Saving model ...
Epoch 3046, train_loss: 777.9603959339217, val_loss: 680.5335775353516
Validation loss decreased (857.753364 --> 857.695183).  Saving model ...
Epoch 3047, train_loss: 774.316456932741, val_loss: 686.0222978774159
Validation loss decreased (857.695183 --> 857.638841).  Saving model ...
Epoch 3048, train_loss: 768.3052756904711, val_loss: 690.2743098425095
Validation loss decreased (857.638841 --> 857.583932).  Saving model ...
Epoch 3049, train_loss: 779.0648802948334, val_loss: 690.4111137758805
Validation loss decreased (857.583932 --> 857.529103).  Saving model ...
Epoch 3050, train_loss: 774.25402467845, val_loss: 685.803554989409
Validation loss decreased (857.529103 --> 857.472800).  Saving model ...
Epoch 3051, train_loss: 776.7866108791856, val_loss: 679.1558503226112
Validation loss decreased (857.472800 --> 857.414354).  Saving model ...
Epoch 3052, train_loss: 772.6717462136068, val_loss: 684.5428041988947
Validation loss decreased (857.414354 --> 857.357712).  Saving model ...
Epoch 3053, train_loss: 774.0979603404676, val_loss: 691.7783263788955
Validation loss decreased (857.357712 --> 857.303477).  Saving model ...
Epoch 3054, train_loss: 780.8286088261578, val_loss: 665.9775057573455
Validation loss decreased (857.303477 --> 857.240829).  Saving model ...
Epoch 3055, train_loss: 774.6328089537146, val_loss: 684.3207722446547
Validation loss decreased (857.240829 --> 857.184227).  Saving model ...
Epoch 3056, train_loss: 771.8600649029833, val_loss: 680.4570390281857
Validation loss decreased (857.184227 --> 857.126398).  Saving model ...
Epoch 3057, train_loss: 782.4584064187867, val_loss: 670.631883024386
Validation loss decreased (857.126398 --> 857.065392).  Saving model ...
Epoch 3058, train_loss: 767.4791252173302, val_loss: 689.078386394658
Validation loss decreased (857.065392 --> 857.010458).  Saving model ...
Epoch 3059, train_loss: 773.8225460828437, val_loss: 694.7532151065825
Validation loss decreased (857.010458 --> 856.957416).  Saving model ...
Epoch 3060, train_loss: 773.1971779322547, val_loss: 690.9725058430657
Validation loss decreased (856.957416 --> 856.903172).  Saving model ...
Epoch 3061, train_loss: 775.6207464604022, val_loss: 678.6502659317855
Validation loss decreased (856.903172 --> 856.844939).  Saving model ...
Epoch 3062, train_loss: 778.6522682273043, val_loss: 680.757648952416
Validation loss decreased (856.844939 --> 856.787431).  Saving model ...
Epoch 3063, train_loss: 777.0819271501692, val_loss: 671.7314836497553
Validation loss decreased (856.787431 --> 856.727015).  Saving model ...
Epoch 3064, train_loss: 775.6633131791787, val_loss: 675.0134410218841
Validation loss decreased (856.727015 --> 856.667709).  Saving model ...
Epoch 3065, train_loss: 774.917991099553, val_loss: 681.289808942102
Validation loss decreased (856.667709 --> 856.610489).  Saving model ...
Epoch 3066, train_loss: 773.126308904349, val_loss: 684.4945056807115
Validation loss decreased (856.610489 --> 856.554352).  Saving model ...
Epoch 3067, train_loss: 772.8417437151636, val_loss: 678.1834293126952
Validation loss decreased (856.554352 --> 856.496194).  Saving model ...
Epoch 3068, train_loss: 776.2982178748758, val_loss: 688.0238286841362
Validation loss decreased (856.496194 --> 856.441281).  Saving model ...
Epoch 3069, train_loss: 773.888390597067, val_loss: 686.9099660538417
Validation loss decreased (856.441281 --> 856.386041).  Saving model ...
Epoch 3070, train_loss: 769.7539267242181, val_loss: 685.5577509162496
Validation loss decreased (856.386041 --> 856.330397).  Saving model ...
Epoch 3071, train_loss: 785.775512090937, val_loss: 691.9088778698889
Validation loss decreased (856.330397 --> 856.276857).  Saving model ...
Epoch 3072, train_loss: 774.9961333581397, val_loss: 685.2633438435863
Validation loss decreased (856.276857 --> 856.221189).  Saving model ...
Epoch 3073, train_loss: 769.317300833152, val_loss: 701.6211371552948
Validation loss decreased (856.221189 --> 856.170879).  Saving model ...
Epoch 3074, train_loss: 779.2262284399574, val_loss: 658.8615310471921
Validation loss decreased (856.170879 --> 856.106693).  Saving model ...
Epoch 3075, train_loss: 777.3151443022363, val_loss: 670.7319971503044
Validation loss decreased (856.106693 --> 856.046408).  Saving model ...
Epoch 3076, train_loss: 770.9986818906874, val_loss: 674.3806945734667
Validation loss decreased (856.046408 --> 855.987349).  Saving model ...
Epoch 3077, train_loss: 781.6618960152518, val_loss: 678.8114265930986
Validation loss decreased (855.987349 --> 855.929769).  Saving model ...
Epoch 3078, train_loss: 764.6202496485605, val_loss: 682.1972137823265
Validation loss decreased (855.929769 --> 855.873325).  Saving model ...
Epoch 3079, train_loss: 772.6049645354127, val_loss: 685.8799570338045
Validation loss decreased (855.873325 --> 855.818115).  Saving model ...
Epoch 3080, train_loss: 770.5467782378335, val_loss: 677.625125416352
Validation loss decreased (855.818115 --> 855.760260).  Saving model ...
Epoch 3081, train_loss: 775.0309845111004, val_loss: 678.8418714271103
Validation loss decreased (855.760260 --> 855.702837).  Saving model ...
Epoch 3082, train_loss: 770.7471208291059, val_loss: 677.1084066413513
Validation loss decreased (855.702837 --> 855.644890).  Saving model ...
Epoch 3083, train_loss: 773.0319235683977, val_loss: 673.5716164532417
Validation loss decreased (855.644890 --> 855.585833).  Saving model ...
Epoch 3084, train_loss: 766.6077043559317, val_loss: 669.2174785917229
Validation loss decreased (855.585833 --> 855.525402).  Saving model ...
Epoch 3085, train_loss: 770.9611815414195, val_loss: 661.5638156015676
Validation loss decreased (855.525402 --> 855.462530).  Saving model ...
Epoch 3086, train_loss: 772.8010308737477, val_loss: 679.8127165713469
Validation loss decreased (855.462530 --> 855.405611).  Saving model ...
Epoch 3087, train_loss: 775.3552602677527, val_loss: 671.1367212145198
Validation loss decreased (855.405611 --> 855.345919).  Saving model ...
Epoch 3088, train_loss: 774.5313803185356, val_loss: 679.4598260914952
Validation loss decreased (855.345919 --> 855.288961).  Saving model ...
Epoch 3089, train_loss: 773.5967857163159, val_loss: 689.2478350955031
Validation loss decreased (855.288961 --> 855.235209).  Saving model ...
Epoch 3090, train_loss: 770.2705853296009, val_loss: 689.4753132120442
Validation loss decreased (855.235209 --> 855.181565).  Saving model ...
Epoch 3091, train_loss: 781.5028175784194, val_loss: 676.4068804356128
Validation loss decreased (855.181565 --> 855.123728).  Saving model ...
Epoch 3092, train_loss: 772.8182522863099, val_loss: 685.866773945745
Validation loss decreased (855.123728 --> 855.068988).  Saving model ...
Epoch 3093, train_loss: 774.5090671374517, val_loss: 683.9317613980508
Validation loss decreased (855.068988 --> 855.013657).  Saving model ...
Epoch 3094, train_loss: 778.9568523122676, val_loss: 679.6052237805837
Validation loss decreased (855.013657 --> 854.956964).  Saving model ...
Epoch 3095, train_loss: 773.4491185144049, val_loss: 681.8873715751153
Validation loss decreased (854.956964 --> 854.901045).  Saving model ...
Epoch 3096, train_loss: 773.7233175562534, val_loss: 679.8854749194232
Validation loss decreased (854.901045 --> 854.844515).  Saving model ...
Epoch 3097, train_loss: 769.3083650411478, val_loss: 673.3463855264919
Validation loss decreased (854.844515 --> 854.785911).  Saving model ...
Epoch 3098, train_loss: 769.8924284569265, val_loss: 688.1590976252714
Validation loss decreased (854.785911 --> 854.732126).  Saving model ...
Epoch 3099, train_loss: 775.8983677147326, val_loss: 674.6919192903684
Validation loss decreased (854.732126 --> 854.674029).  Saving model ...
Epoch 3100, train_loss: 764.4225671482757, val_loss: 692.8473147681248
Validation loss decreased (854.674029 --> 854.621827).  Saving model ...
Epoch 3101, train_loss: 776.711896719841, val_loss: 679.139040961288
Validation loss decreased (854.621827 --> 854.565238).  Saving model ...
Epoch 3102, train_loss: 763.8977610553465, val_loss: 687.1424352988937
Validation loss decreased (854.565238 --> 854.511266).  Saving model ...
Epoch 3103, train_loss: 768.0187139454332, val_loss: 691.8592073139331
Validation loss decreased (854.511266 --> 854.458848).  Saving model ...
Epoch 3104, train_loss: 771.631689718037, val_loss: 678.0746035395732
Validation loss decreased (854.458848 --> 854.402023).  Saving model ...
Epoch 3105, train_loss: 770.1572399757049, val_loss: 673.1225842563975
Validation loss decreased (854.402023 --> 854.343640).  Saving model ...
Epoch 3106, train_loss: 761.9070380489646, val_loss: 682.3410489505974
Validation loss decreased (854.343640 --> 854.288262).  Saving model ...
Epoch 3107, train_loss: 779.6150543684671, val_loss: 670.1920803954207
Validation loss decreased (854.288262 --> 854.229010).  Saving model ...
Epoch 3108, train_loss: 769.1965707039626, val_loss: 681.5940175596435
Validation loss decreased (854.229010 --> 854.173465).  Saving model ...
Epoch 3109, train_loss: 771.2110078477307, val_loss: 689.3005375489375
Validation loss decreased (854.173465 --> 854.120434).  Saving model ...
Epoch 3110, train_loss: 768.8995601629925, val_loss: 677.9710919910673
Validation loss decreased (854.120434 --> 854.063794).  Saving model ...
Epoch 3111, train_loss: 765.8598307549754, val_loss: 693.2313323953089
Validation loss decreased (854.063794 --> 854.012096).  Saving model ...
Epoch 3112, train_loss: 773.4693013540995, val_loss: 640.3208672030106
Validation loss decreased (854.012096 --> 853.943430).  Saving model ...
Epoch 3113, train_loss: 773.5559276972903, val_loss: 671.4183930520442
Validation loss decreased (853.943430 --> 853.884796).  Saving model ...
Epoch 3114, train_loss: 775.0004189058366, val_loss: 653.8052060380139
Validation loss decreased (853.884796 --> 853.820545).  Saving model ...
Epoch 3115, train_loss: 763.1345340497008, val_loss: 687.2990961897818
Validation loss decreased (853.820545 --> 853.767087).  Saving model ...
Epoch 3116, train_loss: 770.2625809123184, val_loss: 672.1860907336521
Validation loss decreased (853.767087 --> 853.708813).  Saving model ...
Epoch 3117, train_loss: 765.53078907085, val_loss: 675.1859543377827
Validation loss decreased (853.708813 --> 853.651539).  Saving model ...
Epoch 3118, train_loss: 771.9999287666102, val_loss: 665.2119358053254
Validation loss decreased (853.651539 --> 853.591103).  Saving model ...
Epoch 3119, train_loss: 769.967701095385, val_loss: 659.9088271465017
Validation loss decreased (853.591103 --> 853.529006).  Saving model ...
Epoch 3120, train_loss: 765.7938014126665, val_loss: 668.6948609227055
Validation loss decreased (853.529006 --> 853.469764).  Saving model ...
Epoch 3121, train_loss: 766.6768593758552, val_loss: 668.8192009059923
Validation loss decreased (853.469764 --> 853.410600).  Saving model ...
Epoch 3122, train_loss: 767.0136092552912, val_loss: 653.1716204756061
Validation loss decreased (853.410600 --> 853.346462).  Saving model ...
Epoch 3123, train_loss: 770.9117586025662, val_loss: 668.1531934154921
Validation loss decreased (853.346462 --> 853.287162).  Saving model ...
Epoch 3124, train_loss: 766.9631114488802, val_loss: 674.6037045365244
Validation loss decreased (853.287162 --> 853.229965).  Saving model ...
Epoch 3125, train_loss: 772.0065268041873, val_loss: 661.939925504029
Validation loss decreased (853.229965 --> 853.168752).  Saving model ...
Epoch 3126, train_loss: 762.2710020723581, val_loss: 678.8815425001475
Validation loss decreased (853.168752 --> 853.112998).  Saving model ...
Epoch 3127, train_loss: 766.8468196898222, val_loss: 670.034170988368
Validation loss decreased (853.112998 --> 853.054451).  Saving model ...
Epoch 3128, train_loss: 762.4866764041028, val_loss: 679.3049664645287
Validation loss decreased (853.054451 --> 852.998904).  Saving model ...
Epoch 3129, train_loss: 770.3179720908327, val_loss: 665.3929246503889
Validation loss decreased (852.998904 --> 852.938947).  Saving model ...
Epoch 3130, train_loss: 772.666396411348, val_loss: 660.6250213923171
Validation loss decreased (852.938947 --> 852.877505).  Saving model ...
Epoch 3131, train_loss: 767.684359131478, val_loss: 657.6563560862456
Validation loss decreased (852.877505 --> 852.815154).  Saving model ...
Epoch 3132, train_loss: 771.1457217240437, val_loss: 678.939138750953
Validation loss decreased (852.815154 --> 852.759638).  Saving model ...
Epoch 3133, train_loss: 769.1089495989748, val_loss: 665.4032923671938
Validation loss decreased (852.759638 --> 852.699837).  Saving model ...
Epoch 3134, train_loss: 770.0725630440995, val_loss: 677.2486845591005
Validation loss decreased (852.699837 --> 852.643854).  Saving model ...
Epoch 3135, train_loss: 768.3765188899879, val_loss: 678.2470449947983
Validation loss decreased (852.643854 --> 852.588225).  Saving model ...
Epoch 3136, train_loss: 768.4112163654042, val_loss: 672.5541839730632
Validation loss decreased (852.588225 --> 852.530816).  Saving model ...
Epoch 3137, train_loss: 775.1207014736789, val_loss: 675.3231777806637
Validation loss decreased (852.530816 --> 852.474326).  Saving model ...
Epoch 3138, train_loss: 771.9546714607014, val_loss: 651.6755084341657
Validation loss decreased (852.474326 --> 852.410337).  Saving model ...
Epoch 3139, train_loss: 771.2980703770521, val_loss: 641.2396159416991
Validation loss decreased (852.410337 --> 852.343064).  Saving model ...
Epoch 3140, train_loss: 759.6568445935793, val_loss: 690.7521682501615
Validation loss decreased (852.343064 --> 852.291602).  Saving model ...
Epoch 3141, train_loss: 769.0672126561237, val_loss: 680.2440871163765
Validation loss decreased (852.291602 --> 852.236827).  Saving model ...
Epoch 3142, train_loss: 764.3556288226513, val_loss: 660.4772284511617
Validation loss decreased (852.236827 --> 852.175796).  Saving model ...
Epoch 3143, train_loss: 769.7716630586502, val_loss: 665.5795425826647
Validation loss decreased (852.175796 --> 852.116427).  Saving model ...
Epoch 3144, train_loss: 762.3064734131415, val_loss: 669.0563129083318
Validation loss decreased (852.116427 --> 852.058202).  Saving model ...
Epoch 3145, train_loss: 771.6047406278882, val_loss: 665.0137542404071
Validation loss decreased (852.058202 --> 851.998728).  Saving model ...
Epoch 3146, train_loss: 761.2756981581181, val_loss: 680.8231562488722
Validation loss decreased (851.998728 --> 851.944318).  Saving model ...
Epoch 3147, train_loss: 767.3217661006175, val_loss: 673.2081064656821
Validation loss decreased (851.944318 --> 851.887522).  Saving model ...
Epoch 3148, train_loss: 762.7904088934517, val_loss: 694.5004555641505
Validation loss decreased (851.887522 --> 851.837526).  Saving model ...
Epoch 3149, train_loss: 764.607358266118, val_loss: 664.6176517538895
Validation loss decreased (851.837526 --> 851.778072).  Saving model ...
Epoch 3150, train_loss: 768.8245186751489, val_loss: 681.4008844669444
Validation loss decreased (851.778072 --> 851.723984).  Saving model ...
Epoch 3151, train_loss: 769.2033240615322, val_loss: 659.913635079574
Validation loss decreased (851.723984 --> 851.663111).  Saving model ...
Epoch 3152, train_loss: 762.9365831042917, val_loss: 665.7447541150894
Validation loss decreased (851.663111 --> 851.604127).  Saving model ...
Epoch 3153, train_loss: 769.8423387403049, val_loss: 671.6376938192494
Validation loss decreased (851.604127 --> 851.547049).  Saving model ...
Epoch 3154, train_loss: 768.3335400811374, val_loss: 673.393553802283
Validation loss decreased (851.547049 --> 851.490564).  Saving model ...
Epoch 3155, train_loss: 768.2735355106723, val_loss: 673.9865689759346
Validation loss decreased (851.490564 --> 851.434303).  Saving model ...
Epoch 3156, train_loss: 766.3937837764618, val_loss: 672.8748156868974
Validation loss decreased (851.434303 --> 851.377725).  Saving model ...
Epoch 3157, train_loss: 768.1379932039175, val_loss: 664.1172066486768
Validation loss decreased (851.377725 --> 851.318409).  Saving model ...
Epoch 3158, train_loss: 762.3333977343294, val_loss: 685.8017905111009
Validation loss decreased (851.318409 --> 851.265997).  Saving model ...
Epoch 3159, train_loss: 765.3555996741086, val_loss: 672.7246671074522
Validation loss decreased (851.265997 --> 851.209479).  Saving model ...
Epoch 3160, train_loss: 766.3779026757556, val_loss: 672.7425415575949
Validation loss decreased (851.209479 --> 851.153002).  Saving model ...
Epoch 3161, train_loss: 762.6412633454323, val_loss: 667.0533166279619
Validation loss decreased (851.153002 --> 851.094761).  Saving model ...
Epoch 3162, train_loss: 765.39419282594, val_loss: 683.3474608493517
Validation loss decreased (851.094761 --> 851.041710).  Saving model ...
Epoch 3163, train_loss: 772.001820964547, val_loss: 678.9898357370058
Validation loss decreased (851.041710 --> 850.987315).  Saving model ...
Epoch 3164, train_loss: 771.2141761208716, val_loss: 676.7384348396022
Validation loss decreased (850.987315 --> 850.932243).  Saving model ...
Epoch 3165, train_loss: 775.7324629801709, val_loss: 648.8272528381593
Validation loss decreased (850.932243 --> 850.868387).  Saving model ...
Epoch 3166, train_loss: 760.8280689703217, val_loss: 677.8235297263886
Validation loss decreased (850.868387 --> 850.813729).  Saving model ...
Epoch 3167, train_loss: 766.0107820535331, val_loss: 672.0261964399067
Validation loss decreased (850.813729 --> 850.757276).  Saving model ...
Epoch 3168, train_loss: 765.7212958972824, val_loss: 671.6137286828075
Validation loss decreased (850.757276 --> 850.700728).  Saving model ...
Epoch 3169, train_loss: 772.2594314761927, val_loss: 674.6005851097244
Validation loss decreased (850.700728 --> 850.645159).  Saving model ...
Epoch 3170, train_loss: 768.3267004424549, val_loss: 662.4740754193843
Validation loss decreased (850.645159 --> 850.585799).  Saving model ...
Epoch 3171, train_loss: 767.5378820243311, val_loss: 656.3358688902969
Validation loss decreased (850.585799 --> 850.524540).  Saving model ...
Epoch 3172, train_loss: 765.540724726284, val_loss: 671.2198289009049
Validation loss decreased (850.524540 --> 850.468013).  Saving model ...
Epoch 3173, train_loss: 763.063980842997, val_loss: 673.1671228056047
Validation loss decreased (850.468013 --> 850.412135).  Saving model ...
Epoch 3174, train_loss: 759.383128478835, val_loss: 679.3769554743727
Validation loss decreased (850.412135 --> 850.358249).  Saving model ...
Epoch 3175, train_loss: 761.4144304659434, val_loss: 681.0207207459656
Validation loss decreased (850.358249 --> 850.304914).  Saving model ...
Epoch 3176, train_loss: 759.0758574793651, val_loss: 681.2373852805963
Validation loss decreased (850.304914 --> 850.251681).  Saving model ...
Epoch 3177, train_loss: 767.5379439629614, val_loss: 673.0037076292218
Validation loss decreased (850.251681 --> 850.195890).  Saving model ...
Epoch 3178, train_loss: 768.2193966703181, val_loss: 671.5612938828824
Validation loss decreased (850.195890 --> 850.139680).  Saving model ...
Epoch 3179, train_loss: 760.1250232898204, val_loss: 679.2372062153842
Validation loss decreased (850.139680 --> 850.085921).  Saving model ...
Epoch 3180, train_loss: 764.395830266257, val_loss: 676.5212627334068
Validation loss decreased (850.085921 --> 850.031341).  Saving model ...
Epoch 3181, train_loss: 766.9192856295159, val_loss: 665.8655161440487
Validation loss decreased (850.031341 --> 849.973445).  Saving model ...
Epoch 3182, train_loss: 763.2037788314664, val_loss: 668.8981771687559
Validation loss decreased (849.973445 --> 849.916539).  Saving model ...
Epoch 3183, train_loss: 769.6284624733487, val_loss: 656.8666488898907
Validation loss decreased (849.916539 --> 849.855889).  Saving model ...
Epoch 3184, train_loss: 761.9955390561773, val_loss: 661.6176235446006
Validation loss decreased (849.855889 --> 849.796769).  Saving model ...
Epoch 3185, train_loss: 764.4220284240756, val_loss: 673.9848874199615
Validation loss decreased (849.796769 --> 849.741569).  Saving model ...
Epoch 3186, train_loss: 763.0867313744087, val_loss: 694.6851252548566
Validation loss decreased (849.741569 --> 849.692900).  Saving model ...
Epoch 3187, train_loss: 766.7247661665806, val_loss: 655.5224685087472
Validation loss decreased (849.692900 --> 849.631975).  Saving model ...
Epoch 3188, train_loss: 761.0284067157743, val_loss: 681.9537268559804
Validation loss decreased (849.631975 --> 849.579378).  Saving model ...
Epoch 3189, train_loss: 767.557049764427, val_loss: 686.5441526525443
Validation loss decreased (849.579378 --> 849.528254).  Saving model ...
Epoch 3190, train_loss: 762.7223482864498, val_loss: 669.8540242690073
Validation loss decreased (849.528254 --> 849.471930).  Saving model ...
Epoch 3191, train_loss: 767.4571245506669, val_loss: 662.628126025421
Validation loss decreased (849.471930 --> 849.413376).  Saving model ...
Epoch 3192, train_loss: 757.1187783771736, val_loss: 672.8012747672093
Validation loss decreased (849.413376 --> 849.358047).  Saving model ...
Epoch 3193, train_loss: 766.3822679799104, val_loss: 665.3205280736312
Validation loss decreased (849.358047 --> 849.300409).  Saving model ...
Epoch 3194, train_loss: 768.1269356265555, val_loss: 691.7774685300063
Validation loss decreased (849.300409 --> 849.251090).  Saving model ...
Epoch 3195, train_loss: 768.9889692121673, val_loss: 665.7952403485447
Validation loss decreased (849.251090 --> 849.193671).  Saving model ...
Epoch 3196, train_loss: 762.4080386903146, val_loss: 681.0369903047551
Validation loss decreased (849.193671 --> 849.141056).  Saving model ...
Epoch 3197, train_loss: 767.9129045516587, val_loss: 677.7567896919453
Validation loss decreased (849.141056 --> 849.087448).  Saving model ...
Epoch 3198, train_loss: 765.1191991841011, val_loss: 648.1598355575735
Validation loss decreased (849.087448 --> 849.024619).  Saving model ...
Epoch 3199, train_loss: 762.0310526635868, val_loss: 682.450891504255
Validation loss decreased (849.024619 --> 848.972548).  Saving model ...
Epoch 3200, train_loss: 764.7423251488505, val_loss: 682.0782674451232
Validation loss decreased (848.972548 --> 848.920394).  Saving model ...
Epoch 3201, train_loss: 770.6900821692888, val_loss: 658.307002434201
Validation loss decreased (848.920394 --> 848.860846).  Saving model ...
Epoch 3202, train_loss: 756.8888779897914, val_loss: 665.8565307484293
Validation loss decreased (848.860846 --> 848.803693).  Saving model ...
Epoch 3203, train_loss: 769.4741808798639, val_loss: 674.2473061692056
Validation loss decreased (848.803693 --> 848.749195).  Saving model ...
Epoch 3204, train_loss: 763.9243641442148, val_loss: 642.6911540164996
Validation loss decreased (848.749195 --> 848.684882).  Saving model ...
Epoch 3205, train_loss: 762.4117103326273, val_loss: 681.8895247215147
Validation loss decreased (848.684882 --> 848.632840).  Saving model ...
Epoch 3206, train_loss: 765.3452589131919, val_loss: 669.5632382889481
Validation loss decreased (848.632840 --> 848.576985).  Saving model ...
Epoch 3207, train_loss: 765.7551488169471, val_loss: 674.8564952410375
Validation loss decreased (848.576985 --> 848.522816).  Saving model ...
Epoch 3208, train_loss: 761.1490602832879, val_loss: 676.2492714379235
Validation loss decreased (848.522816 --> 848.469115).  Saving model ...
Epoch 3209, train_loss: 760.301407472503, val_loss: 674.5206694623942
Validation loss decreased (848.469115 --> 848.414909).  Saving model ...
Epoch 3210, train_loss: 762.5744343578483, val_loss: 669.3924612294196
Validation loss decreased (848.414909 --> 848.359138).  Saving model ...
Epoch 3211, train_loss: 769.1308395951404, val_loss: 661.6750788935913
Validation loss decreased (848.359138 --> 848.301000).  Saving model ...
Epoch 3212, train_loss: 755.6948193529194, val_loss: 684.8697930957215
Validation loss decreased (848.301000 --> 848.250118).  Saving model ...
Epoch 3213, train_loss: 772.9207010082063, val_loss: 667.231019483209
Validation loss decreased (848.250118 --> 848.193778).  Saving model ...
Epoch 3214, train_loss: 763.3409113499703, val_loss: 673.7942827862615
Validation loss decreased (848.193778 --> 848.139516).  Saving model ...
Epoch 3215, train_loss: 762.3545677514195, val_loss: 678.8201690715777
Validation loss decreased (848.139516 --> 848.086851).  Saving model ...
Epoch 3216, train_loss: 761.8440652420941, val_loss: 667.0424999379563
Validation loss decreased (848.086851 --> 848.030556).  Saving model ...
Epoch 3217, train_loss: 764.4079762270327, val_loss: 676.2602886130417
Validation loss decreased (848.030556 --> 847.977161).  Saving model ...
Epoch 3218, train_loss: 769.808453204262, val_loss: 645.556214391126
Validation loss decreased (847.977161 --> 847.914258).  Saving model ...
Epoch 3219, train_loss: 759.9775112080048, val_loss: 661.1261997739698
Validation loss decreased (847.914258 --> 847.856232).  Saving model ...
Epoch 3220, train_loss: 759.1039905388676, val_loss: 669.1678177192259
Validation loss decreased (847.856232 --> 847.800738).  Saving model ...
Epoch 3221, train_loss: 761.2826864647022, val_loss: 673.4338918337451
Validation loss decreased (847.800738 --> 847.746604).  Saving model ...
Epoch 3222, train_loss: 764.9767461138011, val_loss: 689.6996675540346
Validation loss decreased (847.746604 --> 847.697552).  Saving model ...
Epoch 3223, train_loss: 761.2501982211206, val_loss: 671.5205911671346
Validation loss decreased (847.697552 --> 847.642889).  Saving model ...
Epoch 3224, train_loss: 763.1592489082215, val_loss: 674.4624342586048
Validation loss decreased (847.642889 --> 847.589173).  Saving model ...
Epoch 3225, train_loss: 766.6964900683708, val_loss: 671.6608360028271
Validation loss decreased (847.589173 --> 847.534622).  Saving model ...
Epoch 3226, train_loss: 756.5752403207642, val_loss: 654.067864032333
Validation loss decreased (847.534622 --> 847.474651).  Saving model ...
Epoch 3227, train_loss: 760.8094676011858, val_loss: 688.5172534518665
Validation loss decreased (847.474651 --> 847.425392).  Saving model ...
Epoch 3228, train_loss: 762.9145798215366, val_loss: 659.3597404649084
Validation loss decreased (847.425392 --> 847.367131).  Saving model ...
Epoch 3229, train_loss: 762.577854108772, val_loss: 658.9492342010143
Validation loss decreased (847.367131 --> 847.308780).  Saving model ...
Epoch 3230, train_loss: 763.9904157653518, val_loss: 667.7587273473986
Validation loss decreased (847.308780 --> 847.253191).  Saving model ...
Epoch 3231, train_loss: 764.0221981624944, val_loss: 657.0686288394754
Validation loss decreased (847.253191 --> 847.194329).  Saving model ...
Epoch 3232, train_loss: 755.95453326878, val_loss: 653.9610099774492
Validation loss decreased (847.194329 --> 847.134541).  Saving model ...
Epoch 3233, train_loss: 755.5529578872454, val_loss: 654.54152751618
Validation loss decreased (847.134541 --> 847.074970).  Saving model ...
Epoch 3234, train_loss: 761.4036661085095, val_loss: 674.1341259603813
Validation loss decreased (847.074970 --> 847.021495).  Saving model ...
Epoch 3235, train_loss: 761.0046459510137, val_loss: 667.9600658016076
Validation loss decreased (847.021495 --> 846.966143).  Saving model ...
Epoch 3236, train_loss: 760.5858897736805, val_loss: 663.4727249842333
Validation loss decreased (846.966143 --> 846.909439).  Saving model ...
Epoch 3237, train_loss: 759.5372046427925, val_loss: 663.5957579619358
Validation loss decreased (846.909439 --> 846.852809).  Saving model ...
Epoch 3238, train_loss: 759.1999390654856, val_loss: 684.0277381866291
Validation loss decreased (846.852809 --> 846.802523).  Saving model ...
Epoch 3239, train_loss: 757.5798912086075, val_loss: 679.1413453264814
Validation loss decreased (846.802523 --> 846.750760).  Saving model ...
Epoch 3240, train_loss: 766.5295574608134, val_loss: 667.710282604187
Validation loss decreased (846.750760 --> 846.695500).  Saving model ...
Epoch 3241, train_loss: 754.95257364453, val_loss: 652.261425767166
Validation loss decreased (846.695500 --> 846.635508).  Saving model ...
Epoch 3242, train_loss: 758.5128025500829, val_loss: 656.8556359582038
Validation loss decreased (846.635508 --> 846.576970).  Saving model ...
Epoch 3243, train_loss: 766.297547728877, val_loss: 658.0236410426103
Validation loss decreased (846.576970 --> 846.518829).  Saving model ...
Epoch 3244, train_loss: 766.0031636128386, val_loss: 655.8039617729631
Validation loss decreased (846.518829 --> 846.460039).  Saving model ...
Epoch 3245, train_loss: 755.9162068197949, val_loss: 659.011330293307
Validation loss decreased (846.460039 --> 846.402273).  Saving model ...
Epoch 3246, train_loss: 760.6002781695389, val_loss: 675.8050462970253
Validation loss decreased (846.402273 --> 846.349717).  Saving model ...
Epoch 3247, train_loss: 754.0247492559713, val_loss: 666.8204868902325
Validation loss decreased (846.349717 --> 846.294426).  Saving model ...
Epoch 3248, train_loss: 756.0505544605279, val_loss: 657.6535649678225
Validation loss decreased (846.294426 --> 846.236347).  Saving model ...
Epoch 3249, train_loss: 754.3399726688912, val_loss: 678.0812277085696
Validation loss decreased (846.236347 --> 846.184591).  Saving model ...
Epoch 3250, train_loss: 761.18631111764, val_loss: 664.1678995898259
Validation loss decreased (846.184591 --> 846.128586).  Saving model ...
Epoch 3251, train_loss: 756.2923643377305, val_loss: 660.4104733184314
Validation loss decreased (846.128586 --> 846.071460).  Saving model ...
Epoch 3252, train_loss: 762.1405837921944, val_loss: 647.1499622262962
Validation loss decreased (846.071460 --> 846.010291).  Saving model ...
Epoch 3253, train_loss: 755.3120876667181, val_loss: 662.7176014271934
Validation loss decreased (846.010291 --> 845.953945).  Saving model ...
Epoch 3254, train_loss: 761.9430310905148, val_loss: 670.9087288973843
Validation loss decreased (845.953945 --> 845.900151).  Saving model ...
Epoch 3255, train_loss: 759.7500082572077, val_loss: 671.8667286981921
Validation loss decreased (845.900151 --> 845.846685).  Saving model ...
Epoch 3256, train_loss: 761.4978715792694, val_loss: 677.8310417241305
Validation loss decreased (845.846685 --> 845.795083).  Saving model ...
Epoch 3257, train_loss: 762.1306066208934, val_loss: 665.1151542758835
Validation loss decreased (845.795083 --> 845.739609).  Saving model ...
Epoch 3258, train_loss: 762.5173889772132, val_loss: 668.0344819597959
Validation loss decreased (845.739609 --> 845.685064).  Saving model ...
Epoch 3259, train_loss: 759.4446283673308, val_loss: 674.8666048340889
Validation loss decreased (845.685064 --> 845.632650).  Saving model ...
Epoch 3260, train_loss: 752.7069063356114, val_loss: 661.2640659837814
Validation loss decreased (845.632650 --> 845.576095).  Saving model ...
Epoch 3261, train_loss: 759.4134628417972, val_loss: 675.2971932245629
Validation loss decreased (845.576095 --> 845.523878).  Saving model ...
Epoch 3262, train_loss: 764.6151995725355, val_loss: 662.8935483930622
Validation loss decreased (845.523878 --> 845.467891).  Saving model ...
Epoch 3263, train_loss: 753.2249880963799, val_loss: 669.412200984017
Validation loss decreased (845.467891 --> 845.413936).  Saving model ...
Epoch 3264, train_loss: 760.9478318674024, val_loss: 653.0877390087317
Validation loss decreased (845.413936 --> 845.355013).  Saving model ...
Epoch 3265, train_loss: 757.3364146060736, val_loss: 668.6171219158066
Validation loss decreased (845.355013 --> 845.300881).  Saving model ...
Epoch 3266, train_loss: 754.9234293860482, val_loss: 659.4203802733072
Validation loss decreased (845.300881 --> 845.243968).  Saving model ...
Epoch 3267, train_loss: 756.7662006406659, val_loss: 676.3550379966368
Validation loss decreased (845.243968 --> 845.192272).  Saving model ...
Epoch 3268, train_loss: 759.9639359464443, val_loss: 669.8883951314293
Validation loss decreased (845.192272 --> 845.138630).  Saving model ...
Epoch 3269, train_loss: 754.9442720534526, val_loss: 668.0402906649425
Validation loss decreased (845.138630 --> 845.084455).  Saving model ...
Epoch 3270, train_loss: 751.9815445475195, val_loss: 679.9250570213358
Validation loss decreased (845.084455 --> 845.033947).  Saving model ...
Epoch 3271, train_loss: 766.2222847233579, val_loss: 640.7084798307003
Validation loss decreased (845.033947 --> 844.971481).  Saving model ...
Epoch 3272, train_loss: 758.9766412359589, val_loss: 660.1519306550648
Validation loss decreased (844.971481 --> 844.914996).  Saving model ...
Epoch 3273, train_loss: 755.4513848543572, val_loss: 660.5404716158358
Validation loss decreased (844.914996 --> 844.858664).  Saving model ...
Epoch 3274, train_loss: 759.6379504372599, val_loss: 664.0425145812723
Validation loss decreased (844.858664 --> 844.803436).  Saving model ...
Epoch 3275, train_loss: 754.4654349316254, val_loss: 649.7556164722756
Validation loss decreased (844.803436 --> 844.743880).  Saving model ...
Epoch 3276, train_loss: 757.0292462801766, val_loss: 651.0768959512427
Validation loss decreased (844.743880 --> 844.684763).  Saving model ...
Epoch 3277, train_loss: 758.3866847450037, val_loss: 661.9090022515481
Validation loss decreased (844.684763 --> 844.628988).  Saving model ...
Epoch 3278, train_loss: 760.9293099588438, val_loss: 657.5670839131213
Validation loss decreased (844.628988 --> 844.571922).  Saving model ...
Epoch 3279, train_loss: 755.3160956723275, val_loss: 681.9226808539369
Validation loss decreased (844.571922 --> 844.522318).  Saving model ...
Epoch 3280, train_loss: 757.9569725202506, val_loss: 677.1581830708079
Validation loss decreased (844.522318 --> 844.471293).  Saving model ...
Epoch 3281, train_loss: 754.7377166484459, val_loss: 678.373541711448
Validation loss decreased (844.471293 --> 844.420669).  Saving model ...
Epoch 3282, train_loss: 761.8909996419609, val_loss: 656.5360983586756
Validation loss decreased (844.420669 --> 844.363422).  Saving model ...
Epoch 3283, train_loss: 747.0347974853721, val_loss: 666.0637817918375
Validation loss decreased (844.363422 --> 844.309112).  Saving model ...
Epoch 3284, train_loss: 760.4305524762545, val_loss: 653.4716860329999
Validation loss decreased (844.309112 --> 844.251000).  Saving model ...
Epoch 3285, train_loss: 763.4657940292207, val_loss: 665.7321692375787
Validation loss decreased (844.251000 --> 844.196657).  Saving model ...
Epoch 3286, train_loss: 759.1264917353437, val_loss: 659.420154235253
Validation loss decreased (844.196657 --> 844.140425).  Saving model ...
Epoch 3287, train_loss: 754.7426924111252, val_loss: 680.871496186014
Validation loss decreased (844.140425 --> 844.090754).  Saving model ...
Epoch 3288, train_loss: 752.8847477883126, val_loss: 643.2020437816009
Validation loss decreased (844.090754 --> 844.029657).  Saving model ...
Epoch 3289, train_loss: 755.1271051050475, val_loss: 674.5065168025542
Validation loss decreased (844.029657 --> 843.978114).  Saving model ...
Epoch 3290, train_loss: 759.29131020805, val_loss: 659.8979773667348
Validation loss decreased (843.978114 --> 843.922163).  Saving model ...
Epoch 3291, train_loss: 755.9539721191355, val_loss: 662.3956218291659
Validation loss decreased (843.922163 --> 843.867004).  Saving model ...
Epoch 3292, train_loss: 753.9714219202345, val_loss: 650.5501860059526
Validation loss decreased (843.867004 --> 843.808281).  Saving model ...
Epoch 3293, train_loss: 761.27826459456, val_loss: 673.7365980004054
Validation loss decreased (843.808281 --> 843.756635).  Saving model ...
Epoch 3294, train_loss: 763.6772252028085, val_loss: 664.5551025903118
Validation loss decreased (843.756635 --> 843.702232).  Saving model ...
Epoch 3295, train_loss: 764.5387043074006, val_loss: 646.0337976108441
Validation loss decreased (843.702232 --> 843.642242).  Saving model ...
Epoch 3296, train_loss: 757.4473615086912, val_loss: 668.0211783923488
Validation loss decreased (843.642242 --> 843.588959).  Saving model ...
Epoch 3297, train_loss: 751.904905470307, val_loss: 668.6669478201538
Validation loss decreased (843.588959 --> 843.535904).  Saving model ...
Epoch 3298, train_loss: 759.5589897878538, val_loss: 666.5822659690516
Validation loss decreased (843.535904 --> 843.482249).  Saving model ...
Epoch 3299, train_loss: 756.7881593173089, val_loss: 676.1475366072306
Validation loss decreased (843.482249 --> 843.431526).  Saving model ...
Epoch 3300, train_loss: 753.1668650175795, val_loss: 677.6163219596284
Validation loss decreased (843.431526 --> 843.381279).  Saving model ...
Epoch 3301, train_loss: 758.1164874141672, val_loss: 668.8164275781427
Validation loss decreased (843.381279 --> 843.328397).  Saving model ...
Epoch 3302, train_loss: 759.6762568073692, val_loss: 660.2328652050763
Validation loss decreased (843.328397 --> 843.272947).  Saving model ...
Epoch 3303, train_loss: 753.7798691087629, val_loss: 669.8754207926881
Validation loss decreased (843.272947 --> 843.220450).  Saving model ...
Epoch 3304, train_loss: 766.0706456814568, val_loss: 668.2510957282233
Validation loss decreased (843.220450 --> 843.167493).  Saving model ...
Epoch 3305, train_loss: 755.5524177262321, val_loss: 656.5790203425734
Validation loss decreased (843.167493 --> 843.111037).  Saving model ...
Epoch 3306, train_loss: 756.5618971434303, val_loss: 663.8104543046823
Validation loss decreased (843.111037 --> 843.056802).  Saving model ...
Epoch 3307, train_loss: 759.4055315935309, val_loss: 650.0311557530257
Validation loss decreased (843.056802 --> 842.998433).  Saving model ...
Epoch 3308, train_loss: 744.9465621727296, val_loss: 660.6641508354306
Validation loss decreased (842.998433 --> 842.943314).  Saving model ...
Epoch 3309, train_loss: 760.2484464420634, val_loss: 667.6882277142895
Validation loss decreased (842.943314 --> 842.890351).  Saving model ...
Epoch 3310, train_loss: 757.6122975116068, val_loss: 682.904097981586
Validation loss decreased (842.890351 --> 842.842016).  Saving model ...
Epoch 3311, train_loss: 760.667824697307, val_loss: 680.8328638358033
Validation loss decreased (842.842016 --> 842.793086).  Saving model ...
Epoch 3312, train_loss: 754.090334868161, val_loss: 659.0723214957674
Validation loss decreased (842.793086 --> 842.737615).  Saving model ...
Epoch 3313, train_loss: 750.6590973203992, val_loss: 680.5410204635731
Validation loss decreased (842.737615 --> 842.688657).  Saving model ...
Epoch 3314, train_loss: 759.230037573711, val_loss: 677.9725275950965
Validation loss decreased (842.688657 --> 842.638954).  Saving model ...
Epoch 3315, train_loss: 762.0383305860249, val_loss: 664.2506646002226
Validation loss decreased (842.638954 --> 842.585141).  Saving model ...
Epoch 3316, train_loss: 758.1357410793709, val_loss: 661.5246891706523
Validation loss decreased (842.585141 --> 842.530539).  Saving model ...
Epoch 3317, train_loss: 751.0636965610419, val_loss: 663.6348830637229
Validation loss decreased (842.530539 --> 842.476606).  Saving model ...
Epoch 3318, train_loss: 747.5259630945274, val_loss: 687.5681407918978
Validation loss decreased (842.476606 --> 842.429919).  Saving model ...
Epoch 3319, train_loss: 760.9117968675337, val_loss: 671.4515175322474
Validation loss decreased (842.429919 --> 842.378404).  Saving model ...
Epoch 3320, train_loss: 750.0040678428411, val_loss: 673.555237897105
Validation loss decreased (842.378404 --> 842.327554).  Saving model ...
Epoch 3321, train_loss: 758.9102331057263, val_loss: 649.0148466111117
Validation loss decreased (842.327554 --> 842.269344).  Saving model ...
Epoch 3322, train_loss: 752.6076783060671, val_loss: 667.4847788887006
Validation loss decreased (842.269344 --> 842.216730).  Saving model ...
Epoch 3323, train_loss: 752.5477026227738, val_loss: 667.7082799867572
Validation loss decreased (842.216730 --> 842.164215).  Saving model ...
Epoch 3324, train_loss: 747.1961071185709, val_loss: 665.928855756102
Validation loss decreased (842.164215 --> 842.111196).  Saving model ...
Epoch 3325, train_loss: 761.7802803011729, val_loss: 646.5953372247355
Validation loss decreased (842.111196 --> 842.052394).  Saving model ...
Epoch 3326, train_loss: 749.1650274831096, val_loss: 667.1950911483283
Validation loss decreased (842.052394 --> 841.999821).  Saving model ...
Epoch 3327, train_loss: 752.2765535732327, val_loss: 657.6524282102677
Validation loss decreased (841.999821 --> 841.944412).  Saving model ...
Epoch 3328, train_loss: 754.6640312211833, val_loss: 662.6004806930493
Validation loss decreased (841.944412 --> 841.890522).  Saving model ...
Epoch 3329, train_loss: 759.9959754877567, val_loss: 676.0747750184275
Validation loss decreased (841.890522 --> 841.840713).  Saving model ...
Epoch 3330, train_loss: 756.4567968651719, val_loss: 670.0099536727649
Validation loss decreased (841.840713 --> 841.789112).  Saving model ...
Epoch 3331, train_loss: 743.9410525531919, val_loss: 664.333632421803
Validation loss decreased (841.789112 --> 841.735838).  Saving model ...
Epoch 3332, train_loss: 754.8844608254557, val_loss: 663.6326262491173
Validation loss decreased (841.735838 --> 841.682386).  Saving model ...
Epoch 3333, train_loss: 758.1759316785418, val_loss: 664.0853480534867
Validation loss decreased (841.682386 --> 841.629101).  Saving model ...
Epoch 3334, train_loss: 751.0140153981312, val_loss: 654.1591043245686
Validation loss decreased (841.629101 --> 841.572871).  Saving model ...
Epoch 3335, train_loss: 754.6268647250374, val_loss: 667.8848948397023
Validation loss decreased (841.572871 --> 841.520791).  Saving model ...
Epoch 3336, train_loss: 760.1307126516222, val_loss: 650.0895718307412
Validation loss decreased (841.520791 --> 841.463408).  Saving model ...
Epoch 3337, train_loss: 743.6388710903293, val_loss: 647.357382810668
Validation loss decreased (841.463408 --> 841.405240).  Saving model ...
Epoch 3338, train_loss: 757.029511777984, val_loss: 652.5910748253932
Validation loss decreased (841.405240 --> 841.348675).  Saving model ...
Epoch 3339, train_loss: 750.6796899014097, val_loss: 656.438768959962
Validation loss decreased (841.348675 --> 841.293296).  Saving model ...
Epoch 3340, train_loss: 748.7466403412105, val_loss: 659.6725723855146
Validation loss decreased (841.293296 --> 841.238918).  Saving model ...
Epoch 3341, train_loss: 747.3490217383265, val_loss: 659.0099304176484
Validation loss decreased (841.238918 --> 841.184375).  Saving model ...
Epoch 3342, train_loss: 758.7181425575246, val_loss: 663.4355504077677
Validation loss decreased (841.184375 --> 841.131189).  Saving model ...
Epoch 3343, train_loss: 751.7023938045386, val_loss: 671.5836279492029
Validation loss decreased (841.131189 --> 841.080472).  Saving model ...
Epoch 3344, train_loss: 755.4599593004158, val_loss: 674.8450593143926
Validation loss decreased (841.080472 --> 841.030760).  Saving model ...
Epoch 3345, train_loss: 754.361480305556, val_loss: 663.6436664427324
Validation loss decreased (841.030760 --> 840.977730).  Saving model ...
Epoch 3346, train_loss: 750.8508330784325, val_loss: 638.967114397641
Validation loss decreased (840.977730 --> 840.917356).  Saving model ...
Epoch 3347, train_loss: 743.8554484369735, val_loss: 659.4259041933553
Validation loss decreased (840.917356 --> 840.863131).  Saving model ...
Epoch 3348, train_loss: 754.5005672905048, val_loss: 649.8496065170681
Validation loss decreased (840.863131 --> 840.806078).  Saving model ...
Epoch 3349, train_loss: 757.0294512923516, val_loss: 674.8794099295584
Validation loss decreased (840.806078 --> 840.756533).  Saving model ...
Epoch 3350, train_loss: 756.2316453722904, val_loss: 658.1853701807175
Validation loss decreased (840.756533 --> 840.702034).  Saving model ...
Epoch 3351, train_loss: 749.655824701228, val_loss: 646.8339635372387
Validation loss decreased (840.702034 --> 840.644180).  Saving model ...
Epoch 3352, train_loss: 754.0145889321124, val_loss: 664.8207988189992
Validation loss decreased (840.644180 --> 840.591727).  Saving model ...
Epoch 3353, train_loss: 753.8345271170516, val_loss: 637.0235665264951
Validation loss decreased (840.591727 --> 840.531014).  Saving model ...
Epoch 3354, train_loss: 751.9500510411909, val_loss: 643.5298926446068
Validation loss decreased (840.531014 --> 840.472278).  Saving model ...
Epoch 3355, train_loss: 749.2171811965037, val_loss: 644.8576401346705
Validation loss decreased (840.472278 --> 840.413973).  Saving model ...
Epoch 3356, train_loss: 743.8683931717233, val_loss: 653.6442626947169
Validation loss decreased (840.413973 --> 840.358320).  Saving model ...
Epoch 3357, train_loss: 745.962994223826, val_loss: 657.571554094178
Validation loss decreased (840.358320 --> 840.303871).  Saving model ...
Epoch 3358, train_loss: 761.8628699800312, val_loss: 670.4583071474459
Validation loss decreased (840.303871 --> 840.253292).  Saving model ...
Epoch 3359, train_loss: 749.8444743304606, val_loss: 671.5087102687143
Validation loss decreased (840.253292 --> 840.203055).  Saving model ...
Epoch 3360, train_loss: 759.8677088205816, val_loss: 664.7113973847366
Validation loss decreased (840.203055 --> 840.150825).  Saving model ...
Epoch 3361, train_loss: 756.829804336024, val_loss: 677.582248442615
Validation loss decreased (840.150825 --> 840.102456).  Saving model ...
Epoch 3362, train_loss: 752.383720414279, val_loss: 657.6889259326462
Validation loss decreased (840.102456 --> 840.048199).  Saving model ...
Epoch 3363, train_loss: 752.4594863705851, val_loss: 652.8591111378762
Validation loss decreased (840.048199 --> 839.992537).  Saving model ...
Epoch 3364, train_loss: 750.0924861362879, val_loss: 667.1661599346227
Validation loss decreased (839.992537 --> 839.941162).  Saving model ...
Epoch 3365, train_loss: 753.0419179510293, val_loss: 659.9391041137116
Validation loss decreased (839.941162 --> 839.887670).  Saving model ...
Epoch 3366, train_loss: 759.9519802179786, val_loss: 650.0466973224397
Validation loss decreased (839.887670 --> 839.831270).  Saving model ...
Epoch 3367, train_loss: 745.1604817249263, val_loss: 648.3798324760688
Validation loss decreased (839.831270 --> 839.774409).  Saving model ...
Epoch 3368, train_loss: 749.9472937940478, val_loss: 681.6735155277566
Validation loss decreased (839.774409 --> 839.727467).  Saving model ...
Epoch 3369, train_loss: 744.6667809632339, val_loss: 661.951262085416
Validation loss decreased (839.727467 --> 839.674699).  Saving model ...
Epoch 3370, train_loss: 757.910386633571, val_loss: 654.4420180383439
Validation loss decreased (839.674699 --> 839.619734).  Saving model ...
Epoch 3371, train_loss: 746.7485377642133, val_loss: 680.4380196518595
Validation loss decreased (839.619734 --> 839.572513).  Saving model ...
Epoch 3372, train_loss: 748.6069554146292, val_loss: 659.1656844577749
Validation loss decreased (839.572513 --> 839.519011).  Saving model ...
Epoch 3373, train_loss: 756.6967390658673, val_loss: 636.2528828990132
Validation loss decreased (839.519011 --> 839.458748).  Saving model ...
Epoch 3374, train_loss: 752.503829392781, val_loss: 646.6629069616071
Validation loss decreased (839.458748 --> 839.401607).  Saving model ...
Epoch 3375, train_loss: 751.1813948800974, val_loss: 673.9760664938008
Validation loss decreased (839.401607 --> 839.352592).  Saving model ...
Epoch 3376, train_loss: 754.2024290372754, val_loss: 651.401755086493
Validation loss decreased (839.352592 --> 839.296919).  Saving model ...
Epoch 3377, train_loss: 750.1263026198649, val_loss: 660.9561772012714
Validation loss decreased (839.296919 --> 839.244109).  Saving model ...
Epoch 3378, train_loss: 745.9953149912587, val_loss: 642.2790757760741
Validation loss decreased (839.244109 --> 839.185801).  Saving model ...
Epoch 3379, train_loss: 746.6186677094358, val_loss: 672.4874650726279
Validation loss decreased (839.185801 --> 839.136467).  Saving model ...
Epoch 3380, train_loss: 751.9224133012931, val_loss: 666.759166925561
Validation loss decreased (839.136467 --> 839.085468).  Saving model ...
Epoch 3381, train_loss: 746.2290238166553, val_loss: 658.6323663990701
Validation loss decreased (839.085468 --> 839.032095).  Saving model ...
Epoch 3382, train_loss: 752.0413171093587, val_loss: 654.5154781953609
Validation loss decreased (839.032095 --> 838.977537).  Saving model ...
Epoch 3383, train_loss: 751.9946691669882, val_loss: 651.7595000065261
Validation loss decreased (838.977537 --> 838.922196).  Saving model ...
Epoch 3384, train_loss: 744.898470232406, val_loss: 663.0624781960915
Validation loss decreased (838.922196 --> 838.870228).  Saving model ...
Epoch 3385, train_loss: 750.9280745817645, val_loss: 645.4260773418463
Validation loss decreased (838.870228 --> 838.813080).  Saving model ...
Epoch 3386, train_loss: 743.9930809230646, val_loss: 676.0642155720794
Validation loss decreased (838.813080 --> 838.765015).  Saving model ...
Epoch 3387, train_loss: 754.645659999257, val_loss: 651.1260456464471
Validation loss decreased (838.765015 --> 838.709615).  Saving model ...
Epoch 3388, train_loss: 748.1915710251725, val_loss: 644.5628712818914
Validation loss decreased (838.709615 --> 838.652311).  Saving model ...
Epoch 3389, train_loss: 743.9063212724524, val_loss: 665.115002150514
Validation loss decreased (838.652311 --> 838.601105).  Saving model ...
Epoch 3390, train_loss: 750.8381243275177, val_loss: 651.7727017627826
Validation loss decreased (838.601105 --> 838.545993).  Saving model ...
Epoch 3391, train_loss: 749.5143092350743, val_loss: 644.1200992470984
Validation loss decreased (838.545993 --> 838.488658).  Saving model ...
Epoch 3392, train_loss: 745.8461896009452, val_loss: 660.3467569481668
Validation loss decreased (838.488658 --> 838.436139).  Saving model ...
Epoch 3393, train_loss: 751.9838880528363, val_loss: 673.2553115597702
Validation loss decreased (838.436139 --> 838.387457).  Saving model ...
Epoch 3394, train_loss: 753.2089669505068, val_loss: 664.1462536781478
Validation loss decreased (838.387457 --> 838.336119).  Saving model ...
Epoch 3395, train_loss: 748.9410892081423, val_loss: 656.0578028058678
Validation loss decreased (838.336119 --> 838.282428).  Saving model ...
Epoch 3396, train_loss: 752.693422593874, val_loss: 647.8544218557194
Validation loss decreased (838.282428 --> 838.226354).  Saving model ...
Epoch 3397, train_loss: 749.7004695245671, val_loss: 669.3326350269718
Validation loss decreased (838.226354 --> 838.176636).  Saving model ...
Epoch 3398, train_loss: 751.5455489026059, val_loss: 665.2537577955152
Validation loss decreased (838.176636 --> 838.125746).  Saving model ...
Epoch 3399, train_loss: 751.9640959889623, val_loss: 645.6756986809444
Validation loss decreased (838.125746 --> 838.069126).  Saving model ...
Epoch 3400, train_loss: 745.0659029368111, val_loss: 669.7202088146522
Validation loss decreased (838.069126 --> 838.019612).  Saving model ...
Epoch 3401, train_loss: 745.0316898338768, val_loss: 649.8813718680656
Validation loss decreased (838.019612 --> 837.964293).  Saving model ...
Epoch 3402, train_loss: 745.2270690424257, val_loss: 655.4118523752472
Validation loss decreased (837.964293 --> 837.910633).  Saving model ...
Epoch 3403, train_loss: 745.9770537019059, val_loss: 652.678624327139
Validation loss decreased (837.910633 --> 837.856201).  Saving model ...
Epoch 3404, train_loss: 745.3689031629439, val_loss: 670.9389409343627
Validation loss decreased (837.856201 --> 837.807166).  Saving model ...
Epoch 3405, train_loss: 751.9628748356263, val_loss: 679.3320430167631
Validation loss decreased (837.807166 --> 837.760624).  Saving model ...
Epoch 3406, train_loss: 747.971409038389, val_loss: 657.9576279469226
Validation loss decreased (837.760624 --> 837.707834).  Saving model ...
Epoch 3407, train_loss: 746.991186401253, val_loss: 675.3629259739545
Validation loss decreased (837.707834 --> 837.660183).  Saving model ...
Epoch 3408, train_loss: 750.7935467097799, val_loss: 651.1186140434613
Validation loss decreased (837.660183 --> 837.605447).  Saving model ...
Epoch 3409, train_loss: 748.1541381386206, val_loss: 648.3609035068645
Validation loss decreased (837.605447 --> 837.549934).  Saving model ...
Epoch 3410, train_loss: 747.1693728989128, val_loss: 667.7313258514806
Validation loss decreased (837.549934 --> 837.500133).  Saving model ...
Epoch 3411, train_loss: 741.7707768861098, val_loss: 673.569170627749
Validation loss decreased (837.500133 --> 837.452074).  Saving model ...
Epoch 3412, train_loss: 741.1640924779158, val_loss: 676.0842746733741
Validation loss decreased (837.452074 --> 837.404780).  Saving model ...
Epoch 3413, train_loss: 753.8328404154306, val_loss: 655.0272061114182
Validation loss decreased (837.404780 --> 837.351344).  Saving model ...
Epoch 3414, train_loss: 756.2337951712045, val_loss: 677.5525226414871
Validation loss decreased (837.351344 --> 837.304537).  Saving model ...
Epoch 3415, train_loss: 751.2362974352244, val_loss: 665.5871292099582
Validation loss decreased (837.304537 --> 837.254253).  Saving model ...
Epoch 3416, train_loss: 753.159951537899, val_loss: 645.8070451821887
Validation loss decreased (837.254253 --> 837.198209).  Saving model ...
Epoch 3417, train_loss: 743.609207037474, val_loss: 670.7704232207939
Validation loss decreased (837.198209 --> 837.149503).  Saving model ...
Epoch 3418, train_loss: 750.547962604487, val_loss: 670.8739107542792
Validation loss decreased (837.149503 --> 837.100856).  Saving model ...
Epoch 3419, train_loss: 748.6254355008683, val_loss: 662.8438625375985
Validation loss decreased (837.100856 --> 837.049889).  Saving model ...
Epoch 3420, train_loss: 747.7466984334609, val_loss: 659.9343499987659
Validation loss decreased (837.049889 --> 836.998101).  Saving model ...
Epoch 3421, train_loss: 748.4987020824682, val_loss: 647.8653515499503
Validation loss decreased (836.998101 --> 836.942815).  Saving model ...
Epoch 3422, train_loss: 745.70577189906, val_loss: 643.6624279890572
Validation loss decreased (836.942815 --> 836.886333).  Saving model ...
Epoch 3423, train_loss: 746.0839781195665, val_loss: 672.0204648958096
Validation loss decreased (836.886333 --> 836.838169).  Saving model ...
Epoch 3424, train_loss: 751.9088066716571, val_loss: 667.8186483931767
Validation loss decreased (836.838169 --> 836.788806).  Saving model ...
Epoch 3425, train_loss: 745.366977825735, val_loss: 628.173752532381
Validation loss decreased (836.788806 --> 836.727897).  Saving model ...
Epoch 3426, train_loss: 751.7244103796475, val_loss: 650.4667743381751
Validation loss decreased (836.727897 --> 836.673530).  Saving model ...
Epoch 3427, train_loss: 745.7422551830157, val_loss: 669.9941355708356
Validation loss decreased (836.673530 --> 836.624892).  Saving model ...
Epoch 3428, train_loss: 746.7064743103946, val_loss: 644.5871530303032
Validation loss decreased (836.624892 --> 836.568872).  Saving model ...
Epoch 3429, train_loss: 741.9963671939934, val_loss: 651.7031353399714
Validation loss decreased (836.568872 --> 836.514960).  Saving model ...
Epoch 3430, train_loss: 754.6985281670935, val_loss: 647.1253276196236
Validation loss decreased (836.514960 --> 836.459744).  Saving model ...
Epoch 3431, train_loss: 739.5169952876413, val_loss: 671.0436565728104
Validation loss decreased (836.459744 --> 836.411532).  Saving model ...
Epoch 3432, train_loss: 744.3850938121865, val_loss: 648.0410618680719
Validation loss decreased (836.411532 --> 836.356645).  Saving model ...
Epoch 3433, train_loss: 745.3347468068266, val_loss: 631.4255368182288
Validation loss decreased (836.356645 --> 836.296951).  Saving model ...
Epoch 3434, train_loss: 745.3191855285395, val_loss: 665.838959012054
Validation loss decreased (836.296951 --> 836.247313).  Saving model ...
Epoch 3435, train_loss: 742.2308424183501, val_loss: 671.266730594768
Validation loss decreased (836.247313 --> 836.199283).  Saving model ...
Epoch 3436, train_loss: 739.8905906658812, val_loss: 672.8561071436718
Validation loss decreased (836.199283 --> 836.151745).  Saving model ...
Epoch 3437, train_loss: 741.9679651526301, val_loss: 665.2759263981717
Validation loss decreased (836.151745 --> 836.102028).  Saving model ...
Epoch 3438, train_loss: 746.9524311571826, val_loss: 650.8342605007582
Validation loss decreased (836.102028 --> 836.048140).  Saving model ...
Epoch 3439, train_loss: 745.6225501900022, val_loss: 650.9518441591664
Validation loss decreased (836.048140 --> 835.994317).  Saving model ...
Epoch 3440, train_loss: 746.760124662476, val_loss: 652.3200965084857
Validation loss decreased (835.994317 --> 835.940923).  Saving model ...
Epoch 3441, train_loss: 743.3679332589121, val_loss: 651.213982785477
Validation loss decreased (835.940923 --> 835.887239).  Saving model ...
Epoch 3442, train_loss: 745.7271869847193, val_loss: 649.4211131857505
Validation loss decreased (835.887239 --> 835.833065).  Saving model ...
Epoch 3443, train_loss: 751.0696306305605, val_loss: 645.314590418891
Validation loss decreased (835.833065 --> 835.777730).  Saving model ...
Epoch 3444, train_loss: 747.1501746485553, val_loss: 645.9703505360202
Validation loss decreased (835.777730 --> 835.722618).  Saving model ...
Epoch 3445, train_loss: 736.2057646958854, val_loss: 646.6487330651287
Validation loss decreased (835.722618 --> 835.667734).  Saving model ...
Epoch 3446, train_loss: 744.3302785178681, val_loss: 666.2862319856887
Validation loss decreased (835.667734 --> 835.618581).  Saving model ...
Epoch 3447, train_loss: 743.9384866985205, val_loss: 682.1131021873381
Validation loss decreased (835.618581 --> 835.574048).  Saving model ...
Epoch 3448, train_loss: 748.5179577002947, val_loss: 680.8843301998028
Validation loss decreased (835.574048 --> 835.529185).  Saving model ...
Epoch 3449, train_loss: 741.2560288329271, val_loss: 671.7208347769362
Validation loss decreased (835.529185 --> 835.481690).  Saving model ...
Epoch 3450, train_loss: 749.3106761100731, val_loss: 652.9739982231462
Validation loss decreased (835.481690 --> 835.428789).  Saving model ...
Epoch 3451, train_loss: 746.6541364956505, val_loss: 634.9004933410887
Validation loss decreased (835.428789 --> 835.370682).  Saving model ...
Epoch 3452, train_loss: 745.5470843044238, val_loss: 677.573053140718
Validation loss decreased (835.370682 --> 835.324970).  Saving model ...
Epoch 3453, train_loss: 743.9841648210105, val_loss: 664.0704835158149
Validation loss decreased (835.324970 --> 835.275374).  Saving model ...
Epoch 3454, train_loss: 745.0149946183129, val_loss: 651.2285953393251
Validation loss decreased (835.275374 --> 835.222089).  Saving model ...
Epoch 3455, train_loss: 745.4498431192815, val_loss: 658.7611119264369
Validation loss decreased (835.222089 --> 835.171015).  Saving model ...
Epoch 3456, train_loss: 744.9591632863679, val_loss: 642.0991268993753
Validation loss decreased (835.171015 --> 835.115149).  Saving model ...
Epoch 3457, train_loss: 745.9465542460019, val_loss: 644.5127794207802
Validation loss decreased (835.115149 --> 835.060014).  Saving model ...
Epoch 3458, train_loss: 744.2771390599215, val_loss: 642.0145429766955
Validation loss decreased (835.060014 --> 835.004188).  Saving model ...
Epoch 3459, train_loss: 746.3997290615041, val_loss: 675.8501502203504
Validation loss decreased (835.004188 --> 834.958177).  Saving model ...
Epoch 3460, train_loss: 746.1914489944226, val_loss: 636.6139656345716
Validation loss decreased (834.958177 --> 834.900852).  Saving model ...
Epoch 3461, train_loss: 745.8042660080016, val_loss: 663.8203693704146
Validation loss decreased (834.900852 --> 834.851421).  Saving model ...
Epoch 3462, train_loss: 742.5905639024594, val_loss: 657.0024919117385
Validation loss decreased (834.851421 --> 834.800049).  Saving model ...
Epoch 3463, train_loss: 736.9700045255556, val_loss: 653.3473026408757
Validation loss decreased (834.800049 --> 834.747652).  Saving model ...
Epoch 3464, train_loss: 740.7511091467337, val_loss: 642.8259300510534
Validation loss decreased (834.747652 --> 834.692247).  Saving model ...
Epoch 3465, train_loss: 740.4370665100895, val_loss: 632.8292301594664
Validation loss decreased (834.692247 --> 834.633989).  Saving model ...
Epoch 3466, train_loss: 744.9562337132253, val_loss: 637.5590048787885
Validation loss decreased (834.633989 --> 834.577130).  Saving model ...
Epoch 3467, train_loss: 744.8738426028111, val_loss: 655.7684826039609
Validation loss decreased (834.577130 --> 834.525555).  Saving model ...
Epoch 3468, train_loss: 746.6910437011404, val_loss: 650.835551853931
Validation loss decreased (834.525555 --> 834.472588).  Saving model ...
Epoch 3469, train_loss: 740.1125424048859, val_loss: 675.2905661050373
Validation loss decreased (834.472588 --> 834.426701).  Saving model ...
Epoch 3470, train_loss: 741.9686117393059, val_loss: 658.3268828741273
Validation loss decreased (834.426701 --> 834.375952).  Saving model ...
Epoch 3471, train_loss: 745.4848639124353, val_loss: 645.506294401178
Validation loss decreased (834.375952 --> 834.321538).  Saving model ...
Epoch 3472, train_loss: 739.999887014735, val_loss: 656.0571432397546
Validation loss decreased (834.321538 --> 834.270195).  Saving model ...
Epoch 3473, train_loss: 741.1459995628808, val_loss: 655.851019518972
Validation loss decreased (834.270195 --> 834.218822).  Saving model ...
Epoch 3474, train_loss: 737.9783205743527, val_loss: 645.4842766529766
Validation loss decreased (834.218822 --> 834.164494).  Saving model ...
Epoch 3475, train_loss: 746.1361475024481, val_loss: 638.1927167148507
Validation loss decreased (834.164494 --> 834.108099).  Saving model ...
Epoch 3476, train_loss: 747.8075548380067, val_loss: 656.6589505170676
Validation loss decreased (834.108099 --> 834.057050).  Saving model ...
Epoch 3477, train_loss: 744.4896520315967, val_loss: 655.2687029322213
Validation loss decreased (834.057050 --> 834.005629).  Saving model ...
Epoch 3478, train_loss: 743.9397679260773, val_loss: 656.9311168023396
Validation loss decreased (834.005629 --> 833.954716).  Saving model ...
Epoch 3479, train_loss: 744.976083716684, val_loss: 645.697772898233
Validation loss decreased (833.954716 --> 833.900604).  Saving model ...
Epoch 3480, train_loss: 740.5717805317281, val_loss: 649.3263779103098
Validation loss decreased (833.900604 --> 833.847566).  Saving model ...
Epoch 3481, train_loss: 744.0365887929547, val_loss: 677.2142828521247
Validation loss decreased (833.847566 --> 833.802569).  Saving model ...
Epoch 3482, train_loss: 741.437999935713, val_loss: 651.992336392668
Validation loss decreased (833.802569 --> 833.750355).  Saving model ...
Epoch 3483, train_loss: 741.7128060084627, val_loss: 642.4034259639187
Validation loss decreased (833.750355 --> 833.695417).  Saving model ...
Epoch 3484, train_loss: 737.5453253088764, val_loss: 649.2925402797817
Validation loss decreased (833.695417 --> 833.642489).  Saving model ...
Epoch 3485, train_loss: 740.0635204774173, val_loss: 639.8047137944349
Validation loss decreased (833.642489 --> 833.586868).  Saving model ...
Epoch 3486, train_loss: 739.3760487995485, val_loss: 639.8027144770384
Validation loss decreased (833.586868 --> 833.531279).  Saving model ...
Epoch 3487, train_loss: 745.7932782813408, val_loss: 655.9523787221206
