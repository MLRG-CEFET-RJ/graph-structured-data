{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# NUMBER_NODES = 10\n",
    "# NUMBER_NODES = 9\n",
    "NUMBER_NODES = 7\n",
    "# NUMBER_NODES = 5\n",
    "# DATASET_PATH = f'./opt_band_{NUMBER_NODES}_nodes_graph.csv'\n",
    "DATASET_PATH = f'../../../../datasets/examples/opt_band_{NUMBER_NODES}_nodes_graph.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        image = image / 255\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(annotations_file='./annotations_file_train.csv', img_dir='./dataset_7')\n",
    "val_data = CustomImageDataset(annotations_file='./annotations_file_val.csv', img_dir='./dataset_val_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArray(strArray):\n",
    "    arr = strArray.split('.')\n",
    "    first = strArray[1]\n",
    "    arr = [first, *arr[1 : -1]] # skip '[' and ']'\n",
    "    arr = list(map(lambda x: int(x.strip()), arr))\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 32, 32])\n",
      "tensor([0, 2, 2, 1])\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(2) tensor(2) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(type(images))\n",
    "print(type(images[0]))\n",
    "print(type(images[0][0]))\n",
    "print(images[0].shape)\n",
    "print(labels)\n",
    "print(labels[0])\n",
    "\n",
    "# # show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(288.)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLoss,self).__init__()\n",
    "    \n",
    "    def loss_repeated_labels(self, output):\n",
    "      used_labels, counts = torch.unique(output, return_counts=True)\n",
    "      counts = counts.type(torch.DoubleTensor)\n",
    "      diffLabelCounts = (output.shape[0] - counts.shape[0])**2\n",
    "      sampleVariance = torch.var(counts, unbiased=False)\n",
    "\n",
    "      if diffLabelCounts == 0 and sampleVariance != 0:\n",
    "          diffLabelCounts = 1\n",
    "      if sampleVariance == 0 and diffLabelCounts != 0:\n",
    "          sampleVariance = 1\n",
    "      return sampleVariance * diffLabelCounts\n",
    "\n",
    "    def forward(self, output, target):\n",
    "      loss_mse = ((output - target[1:])**2).mean()\n",
    "      roundedOutput = output.round()\n",
    "      loss_repeated = self.loss_repeated_labels(roundedOutput)\n",
    "      if loss_mse == 0 and loss_repeated != 0:\n",
    "        loss_mse = 1\n",
    "      if loss_repeated == 0 and loss_mse != 0:\n",
    "        loss_repeated = 1\n",
    "      return loss_mse * loss_repeated\n",
    "\n",
    "teste = CustomLoss()\n",
    "y_pred = torch.tensor([1., 1., 1., 1., 1., 1., 1.])\n",
    "#y_pred = torch.tensor([0., 1., 1., 2., 2., 3., 1.])\n",
    "#y_pred = torch.tensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "y_true = torch.tensor([0., 0., 1., 2., 3., 4., 5., 6.])\n",
    "teste.forward(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, epoch):\n",
    "    # criterion = CustomLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        for input, target in zip(X, y):\n",
    "            pred = model(X)\n",
    "            one = torch.nn.functional.one_hot(target, num_classes=3)\n",
    "            one = one.type(torch.float32)\n",
    "            print(pred)\n",
    "            print(one)\n",
    "            loss = criterion(pred, one)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    return (train_loss / len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 50, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(50, 30, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3000, 120)\n",
    "        # 1x1600 and 13456x120\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0117, -0.0959, -0.0619], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0117, -0.0956, -0.0619], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0116, -0.0952, -0.0619], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0118, -0.0949, -0.0619], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0112, -0.0991, -0.0597], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0114, -0.0989, -0.0595], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0118, -0.0987, -0.0593], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0121, -0.0985, -0.0589], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0201, -0.0968, -0.0551], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0203, -0.0963, -0.0548], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0205, -0.0959, -0.0544], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0206, -0.0953, -0.0541], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0053, -0.0948, -0.0575], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0056, -0.0941, -0.0572], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0058, -0.0932, -0.0569], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0059, -0.0922, -0.0567], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0131, -0.0888, -0.0589], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0135, -0.0882, -0.0586], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0141, -0.0876, -0.0582], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0146, -0.0871, -0.0578], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0051, -0.0889, -0.0547], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0055, -0.0884, -0.0540], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0060, -0.0879, -0.0533], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0066, -0.0875, -0.0523], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0139, -0.0897, -0.0530], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0144, -0.0891, -0.0522], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0148, -0.0887, -0.0511], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0155, -0.0882, -0.0502], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0202, -0.0966, -0.0399], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0207, -0.0962, -0.0390], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0215, -0.0958, -0.0381], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0225, -0.0955, -0.0372], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0251, -0.0810, -0.0468], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0255, -0.0804, -0.0463], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0258, -0.0798, -0.0456], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0264, -0.0793, -0.0451], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0156, -0.0885, -0.0397], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0161, -0.0881, -0.0387], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0166, -0.0877, -0.0376], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0170, -0.0871, -0.0366], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0150, -0.0814, -0.0345], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0155, -0.0807, -0.0338], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0159, -0.0798, -0.0331], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0165, -0.0790, -0.0324], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0392, -0.0845, -0.0368], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0399, -0.0839, -0.0364], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0404, -0.0831, -0.0360], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0409, -0.0824, -0.0354], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0277, -0.0762, -0.0425], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0283, -0.0756, -0.0418], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0289, -0.0751, -0.0410], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0293, -0.0744, -0.0402], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0277, -0.0716, -0.0354], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0282, -0.0708, -0.0349], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0287, -0.0700, -0.0344], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0292, -0.0692, -0.0337], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0290, -0.0780, -0.0292], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0295, -0.0773, -0.0287], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0299, -0.0767, -0.0281], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0305, -0.0761, -0.0275], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0336, -0.0773, -0.0345], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0342, -0.0767, -0.0340], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0348, -0.0759, -0.0336], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0355, -0.0752, -0.0333], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0499, -0.0663, -0.0351], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0505, -0.0658, -0.0343], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0512, -0.0655, -0.0336], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0519, -0.0651, -0.0327], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0335, -0.0657, -0.0186], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0340, -0.0649, -0.0180], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0348, -0.0642, -0.0175], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0354, -0.0633, -0.0170], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0399, -0.0655, -0.0294], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0402, -0.0647, -0.0291], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0407, -0.0639, -0.0288], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0411, -0.0633, -0.0284], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0431, -0.0528, -0.0208], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0434, -0.0520, -0.0203], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0437, -0.0512, -0.0199], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0439, -0.0503, -0.0195], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0489, -0.0562, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0496, -0.0555, -0.0125], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0503, -0.0548, -0.0119], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0512, -0.0543, -0.0113], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0446, -0.0505, -0.0096], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0451, -0.0499, -0.0090], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0458, -0.0493, -0.0085], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0467, -0.0489, -0.0079], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0406, -0.0497, -0.0212], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0413, -0.0491, -0.0207], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0421, -0.0486, -0.0203], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0429, -0.0479, -0.0199], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0595, -0.0535, -0.0155], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0605, -0.0531, -0.0150], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0615, -0.0524, -0.0146], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0623, -0.0517, -0.0140], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0399, -0.0479, -0.0193], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0405, -0.0472, -0.0190], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0414, -0.0466, -0.0186], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0422, -0.0461, -0.0181], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0620, -0.0487, -0.0219], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0625, -0.0480, -0.0216], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0630, -0.0474, -0.0211], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0635, -0.0468, -0.0204], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0606, -0.0426, -0.0009], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0613, -0.0420, -0.0001], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0618, -0.0413,  0.0006], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0623, -0.0406,  0.0015], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0631, -0.0375,  0.0007], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0635, -0.0370,  0.0017], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0639, -0.0366,  0.0028], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0645, -0.0362,  0.0039], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0570, -0.0445, -0.0118], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0574, -0.0442, -0.0109], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0577, -0.0437, -0.0101], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0580, -0.0432, -0.0092], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0558, -0.0514, -0.0003], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0562, -0.0511,  0.0008], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0565, -0.0508,  0.0020], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0569, -0.0503,  0.0031], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0632, -0.0385,  0.0171], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0638, -0.0381,  0.0181], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0646, -0.0378,  0.0190], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0654, -0.0373,  0.0198], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0688, -0.0424, -0.0005], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 6.9599e-02, -4.2025e-02,  8.0656e-05], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0706, -0.0417,  0.0006], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0714, -0.0414,  0.0013], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0689, -0.0237,  0.0094], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0696, -0.0232,  0.0102], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0705, -0.0227,  0.0109], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0713, -0.0221,  0.0115], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0806, -0.0251,  0.0092], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0812, -0.0242,  0.0097], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0821, -0.0234,  0.0102], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0829, -0.0226,  0.0109], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0864, -0.0345,  0.0300], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0869, -0.0335,  0.0305], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0873, -0.0323,  0.0310], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0881, -0.0313,  0.0314], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0909, -0.0262,  0.0200], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0913, -0.0253,  0.0205], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0917, -0.0245,  0.0211], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0919, -0.0235,  0.0217], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0781, -0.0263,  0.0188], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0788, -0.0257,  0.0193], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0795, -0.0251,  0.0199], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0804, -0.0245,  0.0205], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.1009, -0.0197,  0.0220], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.1018, -0.0192,  0.0225], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.1026, -0.0187,  0.0233], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.1032, -0.0181,  0.0240], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0915, -0.0129,  0.0283], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0919, -0.0123,  0.0290], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0923, -0.0117,  0.0299], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0927, -0.0112,  0.0310], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0766, -0.0054,  0.0288], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0771, -0.0050,  0.0298], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0775, -0.0047,  0.0310], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0779, -0.0042,  0.0320], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0847, -0.0172,  0.0197], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0852, -0.0166,  0.0204], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0855, -0.0159,  0.0210], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0861, -0.0153,  0.0216], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0860, -0.0077,  0.0294], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0868, -0.0072,  0.0301], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0878, -0.0068,  0.0308], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0887, -0.0065,  0.0317], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0989, -0.0060,  0.0416], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0995, -0.0056,  0.0424], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.1004, -0.0053,  0.0432], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.1015, -0.0050,  0.0439], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.0963, -0.0028,  0.0382], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0972, -0.0024,  0.0388], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.0980, -0.0019,  0.0393], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.0987, -0.0014,  0.0400], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1110, 0.0016, 0.0536], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1116, 0.0021, 0.0545], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1124, 0.0025, 0.0555], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1135, 0.0028, 0.0564], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1099, 0.0016, 0.0438], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1105, 0.0022, 0.0445], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1111, 0.0028, 0.0454], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1115, 0.0036, 0.0462], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.1058, -0.0006,  0.0480], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1061, 0.0001, 0.0489], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1067, 0.0007, 0.0497], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1072, 0.0016, 0.0504], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.1270, -0.0018,  0.0700], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.1276, -0.0013,  0.0708], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.1283, -0.0008,  0.0718], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.1289, -0.0003,  0.0731], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([ 0.1207, -0.0015,  0.0453], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([ 0.1211, -0.0008,  0.0463], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([ 0.1217, -0.0003,  0.0473], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1223, 0.0005, 0.0481], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1122, 0.0060, 0.0559], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1124, 0.0068, 0.0565], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1129, 0.0075, 0.0570], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1134, 0.0082, 0.0578], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1221, 0.0130, 0.0588], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1227, 0.0135, 0.0597], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1236, 0.0139, 0.0606], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1243, 0.0146, 0.0613], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1249, 0.0157, 0.0684], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1253, 0.0165, 0.0690], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1255, 0.0176, 0.0694], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1260, 0.0185, 0.0699], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1149, 0.0231, 0.0665], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1155, 0.0237, 0.0672], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1160, 0.0245, 0.0679], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1164, 0.0253, 0.0688], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1244, 0.0244, 0.0706], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1248, 0.0250, 0.0718], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1251, 0.0258, 0.0728], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1254, 0.0265, 0.0740], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1263, 0.0217, 0.0747], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1267, 0.0222, 0.0758], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1272, 0.0226, 0.0771], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1276, 0.0230, 0.0784], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1148, 0.0187, 0.0671], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1153, 0.0192, 0.0681], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1158, 0.0196, 0.0692], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1163, 0.0202, 0.0703], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1247, 0.0308, 0.0820], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1252, 0.0312, 0.0832], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1256, 0.0316, 0.0845], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1261, 0.0319, 0.0859], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1385, 0.0253, 0.0843], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1387, 0.0260, 0.0854], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1392, 0.0266, 0.0863], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1400, 0.0271, 0.0872], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1317, 0.0183, 0.0860], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1321, 0.0189, 0.0868], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1325, 0.0195, 0.0879], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1329, 0.0202, 0.0888], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1254, 0.0207, 0.0608], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1257, 0.0212, 0.0620], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1259, 0.0219, 0.0629], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1261, 0.0225, 0.0641], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1325, 0.0392, 0.1050], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1326, 0.0399, 0.1063], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1330, 0.0405, 0.1074], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1334, 0.0410, 0.1087], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1351, 0.0349, 0.1021], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1353, 0.0356, 0.1033], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1355, 0.0365, 0.1043], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1359, 0.0373, 0.1053], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1229, 0.0420, 0.1138], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1232, 0.0426, 0.1151], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1239, 0.0431, 0.1163], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1245, 0.0436, 0.1177], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1365, 0.0444, 0.1120], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1369, 0.0448, 0.1136], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1377, 0.0451, 0.1151], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1384, 0.0453, 0.1167], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1404, 0.0404, 0.1091], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1411, 0.0406, 0.1105], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1422, 0.0408, 0.1118], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1431, 0.0412, 0.1130], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1495, 0.0461, 0.1336], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1506, 0.0464, 0.1349], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1519, 0.0467, 0.1360], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1534, 0.0469, 0.1371], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1669, 0.0441, 0.1571], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1684, 0.0446, 0.1580], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1701, 0.0450, 0.1589], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1717, 0.0453, 0.1600], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1481, 0.0408, 0.1216], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1491, 0.0410, 0.1227], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1500, 0.0412, 0.1240], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1511, 0.0413, 0.1252], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1565, 0.0516, 0.1314], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1572, 0.0522, 0.1324], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1578, 0.0529, 0.1332], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1582, 0.0539, 0.1339], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1622, 0.0432, 0.1471], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1625, 0.0441, 0.1480], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1626, 0.0452, 0.1487], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1625, 0.0465, 0.1493], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1703, 0.0507, 0.1629], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1709, 0.0516, 0.1634], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1716, 0.0524, 0.1642], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1725, 0.0530, 0.1650], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1812, 0.0503, 0.1602], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1817, 0.0512, 0.1610], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1826, 0.0520, 0.1617], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1832, 0.0530, 0.1623], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1628, 0.0500, 0.1471], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1631, 0.0510, 0.1477], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1634, 0.0519, 0.1486], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1636, 0.0530, 0.1493], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1939, 0.0737, 0.1853], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1946, 0.0745, 0.1864], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1957, 0.0752, 0.1874], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1964, 0.0762, 0.1882], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1759, 0.0771, 0.1722], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1768, 0.0778, 0.1731], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1775, 0.0786, 0.1739], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1781, 0.0794, 0.1750], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1845, 0.0644, 0.1852], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1849, 0.0654, 0.1863], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1857, 0.0663, 0.1872], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1865, 0.0671, 0.1885], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1874, 0.0774, 0.1630], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1879, 0.0782, 0.1642], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1883, 0.0788, 0.1656], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1887, 0.0794, 0.1672], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1898, 0.0789, 0.1898], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1906, 0.0794, 0.1915], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1911, 0.0802, 0.1930], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1920, 0.0808, 0.1943], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1954, 0.0847, 0.2011], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1959, 0.0856, 0.2024], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1968, 0.0862, 0.2036], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1977, 0.0868, 0.2051], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1930, 0.0872, 0.2016], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1933, 0.0884, 0.2026], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1937, 0.0894, 0.2038], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1941, 0.0903, 0.2054], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1990, 0.0896, 0.1902], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1999, 0.0902, 0.1913], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2006, 0.0911, 0.1922], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2012, 0.0919, 0.1935], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1941, 0.0870, 0.2087], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1952, 0.0874, 0.2101], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1962, 0.0879, 0.2118], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1975, 0.0882, 0.2134], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2063, 0.0931, 0.2233], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2081, 0.0933, 0.2245], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2102, 0.0933, 0.2257], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2121, 0.0934, 0.2272], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1868, 0.0896, 0.1869], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1879, 0.0899, 0.1882], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1890, 0.0902, 0.1897], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1899, 0.0906, 0.1914], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1954, 0.0856, 0.1873], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1964, 0.0858, 0.1889], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1976, 0.0859, 0.1903], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1988, 0.0860, 0.1920], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2057, 0.0930, 0.2155], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2064, 0.0938, 0.2168], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2069, 0.0948, 0.2178], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2073, 0.0958, 0.2191], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2168, 0.0938, 0.2288], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2173, 0.0948, 0.2298], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2175, 0.0961, 0.2306], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2180, 0.0971, 0.2313], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2111, 0.1052, 0.2265], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2112, 0.1067, 0.2269], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2112, 0.1083, 0.2272], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2109, 0.1102, 0.2272], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2155, 0.1005, 0.2177], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2157, 0.1016, 0.2180], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2157, 0.1029, 0.2183], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2156, 0.1044, 0.2184], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2005, 0.0896, 0.2009], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2001, 0.0913, 0.2008], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1998, 0.0928, 0.2011], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1995, 0.0942, 0.2018], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1963, 0.1009, 0.2011], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1962, 0.1022, 0.2015], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1960, 0.1037, 0.2018], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1958, 0.1051, 0.2025], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2204, 0.1284, 0.2557], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2199, 0.1302, 0.2560], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2195, 0.1319, 0.2568], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2192, 0.1333, 0.2579], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2093, 0.1302, 0.2280], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2087, 0.1319, 0.2286], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2081, 0.1334, 0.2296], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2076, 0.1349, 0.2308], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2236, 0.1375, 0.2491], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2232, 0.1386, 0.2509], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2229, 0.1397, 0.2531], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2227, 0.1407, 0.2554], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2200, 0.1444, 0.2784], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2202, 0.1454, 0.2802], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2208, 0.1461, 0.2818], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2211, 0.1472, 0.2830], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1736, 0.1072, 0.1833], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.1742, 0.1077, 0.1840], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1749, 0.1081, 0.1849], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1755, 0.1085, 0.1861], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2034, 0.1304, 0.2465], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2045, 0.1308, 0.2479], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2059, 0.1310, 0.2492], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2071, 0.1315, 0.2502], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2276, 0.1551, 0.2782], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2284, 0.1558, 0.2794], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2296, 0.1563, 0.2805], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2306, 0.1568, 0.2819], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2492, 0.1639, 0.3181], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2501, 0.1647, 0.3190], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2514, 0.1653, 0.3197], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2522, 0.1663, 0.3201], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.1990, 0.1079, 0.2068], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1995, 0.1086, 0.2072], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.1998, 0.1096, 0.2075], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2000, 0.1104, 0.2081], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2411, 0.1627, 0.2981], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2422, 0.1634, 0.2987], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2430, 0.1643, 0.2990], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2441, 0.1650, 0.2991], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2292, 0.1580, 0.2615], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2301, 0.1589, 0.2614], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2308, 0.1596, 0.2618], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2316, 0.1602, 0.2626], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2399, 0.1558, 0.2795], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2409, 0.1563, 0.2806], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2422, 0.1566, 0.2814], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2434, 0.1569, 0.2827], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2392, 0.1651, 0.3030], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2406, 0.1653, 0.3043], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2419, 0.1654, 0.3060], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2428, 0.1660, 0.3074], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2368, 0.1606, 0.2651], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2371, 0.1615, 0.2657], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2373, 0.1623, 0.2668], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2380, 0.1630, 0.2677], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2666, 0.1729, 0.3144], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2676, 0.1734, 0.3155], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2682, 0.1742, 0.3163], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2688, 0.1750, 0.3175], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2330, 0.1464, 0.2612], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2338, 0.1468, 0.2623], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2349, 0.1470, 0.2633], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2363, 0.1471, 0.2641], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2454, 0.1623, 0.2881], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2468, 0.1624, 0.2894], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2481, 0.1625, 0.2909], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2490, 0.1630, 0.2921], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2452, 0.1589, 0.2641], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2459, 0.1593, 0.2656], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2469, 0.1595, 0.2669], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2482, 0.1597, 0.2680], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2582, 0.1671, 0.2988], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2588, 0.1678, 0.2995], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2598, 0.1683, 0.3001], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2607, 0.1688, 0.3011], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2679, 0.1683, 0.3230], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2687, 0.1690, 0.3235], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2691, 0.1701, 0.3237], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2692, 0.1714, 0.3236], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2513, 0.1751, 0.2871], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2513, 0.1762, 0.2872], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2513, 0.1773, 0.2878], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2514, 0.1782, 0.2888], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2582, 0.1745, 0.2828], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2581, 0.1755, 0.2839], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2581, 0.1765, 0.2853], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2584, 0.1772, 0.2866], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2710, 0.1864, 0.3102], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2708, 0.1876, 0.3108], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2707, 0.1886, 0.3118], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2705, 0.1895, 0.3132], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2578, 0.1969, 0.3180], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2575, 0.1980, 0.3195], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2572, 0.1989, 0.3213], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2570, 0.1998, 0.3234], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2433, 0.1737, 0.2887], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2427, 0.1748, 0.2897], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2426, 0.1757, 0.2906], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2429, 0.1764, 0.2914], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2685, 0.2078, 0.3485], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2686, 0.2084, 0.3502], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2684, 0.2094, 0.3514], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2681, 0.2103, 0.3531], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2623, 0.2083, 0.3473], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2618, 0.2096, 0.3480], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2613, 0.2107, 0.3491], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2612, 0.2116, 0.3500], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2355, 0.1989, 0.3152], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2358, 0.1995, 0.3162], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2361, 0.2000, 0.3176], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2363, 0.2004, 0.3194], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2648, 0.2190, 0.3838], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2654, 0.2195, 0.3849], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2659, 0.2199, 0.3865], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2660, 0.2207, 0.3875], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2154, 0.1587, 0.2767], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2158, 0.1591, 0.2775], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2160, 0.1597, 0.2782], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2165, 0.1602, 0.2787], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2707, 0.2033, 0.3545], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2720, 0.2036, 0.3549], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2728, 0.2042, 0.3549], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2732, 0.2051, 0.3547], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2245, 0.1668, 0.2830], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2255, 0.1671, 0.2827], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2264, 0.1675, 0.2829], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2276, 0.1677, 0.2830], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2834, 0.2089, 0.3666], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2841, 0.2096, 0.3668], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2846, 0.2103, 0.3675], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2858, 0.2105, 0.3679], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2402, 0.1857, 0.2939], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2412, 0.1859, 0.2945], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2421, 0.1860, 0.2955], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2428, 0.1864, 0.2962], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2961, 0.2294, 0.3843], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2970, 0.2297, 0.3853], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2979, 0.2299, 0.3868], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2983, 0.2305, 0.3878], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.3019, 0.2344, 0.3909], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.3016, 0.2356, 0.3910], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.3019, 0.2364, 0.3907], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.3027, 0.2369, 0.3902], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2714, 0.2151, 0.3467], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2716, 0.2159, 0.3466], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2721, 0.2165, 0.3464], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2723, 0.2173, 0.3459], grad_fn=<AddBackward0>)\n",
      "tensor([1., 0., 0.])\n",
      "tensor([0.2964, 0.2431, 0.3972], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0.2965, 0.2441, 0.3964], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 1.])\n",
      "tensor([0.2966, 0.2450, 0.3961], grad_fn=<AddBackward0>)\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GUILHE~1\\AppData\\Local\\Temp/ipykernel_13180/1376059799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mlist_train_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\GUILHE~1\\AppData\\Local\\Temp/ipykernel_13180/3344669658.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer, epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(train_dataloader, model, optimizer, epoch)\n",
    "    list_train_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_train_loss, label='Training Loss')\n",
    "plt.plot(list_val_loss, label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss average per batch')\n",
    "plt.savefig(os.path.join(os.path.dirname(__file__), 'loss3.jpg'))\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test dataloader\")\n",
    "for x, y in test_dataloader:\n",
    "  print(x.shape)\n",
    "  pred = model(x).round()\n",
    "  print(\"=============\")\n",
    "  print('pred:', pred)\n",
    "  print('y:', y[:,1:])\n",
    "  break\n",
    "print(\"Train dataloader\")\n",
    "for x, y in train_dataloader:\n",
    "  print(x.shape)\n",
    "  pred = model(x).round()\n",
    "  print(\"=============\")\n",
    "  print('pred:', pred)\n",
    "  print('y:', y[:,1:])\n",
    "  break\n",
    "# load the last checkpoint with the best model\n",
    "# model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c5b3efaa918d9f28db231eb82daaaf5f44447677f2df3439a28b7e91ebffcf4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
