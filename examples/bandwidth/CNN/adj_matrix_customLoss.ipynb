{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.python.ops import gen_array_ops\n",
    "from PIL import Image\n",
    "\n",
    "# the file remains as the same, but get different data (to be compared and calculates bandwidth mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_NODES = 7\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(os.path.join('..', 'DNN', 'datasets', f'dataset_{NUMBER_NODES}_train.csv'))\n",
    "    val_df = pd.read_csv(os.path.join('..', 'DNN', 'datasets', f'dataset_{NUMBER_NODES}_val.csv'))\n",
    "    test_df = pd.read_csv(os.path.join('..', 'DNN', 'datasets', f'dataset_{NUMBER_NODES}_test.csv'))\n",
    "\n",
    "    featuresNumber = (NUMBER_NODES * NUMBER_NODES - NUMBER_NODES) // 2 \n",
    "    def get_tuple_tensor_dataset(row):\n",
    "        X = row[0 : featuresNumber].astype('float32')\n",
    "        Y = row[featuresNumber + 1: ].astype('float32') # Pula a banda otima na posicao 0\n",
    "        return X, Y\n",
    "\n",
    "    train_dataset = list(map(get_tuple_tensor_dataset, train_df.to_numpy()))\n",
    "    val_dataset = list(map(get_tuple_tensor_dataset, val_df.to_numpy()))\n",
    "    test_dataset = list(map(get_tuple_tensor_dataset, test_df.to_numpy()))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in train_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_train = np.array(X)\n",
    "    y_train = np.array(Y)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in test_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_test = np.array(X)\n",
    "    y_test = np.array(Y)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in val_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_val = np.array(X)\n",
    "    y_val = np.array(Y)\n",
    "\n",
    "    x_train = np.concatenate((x_train, x_val))\n",
    "    y_train = np.concatenate((y_train, y_val))\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, x_t, y_t = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraph(upperTriangleAdjMatrix):\n",
    "    dense_adj = np.zeros((NUMBER_NODES, NUMBER_NODES))\n",
    "    k = 0\n",
    "    for i in range(NUMBER_NODES):\n",
    "        for j in range(NUMBER_NODES):\n",
    "            if i == j:\n",
    "                continue\n",
    "            elif i < j:\n",
    "                dense_adj[i][j] = upperTriangleAdjMatrix[k]\n",
    "                k += 1\n",
    "            else:\n",
    "                dense_adj[i][j] = dense_adj[j][i]\n",
    "    return dense_adj\n",
    "\n",
    "def processDataToAdjImage(graphInput):\n",
    "    adj = getGraph(graphInput)\n",
    "    w, h = NUMBER_NODES, NUMBER_NODES\n",
    "    data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for i in range(len(adj)):\n",
    "        for j in range(len(adj)):\n",
    "            if adj[i, j] == 1:\n",
    "                data[i, j] = np.array([255.0, 255.0, 255.0])\n",
    "    img = Image.fromarray(data, 'RGB')\n",
    "    resized = img.resize((NUMBER_NODES * 4, NUMBER_NODES * 4), Image.NEAREST)\n",
    "    image_input_np = np.array(resized)\n",
    "    return image_input_np\n",
    "# def processDataToImage(graphInput):\n",
    "#     graph_adj = getGraph(graphInput)\n",
    "#     plt.imshow(graph_adj, cmap=\"gray\")\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.savefig(f'./Graph_adj_input_mse.png')\n",
    "#     plt.clf()\n",
    "#     image_input = tf.keras.preprocessing.image.load_img(f'./Graph_adj_input_mse.png')\n",
    "#     image_input_arr = tf.keras.preprocessing.image.img_to_array(image_input)\n",
    "#     image_input_np = np.array(image_input_arr)\n",
    "#     # image_input_np = image_input_np / 255.0\n",
    "\n",
    "#     image_input_np = tf.image.resize(image_input_np, [32, 32])\n",
    "#     return image_input_np\n",
    "print(getGraph(X[0]).astype(np.int32))\n",
    "img = processDataToAdjImage(X[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData_2(features, labels):\n",
    "    train_images = []\n",
    "    train_nodelist = []\n",
    "    for graphInput, target in zip(features, labels):\n",
    "        graphNodeList = target\n",
    "        x_image = processDataToAdjImage(graphInput)\n",
    "        train_images.append(x_image)\n",
    "        train_nodelist.append(graphNodeList)\n",
    "    # mlb = MultiLabelBinarizer()\n",
    "    # labels = mlb.fit_transform(train_nodelist)\n",
    "    return np.array(train_images), np.array(train_nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = getData_2(X, y)\n",
    "x_test, y_test = getData_2(x_t, y_t)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(X_train)\n",
    "it2 = iter(X)\n",
    "entry = next(it)\n",
    "entry2 = next(it2)\n",
    "getGraph(entry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(entry)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is to show an example of the custom loss\n",
    "def body_example(i, acc, out):\n",
    "  used_labels, indexes, counts = tf.unique_with_counts(out[i])\n",
    "  counts = tf.cast(counts, tf.float32)\n",
    "  variance = tf.math.reduce_variance(counts)\n",
    "  return (i + 1, tf.add(acc, variance), out)\n",
    "\n",
    "def loss_repeated_labels_example(roundedOutput):\n",
    "  acc = tf.constant(0, dtype=tf.float32)\n",
    "  out = roundedOutput\n",
    "  batch_size = tf.shape(roundedOutput)[0]\n",
    "\n",
    "  i = tf.constant(0)\n",
    "  c = lambda i, acc, out: tf.less(i, batch_size)\n",
    "  b = body_example\n",
    "  r = tf.while_loop(c, b, loop_vars=[i, acc, out])\n",
    "  return r\n",
    "\n",
    "output = tf.constant([[1, 2, 1], [3, 4, 3]])\n",
    "output[0]\n",
    "\n",
    "i, loss, out = loss_repeated_labels_example(output)\n",
    "print(i)\n",
    "print(loss)\n",
    "print(out)\n",
    "\n",
    "used_labels, indexes, counts1 = tf.unique_with_counts(output[0])\n",
    "used_labels, indexes, counts2 = tf.unique_with_counts(output[1])\n",
    "counts1 = tf.cast(counts1, tf.float32)\n",
    "counts2 = tf.cast(counts2, tf.float32)\n",
    "variance1 = tf.math.reduce_variance(counts1)\n",
    "variance2 = tf.math.reduce_variance(counts2)\n",
    "print(variance1)\n",
    "print(variance2)\n",
    "print(tf.add(variance1, variance2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "mseLoss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def loss_repeated_labels(roundedOutput):\n",
    "  def body(i, acc, out):\n",
    "    used_labels, indexes, counts = tf.unique_with_counts(out[i])\n",
    "    counts = tf.cast(counts, tf.float32)\n",
    "    # variance = tf.math.reduce_variance(counts)\n",
    "    # return (i + 1, tf.add(acc, variance), out)\n",
    "    counts_shape = tf.shape(counts)[0]\n",
    "    mse = mseLoss(tf.ones(counts_shape), counts)\n",
    "    return (i + 1, tf.add(acc, mse), out)\n",
    "  \n",
    "  acc = tf.constant(0, dtype=tf.float32)\n",
    "  out = roundedOutput\n",
    "  batch_size = tf.shape(out)[0]\n",
    "\n",
    "  i = tf.constant(0)\n",
    "  condition = lambda i, acc, out: tf.less(i, batch_size)\n",
    "  b = body\n",
    "  result = tf.while_loop(condition, b, loop_vars=[i, acc, out])\n",
    "  return result\n",
    "\n",
    "def custom_loss(true, pred):\n",
    "  mse = mseLoss(true, pred)\n",
    "  roundedOutput = tf.round(pred)\n",
    "  i, loss_repeated, roundedOutput = loss_repeated_labels(roundedOutput)\n",
    "  return mse + loss_repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  data_augmentation, # with aug mean band = 4.571428571428571, without = 4.603174603174603\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(NUMBER_NODES)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=custom_loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=128,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    # to_file='model.png',\n",
    "    rankdir='LR',\n",
    "    show_shapes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_repeats(output):\n",
    "    counts = np.unique(np.round(output))\n",
    "    repeated = NUMBER_NODES - counts.shape[0]\n",
    "    return repeated\n",
    "\n",
    "def get_valid_pred(pred):\n",
    "    valid = np.ones(NUMBER_NODES)\n",
    "    labels = np.arange(0, NUMBER_NODES)\n",
    "    for i in labels:\n",
    "        min_value = np.amin(pred)\n",
    "        min_idx = np.where(pred == min_value)\n",
    "        pred[min_idx] = 100\n",
    "        valid[min_idx] = i\n",
    "    return valid\n",
    "    \n",
    "def get_bandwidth(Graph, nodelist):\n",
    "    Graph = nx.Graph(Graph)\n",
    "    if not Graph.edges:\n",
    "        return 0\n",
    "    if nodelist.all() != None:\n",
    "        L = nx.laplacian_matrix(Graph, nodelist=nodelist)\n",
    "    else:\n",
    "        L = nx.laplacian_matrix(Graph)\n",
    "    x, y = np.nonzero(L)\n",
    "    return (x-y).max()\n",
    "\n",
    "def get_array_from_image(graphnp):\n",
    "    img = Image.fromarray(graphnp, 'RGB')\n",
    "    img = img.convert('L')\n",
    "    resized = img.resize((NUMBER_NODES, NUMBER_NODES), Image.NEAREST)\n",
    "    image_input_np = np.array(resized)\n",
    "    return image_input_np / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "sumTest_original = []\n",
    "sumTest_pred = []\n",
    "sumTest_true = []\n",
    "\n",
    "count = 0\n",
    "cases_with_repetition = 0\n",
    "\n",
    "start = time.time()\n",
    "for i in range(len(pred)):\n",
    "    output = pred[i]\n",
    "    quantity_repeated = count_repeats(np.round(output))\n",
    "    print('Pred: ', output)\n",
    "    print('True: ', y_test[i])\n",
    "    if quantity_repeated != 0:\n",
    "        cases_with_repetition += 1\n",
    "    output = get_valid_pred(output)\n",
    "    print('Pred valid: ', output)\n",
    "    count += quantity_repeated\n",
    "\n",
    "    graph = get_array_from_image(x_test[i])\n",
    "\n",
    "    original_band = get_bandwidth(graph, np.array(None))\n",
    "    sumTest_original.append(original_band)\n",
    "\n",
    "    pred_band = get_bandwidth(graph, output)\n",
    "    sumTest_pred.append(pred_band)\n",
    "\n",
    "    true_band = get_bandwidth(graph, y_test[i])\n",
    "    sumTest_true.append(true_band)\n",
    "\n",
    "    # print(\"Bandwidth\")\n",
    "    # print(original_band)\n",
    "    # print(pred_band)\n",
    "    # print(true_band)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de rótulos repetidos, exemplo [1, 1, 1, 1, 1, 1, 1] conta como 6 - ', count)\n",
    "print('Quantidade de saídas com repetição, exemplo [1, 1, 1, 1, 1, 1, 1] conta como 1 - ', cases_with_repetition)\n",
    "test_length = pred.shape[0]\n",
    "print('Test length - ', test_length)\n",
    "print('Time- ', (end - start) / test_length)\n",
    "\n",
    "print(\"Bandwidth mean±std\")\n",
    "print(f'{np.mean(sumTest_original)}±{np.std(sumTest_original)}')\n",
    "print(\"Pred bandwidth mean±std\")\n",
    "print(f'{np.mean(sumTest_pred)}±{np.std(sumTest_pred)}')\n",
    "print(\"True bandwidth mean±std\")\n",
    "print(f'{np.mean(sumTest_true)}±{np.std(sumTest_true)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9eba946ae18c2fd52bd7ee0675653c9ba3cc2017ffd7c41149393a04d904615d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
