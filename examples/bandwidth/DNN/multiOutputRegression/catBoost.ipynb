{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_NODES = 7\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_train.csv'))\n",
    "    val_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_val.csv'))\n",
    "    test_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_test.csv'))\n",
    "\n",
    "    featuresNumber = (NUMBER_NODES * NUMBER_NODES - NUMBER_NODES) // 2 \n",
    "    def get_tuple_tensor_dataset(row):\n",
    "        X = row[0 : featuresNumber].astype('int32')\n",
    "        Y = row[featuresNumber + 1: ].astype('int32') # Inclui a banda otima na posicao 0\n",
    "        return X, Y\n",
    "\n",
    "    train_dataset = list(map(get_tuple_tensor_dataset, train_df.to_numpy()))\n",
    "    val_dataset = list(map(get_tuple_tensor_dataset, val_df.to_numpy()))\n",
    "    test_dataset = list(map(get_tuple_tensor_dataset, test_df.to_numpy()))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in train_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_train = np.array(X)\n",
    "    y_train = np.array(Y)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in test_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_test = np.array(X)\n",
    "    y_test = np.array(Y)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in val_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_val = np.array(X)\n",
    "    y_val = np.array(Y)\n",
    "\n",
    "    x_train = np.concatenate((x_train, x_val))\n",
    "    y_train = np.concatenate((y_train, y_val))\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, x_t, y_t = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.9685372\ttotal: 9.62ms\tremaining: 9.61s\n",
      "100:\tlearn: 4.2595071\ttotal: 1.36s\tremaining: 12.1s\n",
      "200:\tlearn: 3.9160863\ttotal: 2.67s\tremaining: 10.6s\n",
      "300:\tlearn: 3.6589244\ttotal: 4.02s\tremaining: 9.34s\n",
      "400:\tlearn: 3.4594657\ttotal: 5.37s\tremaining: 8.02s\n",
      "500:\tlearn: 3.2926053\ttotal: 6.74s\tremaining: 6.71s\n",
      "600:\tlearn: 3.1553447\ttotal: 8.09s\tremaining: 5.37s\n",
      "700:\tlearn: 3.0330676\ttotal: 9.43s\tremaining: 4.02s\n",
      "800:\tlearn: 2.9279096\ttotal: 10.7s\tremaining: 2.67s\n",
      "900:\tlearn: 2.8332496\ttotal: 12.1s\tremaining: 1.33s\n",
      "999:\tlearn: 2.7492686\ttotal: 13.4s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2f401375e80>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# cat_features is the categorical features indices\n",
    "\n",
    "model = CatBoostRegressor(objective='MultiRMSE', verbose=100)\n",
    "model.fit(X, y, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.45526307 1.30165131 4.07261749 3.93628902 5.25165878 2.03353679\n",
      " 2.94898353]\n",
      "[1. 1. 4. 4. 5. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = model.predict(x_t)\n",
    "print(a[1])\n",
    "print(np.round(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def count_repeats(output):\n",
    "    x = [x for x in output if x > 6]\n",
    "    greaterSix = len(x)\n",
    "    true_shape = NUMBER_NODES\n",
    "    counts = np.unique(np.round(output))\n",
    "    repeated = true_shape - counts.shape[0]\n",
    "    return repeated, greaterSix\n",
    "\n",
    "count = 0\n",
    "greaterSix = 0\n",
    "for i in a:\n",
    "    c, g = count_repeats(i)\n",
    "    count += c\n",
    "    greaterSix += g\n",
    "print(count)\n",
    "print(greaterSix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com repetição - 185\n"
     ]
    }
   ],
   "source": [
    "print(f\"Com repetição - {count}\") \n",
    "# 185, 1 com mais dados\n",
    "# 144, 24 com mais dados e 10k"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f17ea74e9a07f02efaa90ee1f47e0c923e4f633c8e0a68dd26777c24f53b763"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
