{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# https://medium.com/analytics-vidhya/gradient-boost-decomposition-pytorch-optimization-sklearn-decision-tree-regressor-41a3d0cb9bb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling cuda availability\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "if USE_CUDA:\n",
    "    torch.cuda.set_device(gpus[0])\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunctionMinimizer(nn.Module):\n",
    "    def __init__(self, type):\n",
    "        # type can be one of the 2 : \"regressor\" or \"classifier\"\n",
    "        super(LossFunctionMinimizer, self).__init__()\n",
    "        self.type = type\n",
    "        self.current_leaf_value = nn.Parameter(data=FloatTensor([0.0]), requires_grad=True)\n",
    "    def reinitialize_variable(self):\n",
    "        self.current_leaf_value.data = FloatTensor([0.0])\n",
    "    def refine_previous_predictions(self, previous_predictions):\n",
    "        new_predictions = previous_predictions + self.current_leaf_value\n",
    "        return new_predictions\n",
    "    def loss(self, previous_predictions, targets_leaf_tensor):\n",
    "        if self.type == \"regressor\":\n",
    "            return self.loss_regressor(previous_predictions, targets_leaf_tensor)\n",
    "        elif self.type == \"classifier\":\n",
    "            return self.loss_classifier(previous_predictions, targets_leaf_tensor)\n",
    "        else:\n",
    "            raise Exception(\"Not supported\")\n",
    "    def loss_classifier(self, previous_predictions, targets_leaf_tensor):\n",
    "        logodds = self.refine_previous_predictions(previous_predictions)\n",
    "        probabilities = 1.0 / (1.0 + torch.exp(-logodds))\n",
    "        loss = F.binary_cross_entropy(probabilities, targets_leaf_tensor)\n",
    "        return loss\n",
    "    def loss_regressor(self, previous_predictions, targets_leaf_tensor):\n",
    "        values = self.refine_previous_predictions(previous_predictions)\n",
    "        loss = F.mse_loss(values, targets_leaf_tensor)\n",
    "        return loss     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What are the residuals ???\n",
    "We have a loss function : Loss(prediction_1, prediction_2, ....., prediction_m), m : number of training points\n",
    "Going back to the definition of the partial derivative/gradient with respect to a parameter, it is the change incurred to \n",
    "the loss function if we change by a little bit the parameter\n",
    "So, the array of partial derivatives tells us how the Loss changes by changes in the predictions\n",
    "It makes sense to group predictions with the same / similar effect !!!\n",
    "This is the heart of the algorithm and explains why the algorithm builds regression trees around the residuals/partial derivatives\n",
    "In my opinion, the term residuals is not that correct! The term gradient should be used instead to allow for the understanding of the algorithm rational.\n",
    "'''\n",
    "class ResidualsCalculator(nn.Module):\n",
    "    def __init__(self, predicted_values, type):\n",
    "        super(ResidualsCalculator, self).__init__()\n",
    "        self.type = type\n",
    "        self.predicted_values = nn.Parameter(data=torch.zeros(predicted_values.shape), requires_grad=True)\n",
    "        self.predicted_values.data = predicted_values\n",
    "    def forward(self):\n",
    "        my_parameters = self.predicted_values\n",
    "        return my_parameters\n",
    "    def loss(self, targets):\n",
    "        if self.type == \"regressor\":\n",
    "            return self.loss_regressor(targets)\n",
    "        elif self.type == \"classifier\":\n",
    "            return self.loss_classifier(targets)\n",
    "        else:\n",
    "            raise Exception(\"Not supported\")\n",
    "    def loss_classifier(self, targets):\n",
    "        logodds = self.forward()\n",
    "        probabilities = 1.0 / (1.0 + torch.exp(-logodds))\n",
    "        loss = F.binary_cross_entropy(probabilities, targets)\n",
    "        return loss\n",
    "    def loss_regressor(self, targets):\n",
    "        values = self.forward()\n",
    "        loss = F.mse_loss(values, targets)\n",
    "        return loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression_tree_classifier_to_residuals(X_data, y_data, max_depth): # y_data -> residuals\n",
    "    tree_regressor = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    tree_regressor.fit(X_data, y_data)\n",
    "    leaf_buckets = []\n",
    "    for i in range(X_data.shape[0]):\n",
    "        leaf_buckets.append(tuple(tree_regressor.decision_path(X_data[i, :].reshape(1, -1)).todok().keys()))\n",
    "    unique_paths = list(set(leaf_buckets))\n",
    "    return (leaf_buckets, unique_paths, tree_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the pieces together\n",
    "class PytorchBasedGenericGradientBoost():\n",
    "    def __init__(self, type, n_trees, max_depth, GRADIENT_BOOST_LEARNING_RATE = 0.1, MINIMIZER_LEARNING_RATE = 0.001, MINIMIZER_TRAINING_EPOCHS = 100):\n",
    "        '''\n",
    "        type : \"regressor\" or \"classifier\"\n",
    "        '''\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.type = type\n",
    "        self.gradient_boost_learning_rate = GRADIENT_BOOST_LEARNING_RATE\n",
    "        self.minimizer_learning_rate = MINIMIZER_LEARNING_RATE\n",
    "        self.minimizer_training_epochs = MINIMIZER_TRAINING_EPOCHS\n",
    "        # Variables to hold output of algorithm\n",
    "        self.initial_prediction = None\n",
    "        self.regression_trees = []\n",
    "        # Get an instance of a minimizer\n",
    "        self.minimizer = LossFunctionMinimizer(self.type)\n",
    "        if USE_CUDA:\n",
    "            self.minimizer.cuda()\n",
    "        self.minimizer_optimizer = torch.optim.Adam(self.minimizer.parameters(), lr=self.minimizer_learning_rate)\n",
    "    def minimize_loss_function(self, targets, previous_predictions):\n",
    "        self.minimizer.reinitialize_variable()\n",
    "        for training_epoch in range(self.minimizer_training_epochs):\n",
    "            targets_leaf_tensor = FloatTensor(targets)\n",
    "            loss = self.minimizer.loss_regressor(previous_predictions, targets_leaf_tensor)\n",
    "            self.minimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.minimizer_optimizer.step()\n",
    "        return [el for el in self.minimizer.parameters()][0].cpu().detach().numpy()[0]\n",
    "    def compute_residuals(self, targets, predicted_values):\n",
    "        model = ResidualsCalculator(predicted_values, self.type)\n",
    "        if USE_CUDA:\n",
    "            model.cuda()\n",
    "        loss = model.loss(targets)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        residuals = model.predicted_values.grad.clone() # deep copy of the input/gradients\n",
    "        return residuals\n",
    "    def fit(self, X, y):\n",
    "        X_values = X.copy()\n",
    "        y_values = y.copy()\n",
    "        # Initialization phase\n",
    "        if USE_CUDA:\n",
    "            initial_values = torch.zeros(y_values.shape,1).cuda()\n",
    "        else:\n",
    "            initial_values = torch.zeros(y_values.shape)\n",
    "        self.initial_prediction = self.minimize_loss_function(y_values, initial_values)\n",
    "        prediction_values = np.ones(y_values.shape) * self.initial_prediction\n",
    "\n",
    "        for classifier_index in range(self.n_trees):\n",
    "            self.regression_trees.append({\"tree_index\": classifier_index})\n",
    "            residuals = self.compute_residuals(FloatTensor(y_values), FloatTensor(prediction_values))\n",
    "            leaf_buckets, unique_clusters, tree_regressor = fit_regression_tree_classifier_to_residuals(X_values, residuals.cpu(), self.max_depth)\n",
    "            self.regression_trees[-1][\"tree_regressor\"] = tree_regressor\n",
    "\n",
    "            X_values_temp = np.array([])\n",
    "            y_values_temp = np.array([])\n",
    "            prediction_values_temp = np.array([])\n",
    "\n",
    "            for unique_cluster in unique_clusters:\n",
    "                indices = [1 if el == unique_cluster else 0 for el in leaf_buckets]\n",
    "                y_leaf = y_values[np.array(indices) == 1]\n",
    "                X_leaf = X_values[np.array(indices) == 1]\n",
    "                predictions_leaf = prediction_values[np.array(indices) == 1]\n",
    "                prediction_for_leaf = self.minimize_loss_function(FloatTensor(np.array(y_leaf)), FloatTensor(predictions_leaf))\n",
    "                predictions_for_leaf_array = np.ones(y_leaf.shape) * self.gradient_boost_learning_rate * prediction_for_leaf + predictions_leaf\n",
    "                self.regression_trees[-1][str(unique_cluster)] = prediction_for_leaf\n",
    "                X_values_temp = X_leaf if X_values_temp.shape == (0, ) else np.append(X_values_temp, X_leaf, axis=0)\n",
    "                y_values_temp = np.append(y_values_temp, y_leaf)\n",
    "                prediction_values_temp = np.append(prediction_values_temp, predictions_for_leaf_array)\n",
    "            y_values = y_values_temp\n",
    "            X_values = X_values_temp\n",
    "            prediction_values = prediction_values_temp    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for index in range(X.shape[0]):\n",
    "            prediction = self.initial_prediction\n",
    "            for tree_index in range(self.n_trees):\n",
    "                tree = self.regression_trees[tree_index]\n",
    "                prediction += self.gradient_boost_learning_rate * tree[str(tuple(tree[\"tree_regressor\"].decision_path(X[index, :].reshape(1,-1)).todok().keys()))]\n",
    "            predictions.append(prediction)\n",
    "        if self.type == \"regressor\":\n",
    "            return predictions\n",
    "        elif self.type == \"classifier\":\n",
    "            return torch.sigmoid(torch.tensor(predictions)).numpy()\n",
    "        else:\n",
    "            raise Exception(\"Not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_NODES = 7\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_train.csv'))\n",
    "    val_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_val.csv'))\n",
    "    test_df = pd.read_csv(os.path.join('..', 'datasets', f'dataset_{NUMBER_NODES}_test.csv'))\n",
    "\n",
    "    featuresNumber = (NUMBER_NODES * NUMBER_NODES - NUMBER_NODES) // 2 \n",
    "    def get_tuple_tensor_dataset(row):\n",
    "        X = row[0 : featuresNumber].astype('float32')\n",
    "        Y = row[featuresNumber + 1: ].astype('float32') # Inclui a banda otima na posicao 0\n",
    "        return X, Y\n",
    "\n",
    "    train_dataset = list(map(get_tuple_tensor_dataset, train_df.to_numpy()))\n",
    "    val_dataset = list(map(get_tuple_tensor_dataset, val_df.to_numpy()))\n",
    "    test_dataset = list(map(get_tuple_tensor_dataset, test_df.to_numpy()))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in train_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_train = np.array(X, dtype=np.float32)\n",
    "    y_train = np.array(Y, dtype=np.float32)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x, y in val_dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x_test = np.array(X, dtype=np.float32)\n",
    "    y_test = np.array(Y, dtype=np.float32)\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=5845 does not match number of samples=835",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Running the custom algorithm \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# type, n_trees, max_depth, ):\u001b[39;00m\n\u001b[0;32m      5\u001b[0m custom \u001b[38;5;241m=\u001b[39m PytorchBasedGenericGradientBoost(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m      8\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcustom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeleza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m custom\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mPytorchBasedGenericGradientBoost.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_trees\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: classifier_index})\n\u001b[0;32m     52\u001b[0m residuals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_residuals(FloatTensor(y_values), FloatTensor(prediction_values))\n\u001b[1;32m---> 53\u001b[0m leaf_buckets, unique_clusters, tree_regressor \u001b[38;5;241m=\u001b[39m \u001b[43mfit_regression_tree_classifier_to_residuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresiduals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_trees[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_regressor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tree_regressor\n\u001b[0;32m     56\u001b[0m X_values_temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mfit_regression_tree_classifier_to_residuals\u001b[1;34m(X_data, y_data, max_depth)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_regression_tree_classifier_to_residuals\u001b[39m(X_data, y_data, max_depth): \u001b[38;5;66;03m# y_data -> residuals\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     tree_regressor \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtree_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     leaf_buckets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:299\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features_ \u001b[38;5;241m=\u001b[39m max_features\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m does not match number of samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(y), n_samples)\n\u001b[0;32m    302\u001b[0m     )\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_weight_fraction_leaf \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_weight_fraction_leaf must in [0, 0.5]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=5845 does not match number of samples=835"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()\n",
    "\n",
    "# Running the custom algorithm \n",
    "# type, n_trees, max_depth, ):\n",
    "custom = PytorchBasedGenericGradientBoost(\n",
    "    \"regressor\",\n",
    "    7,\n",
    "    max_depth=None\n",
    ")\n",
    "custom.fit(X_train, y_train)\n",
    "print(\"beleza\")\n",
    "predictions = custom.predict(X_test)\n",
    "print('X_test')\n",
    "print(X_test)\n",
    "print(\"Pred\")\n",
    "print(predictions)\n",
    "print('True')\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f17ea74e9a07f02efaa90ee1f47e0c923e4f633c8e0a68dd26777c24f53b763"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
